from django.shortcuts import render, get_object_or_404, redirect
from django.contrib.auth.decorators import login_required
from django.contrib import messages
from django.http import JsonResponse, HttpResponse
from django.core.paginator import Paginator
from django.db.models import Q
from django.utils import timezone
import json
import os
from .models import AnalysisProject, BoreholeData, SoilLayer, AnalysisResult, Project
from django.http import FileResponse, Http404
from django.contrib.auth.decorators import login_required
from datetime import datetime
import glob
from django.conf import settings
import pandas as pd

def project_list(request):
    projects = Project.objects.all().order_by('-created_at')
    return render(request, 'liquefaction/project_list.html', {'projects': projects})

def index(request):
    """é¦–é è¦–åœ–"""
    context = {
        'title': 'åœŸå£¤æ¶²åŒ–åˆ†æç³»çµ±',
        'description': 'åœŸå£¤æ¶²åŒ–æ½›èƒ½åˆ†æå·¥å…·',
    }
    
    if request.user.is_authenticated:
        # å¦‚æœç”¨æˆ¶å·²ç™»å…¥ï¼Œé¡¯ç¤ºæœ€è¿‘çš„å°ˆæ¡ˆ
        recent_projects = AnalysisProject.objects.filter(
            user=request.user
        ).order_by('-updated_at')[:5]
        context['recent_projects'] = recent_projects
        
        # çµ±è¨ˆè³‡æ–™
        context['stats'] = {
            'total_projects': AnalysisProject.objects.filter(user=request.user).count(),
            'completed_projects': AnalysisProject.objects.filter(
                user=request.user, status='completed'
            ).count(),
            'processing_projects': AnalysisProject.objects.filter(
                user=request.user, status='processing'
            ).count(),
        }
    
    return render(request, 'liquefaction/index.html', context)


@login_required
def project_list(request):
    """å°ˆæ¡ˆåˆ—è¡¨è¦–åœ–"""
    projects = AnalysisProject.objects.filter(user=request.user).order_by('-updated_at')
    
    # æœç´¢åŠŸèƒ½
    search_query = request.GET.get('search', '')
    if search_query:
        projects = projects.filter(
            Q(name__icontains=search_query) | 
            Q(description__icontains=search_query)
        )
    
    # ç‹€æ…‹ç¯©é¸
    status_filter = request.GET.get('status', '')
    if status_filter:
        projects = projects.filter(status=status_filter)
    
    # åˆ†é 
    paginator = Paginator(projects, 10)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'page_obj': page_obj,
        'search_query': search_query,
        'status_filter': status_filter,
        'status_choices': AnalysisProject.STATUS_CHOICES,
    }
    
    return render(request, 'liquefaction/project_list.html', context)


@login_required
def project_create(request):
    """å‰µå»ºæ–°å°ˆæ¡ˆ"""
    if request.method == 'POST':
        try:
            # è™•ç†è¡¨å–®æ•¸æ“š
            name = request.POST.get('name')
            description = request.POST.get('description', '')
            em_value = float(request.POST.get('em_value', 72))
            unit_weight_unit = request.POST.get('unit_weight_unit', 't/m3')
            use_fault_data = request.POST.get('use_fault_data') == 'on'
            
            # å‰µå»ºå°ˆæ¡ˆ
            project = AnalysisProject.objects.create(
                user=request.user,
                name=name,
                analysis_method='HBF',
                description=description,
                em_value=em_value,
                unit_weight_unit=unit_weight_unit,
                use_fault_data=use_fault_data,
            )
            
            # è™•ç†æª”æ¡ˆä¸Šå‚³ä¸¦ç«‹å³è™•ç†
            csv_processed = False

            if 'source_file' in request.FILES:
                project.source_file = request.FILES['source_file']
                project.save()  # å…ˆä¿å­˜æª”æ¡ˆè·¯å¾‘
                
                # ç«‹å³è™•ç† CSV æª”æ¡ˆ
                from .services.data_import_service import DataImportService
                import_service = DataImportService(project)

                import_result = import_service.import_csv_data(request.FILES['source_file'],
                                                               unit_weight_unit=unit_weight_unit )
                
                if import_result['success']:
                    summary = import_result['summary']
                    messages.success(
                        request, 
                        f'å°ˆæ¡ˆ "{name}" å‰µå»ºæˆåŠŸï¼å·²åŒ¯å…¥ {summary["imported_boreholes"]} å€‹é‘½å­”ï¼Œ{summary["imported_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in import_result.get('warnings', []):
                        messages.warning(request, f'è­¦å‘Šï¼š{warning}')
                        
                    csv_processed = True
                else:
                    messages.error(request, f'CSV æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{import_result["error"]}')
                    project.status = 'error'
                    project.error_message = import_result["error"]

            if 'fault_shapefile' in request.FILES:
                project.fault_shapefile = request.FILES['fault_shapefile']

            project.save()

            if not csv_processed:
                messages.success(request, f'å°ˆæ¡ˆ "{name}" å‰µå»ºæˆåŠŸï¼è«‹ä¸Šå‚³ CSV æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚')
            
            messages.success(request, f'å°ˆæ¡ˆ "{name}" å‰µå»ºæˆåŠŸï¼')
            return redirect('liquefaction:project_detail', pk=project.pk)
            
        except Exception as e:
            messages.error(request, f'å‰µå»ºå°ˆæ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
    
    context = {
        'unit_weight_units': AnalysisProject._meta.get_field('unit_weight_unit').choices,
    }
    
    return render(request, 'liquefaction/project_create.html', context)


@login_required
def project_detail(request, pk):
    """å°ˆæ¡ˆè©³æƒ…è¦–åœ– - æ–°å¢å¿«é€Ÿåˆ†æåŠŸèƒ½"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # è™•ç†å¿«é€Ÿåˆ†æè«‹æ±‚
    if request.method == 'POST':
        selected_methods = request.POST.getlist('analysis_methods')
        if not selected_methods:
            messages.error(request, 'è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®åˆ†ææ–¹æ³•')
            return redirect('liquefaction:project_detail', pk=project.pk)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
        boreholes_count = BoreholeData.objects.filter(project=project).count()
        if boreholes_count == 0:
            messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰é‘½å­”è³‡æ–™ï¼Œè«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆ')
            return redirect('liquefaction:project_detail', pk=project.pk)
        
        # åŸ·è¡Œåˆ†æ
        try:
            from .services.analysis_engine import LiquefactionAnalysisEngine
            
            total_success = 0
            total_errors = []
            
            for method in selected_methods:
                # æš«æ™‚æ›´æ–°å°ˆæ¡ˆçš„åˆ†ææ–¹æ³•
                original_method = project.analysis_method
                project.analysis_method = method
                project.save()
                
                # åŸ·è¡Œåˆ†æ
                analysis_engine = LiquefactionAnalysisEngine(project)
                analysis_result = analysis_engine.run_analysis()
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(request, f'{method} åˆ†æå®Œæˆï¼')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                
                # æ¢å¾©åŸå§‹åˆ†ææ–¹æ³•
                project.analysis_method = original_method
                project.save()
            
            if total_success > 0:
                project.status = 'completed'
                project.save()
                messages.success(request, f'åˆ†æå®Œæˆï¼æˆåŠŸå®Œæˆ {total_success} ç¨®æ–¹æ³•çš„åˆ†æ')
                return redirect('liquefaction:results', pk=project.pk)
            else:
                project.status = 'error'
                project.error_message = '; '.join(total_errors)
                project.save()
                
        except Exception as e:
            messages.error(request, f'åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
    
    # ç²å–é‘½å­”è³‡æ–™
    boreholes = BoreholeData.objects.filter(project=project).prefetch_related('soil_layers').order_by('borehole_id')
    
    # ç‚ºæ¯å€‹é‘½å­”è¨ˆç®—æœ€å¤§æ·±åº¦
    boreholes_with_stats = []
    for borehole in boreholes:
        soil_layers = borehole.soil_layers.all()
        max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
        
        borehole_data = {
            'borehole': borehole,
            'layers_count': soil_layers.count(),
            'max_depth': max_depth
        }
        boreholes_with_stats.append(borehole_data)
    
    # ç²å–åˆ†æçµæœçµ±è¨ˆ
    total_layers = SoilLayer.objects.filter(borehole__project=project).count()
    
    # çµ±è¨ˆå„æ–¹æ³•çš„åˆ†æçµæœ
    analysis_methods_stats = {}
    for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
        analyzed_count = AnalysisResult.objects.filter(
            soil_layer__borehole__project=project,
            analysis_method=method_code
        ).count()
        analysis_methods_stats[method_code] = {
            'name': method_name,
            'count': analyzed_count,
            'progress': (analyzed_count / total_layers * 100) if total_layers > 0 else 0
        }
    
    context = {
        'project': project,
        'boreholes': boreholes,
        'boreholes_with_stats': boreholes_with_stats,
        'total_layers': total_layers,
        'analysis_methods_stats': analysis_methods_stats,
        'available_methods': AnalysisProject._meta.get_field('analysis_method').choices,
    }
    
    return render(request, 'liquefaction/project_detail.html', context)



@login_required
def project_update(request, pk):
    """æ›´æ–°å°ˆæ¡ˆ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            project.name = request.POST.get('name', project.name)
            project.description = request.POST.get('description', project.description)
            project.analysis_method = request.POST.get('analysis_method', project.analysis_method)
            project.em_value = float(request.POST.get('em_value', project.em_value))
            project.unit_weight_unit = request.POST.get('unit_weight_unit', project.unit_weight_unit)
            project.use_fault_data = request.POST.get('use_fault_data') == 'on'
            
            # è™•ç†æ–°æª”æ¡ˆä¸Šå‚³
            if 'source_file' in request.FILES:
                project.source_file = request.FILES['source_file']
            
            if 'fault_shapefile' in request.FILES:
                project.fault_shapefile = request.FILES['fault_shapefile']
            
            project.save()
            
            messages.success(request, 'å°ˆæ¡ˆæ›´æ–°æˆåŠŸï¼')
            return redirect('liquefaction:project_detail', pk=project.pk)
            
        except Exception as e:
            messages.error(request, f'æ›´æ–°å°ˆæ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
    
    context = {
        'project': project,
        'analysis_methods': AnalysisProject._meta.get_field('analysis_method').choices,
        'unit_weight_units': AnalysisProject._meta.get_field('unit_weight_unit').choices,
    }
    
    return render(request, 'liquefaction/project_update.html', context)


@login_required
def project_delete(request, pk):
    """åˆªé™¤å°ˆæ¡ˆ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        project_name = project.name
        project.delete()
        messages.success(request, f'å°ˆæ¡ˆ "{project_name}" å·²æˆåŠŸåˆªé™¤ï¼')
        return redirect('liquefaction:project_list')
    
    return render(request, 'liquefaction/project_delete.html', {'project': project})


# åœ¨ views.py é–‹é ­æˆ–è€…å‰µå»ºä¸€å€‹æ–°çš„ utils.py æ–‡ä»¶æ·»åŠ é€™å€‹å‡½æ•¸

def filter_liquid_limit_messages(messages_list):
    """
    éæ¿¾æ‰èˆ‡ liquid_limit ç›¸é—œçš„éŒ¯èª¤å’Œè­¦å‘Šè¨Šæ¯
    
    Args:
        messages_list: è¨Šæ¯åˆ—è¡¨
    
    Returns:
        list: éæ¿¾å¾Œçš„è¨Šæ¯åˆ—è¡¨
    """
    if not messages_list:
        return []
    
    # å®šç¾©éœ€è¦éæ¿¾çš„é—œéµå­— - æ ¹æ“šå¯¦éš›éŒ¯èª¤è¨Šæ¯èª¿æ•´
    filter_keywords = [
        'liquid_limit', 
        'liquid limit', 
        'll',           # ä½†è¦å°å¿ƒï¼Œå¯èƒ½æœƒèª¤éæ¿¾å…¶ä»–åŒ…å« 'll' çš„è¨Šæ¯
        'æ¶²æ€§é™åº¦',
        'liquid_limit æ•¸å€¼æ ¼å¼éŒ¯èª¤',  # æ›´ç²¾ç¢ºçš„åŒ¹é…
    ]
    
    filtered_messages = []
    for message in messages_list:
        message_str = str(message).lower()
        should_filter = False
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•éæ¿¾é—œéµå­—
        for keyword in filter_keywords:
            if keyword.lower() in message_str:
                should_filter = True
                break
        
        # ç‰¹åˆ¥æª¢æŸ¥ï¼šå¦‚æœè¨Šæ¯åŒ…å« "liquid_limit" å°±ä¸€å®šè¦éæ¿¾
        if 'liquid_limit' in message_str:
            should_filter = True
            
        if not should_filter:
            filtered_messages.append(message)
    
    return filtered_messages

def check_has_non_liquid_limit_errors(error_message, errors_list):
    """
    æª¢æŸ¥æ˜¯å¦æœ‰é liquid_limit ç›¸é—œçš„éŒ¯èª¤
    
    Args:
        error_message: ä¸»è¦éŒ¯èª¤è¨Šæ¯
        errors_list: éŒ¯èª¤åˆ—è¡¨
    
    Returns:
        bool: æ˜¯å¦æœ‰é liquid_limit ç›¸é—œçš„éŒ¯èª¤
    """
    # æª¢æŸ¥ä¸»è¦éŒ¯èª¤è¨Šæ¯
    if error_message:
        message_str = str(error_message).lower()
        # å¦‚æœåŒ…å« liquid_limit å°±è¦–ç‚ºæ¶²æ€§é™åº¦éŒ¯èª¤
        if 'liquid_limit' in message_str:
            # æª¢æŸ¥æ˜¯å¦é‚„æœ‰å…¶ä»–é¡å‹çš„éŒ¯èª¤æè¿°
            other_error_keywords = ['missing', 'ç¼ºå°‘', 'format', 'æ ¼å¼', 'invalid', 'ç„¡æ•ˆ']
            has_other_errors = any(keyword in message_str for keyword in other_error_keywords 
                                 if 'liquid_limit' not in message_str[message_str.find(keyword):])
            if not has_other_errors:
                return False  # åªæ˜¯æ¶²æ€§é™åº¦éŒ¯èª¤
        else:
            return True  # æœ‰å…¶ä»–é¡å‹çš„éŒ¯èª¤
    
    # æª¢æŸ¥éŒ¯èª¤åˆ—è¡¨
    filtered_errors = filter_liquid_limit_messages(errors_list or [])
    return len(filtered_errors) > 0

# ä½¿ç”¨ç¯„ä¾‹ - ä¿®æ”¹å¾Œçš„ file_upload å‡½æ•¸
@login_required
def file_upload(request, pk):
    """æª”æ¡ˆä¸Šå‚³è™•ç†"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            if 'csv_file' not in request.FILES:
                messages.error(request, 'è«‹é¸æ“‡è¦ä¸Šå‚³çš„ CSV æª”æ¡ˆ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            csv_file = request.FILES['csv_file']
            
            # æª¢æŸ¥æª”æ¡ˆé¡å‹
            if not csv_file.name.endswith('.csv'):
                messages.error(request, 'è«‹ä¸Šå‚³ CSV æ ¼å¼çš„æª”æ¡ˆ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æª”æ¡ˆå¤§å° (é™åˆ¶ 10MB)
            if csv_file.size > 10 * 1024 * 1024:
                messages.error(request, 'æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é 10MB')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # ä½¿ç”¨ DataImportService åŒ¯å…¥è³‡æ–™
            from .services.data_import_service import DataImportService
            import_service = DataImportService(project)
            import_result = import_service.import_csv_data(
                csv_file,
                unit_weight_unit=project.unit_weight_unit)
            
            if import_result['success']:
                # åŒ¯å…¥æˆåŠŸ
                summary = import_result['summary']
                messages.success(
                    request, 
                    f'CSV æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼å·²åŒ¯å…¥ {summary["imported_boreholes"]} å€‹é‘½å­”ï¼Œ{summary["imported_layers"]} å€‹åœŸå±¤ã€‚'
                )
                
                # é¡¯ç¤ºå–®ä½æª¢æ¸¬çµæœ
                if 'detected_unit' in import_result and import_result['detected_unit']:
                    if import_result.get('unit_consistency', True):
                        messages.info(request, f'âœ“ çµ±é«”å–®ä½é‡å–®ä½æª¢æ¸¬ï¼š{import_result["detected_unit"]}ï¼ˆèˆ‡å°ˆæ¡ˆè¨­å®šä¸€è‡´ï¼‰')
                    else:
                        messages.warning(request, f'âš ï¸ çµ±é«”å–®ä½é‡å–®ä½æª¢æ¸¬ï¼š{import_result["detected_unit"]}ï¼ˆèˆ‡å°ˆæ¡ˆè¨­å®š {project.unit_weight_unit} ä¸ä¸€è‡´ï¼‰')
                
                # ä½¿ç”¨éæ¿¾å‡½æ•¸è™•ç†è­¦å‘Šå’ŒéŒ¯èª¤è¨Šæ¯
                filtered_warnings = filter_liquid_limit_messages(import_result.get('warnings', []))
                for warning in filtered_warnings:
                    messages.warning(request, f'è­¦å‘Šï¼š{warning}')
                
                filtered_errors = filter_liquid_limit_messages(import_result.get('errors', []))
                for error in filtered_errors:
                    messages.error(request, f'éŒ¯èª¤ï¼š{error}')
                
                # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
                project.status = 'pending'
                project.error_message = ''
                project.save()
                
            else:
                # åŒ¯å…¥å¤±æ•— - æª¢æŸ¥æ˜¯å¦åªæ˜¯ liquid_limit å•é¡Œ
                has_real_errors = check_has_non_liquid_limit_errors(
                    import_result["error"], 
                    import_result.get('errors', [])
                )
                
                if has_real_errors:
                    # æœ‰çœŸæ­£çš„éŒ¯èª¤
                    main_error = import_result["error"]
                    filtered_main_error = filter_liquid_limit_messages([main_error])
                    
                    if filtered_main_error:
                        messages.error(request, f'CSV æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{filtered_main_error[0]}')
                    
                    # é¡¯ç¤ºå…¶ä»–è©³ç´°éŒ¯èª¤
                    filtered_errors = filter_liquid_limit_messages(import_result.get('errors', []))
                    for error in filtered_errors:
                        messages.error(request, f'è©³ç´°éŒ¯èª¤ï¼š{error}')
                    
                    # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹ç‚ºéŒ¯èª¤
                    project.status = 'error'
                    project.error_message = filtered_main_error[0] if filtered_main_error else "è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤"
                    project.save()
                    
                else:
                    # åªæœ‰ liquid_limit ç›¸é—œå•é¡Œï¼Œè¦–ç‚ºæˆåŠŸ
                    messages.success(request, 'CSV æª”æ¡ˆè™•ç†å®Œæˆï¼ˆå·²å¿½ç•¥æ¶²æ€§é™åº¦ç›¸é—œå•é¡Œï¼‰')
                    project.status = 'pending'
                    project.error_message = ''
                    project.save()
                
                # å¦‚æœæ˜¯ç¼ºå°‘æ¬„ä½çš„å•é¡Œï¼Œæä¾›è©³ç´°è³‡è¨Š
                if 'missing_fields' in import_result:
                    messages.info(request, f'å¯ç”¨çš„æ¬„ä½ï¼š{", ".join(import_result["available_columns"])}')
                    messages.info(request, 'è«‹ç¢ºä¿ CSV æª”æ¡ˆåŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½ï¼Œæˆ–ä½¿ç”¨ç›¸æ‡‰çš„ä¸­æ–‡æ¬„ä½åç¨±')
                
        except Exception as e:
            messages.error(request, f'æª”æ¡ˆä¸Šå‚³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
    
    return redirect('liquefaction:project_detail', pk=project.pk)
# views.py ä¿®å¾©å°ˆæ¡ˆç‹€æ…‹å¡ä½çš„å•é¡Œ

@login_required
def analyze(request, pk):
    """åŸ·è¡Œæ¶²åŒ–åˆ†æ - æ”¯æ´å¤šæ–¹æ³•åˆ†æ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            # ç²å–é¸æ“‡çš„åˆ†ææ–¹æ³•
            selected_methods = request.POST.getlist('analysis_methods')
            if not selected_methods:
                messages.error(request, 'è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®åˆ†ææ–¹æ³•')
                return redirect('liquefaction:analyze', pk=project.pk)
            
            print(f"=== é–‹å§‹åˆ†æå°ˆæ¡ˆ {project.name}ï¼Œæ–¹æ³•ï¼š{selected_methods} ===")
            
            # æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹
            if project.status == 'processing':
                from django.utils import timezone
                import datetime
                
                time_diff = timezone.now() - project.updated_at
                if time_diff > datetime.timedelta(minutes=10):
                    print(f"âš ï¸ å°ˆæ¡ˆè™•ç†è¶…æ™‚ ({time_diff})ï¼Œé‡ç½®ç‹€æ…‹")
                    project.status = 'pending'
                    project.error_message = ''
                    project.save()
                    messages.warning(request, 'æª¢æ¸¬åˆ°ä¹‹å‰çš„åˆ†æå¯èƒ½ä¸­æ–·ï¼Œå·²é‡ç½®ç‹€æ…‹ã€‚')
                else:
                    print(f"âš ï¸ å°ˆæ¡ˆæ­£åœ¨è™•ç†ä¸­ï¼Œç­‰å¾…æ™‚é–“: {time_diff}")
                    messages.warning(request, f'å°ˆæ¡ˆæ­£åœ¨åˆ†æä¸­ï¼Œå·²åŸ·è¡Œ {time_diff}ï¼Œè«‹ç¨å€™...')
                    return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‘½å­”è³‡æ–™
            boreholes_count = BoreholeData.objects.filter(project=project).count()
            if boreholes_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰é‘½å­”è³‡æ–™ï¼Œè«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åœŸå±¤è³‡æ–™
            layers_count = SoilLayer.objects.filter(borehole__project=project).count()
            if layers_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰åœŸå±¤è³‡æ–™')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            print("æ­£åœ¨è¼‰å…¥åˆ†æå¼•æ“...")
            from .services.analysis_engine import LiquefactionAnalysisEngine
            
            total_success = 0
            total_errors = []
            original_method = project.analysis_method
            
            for method in selected_methods:
                print(f"é–‹å§‹åŸ·è¡Œ {method} åˆ†æ...")
                
                # åªå»ºç«‹ä¸€æ¬¡åˆ†æå¼•æ“ï¼Œä¸¦å‚³å…¥æŒ‡å®šçš„æ–¹æ³•
                analysis_engine = LiquefactionAnalysisEngine(project, analysis_method=method)
                analysis_result = analysis_engine.run_analysis()
                
                print(f"{method} åˆ†æçµæœ: {analysis_result}")
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(
                        request, 
                        f'{method} åˆ†æå®Œæˆï¼å…±åˆ†æ {analysis_result["analyzed_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in analysis_result.get('warnings', []):
                        messages.warning(request, f'{method} è­¦å‘Šï¼š{warning}')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                    
                    # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
                    for error in analysis_result.get('errors', []):
                        messages.error(request, f'{method} éŒ¯èª¤ï¼š{error}')
                
                print(f"{method} åˆ†æçµæœ: {analysis_result}")
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(
                        request, 
                        f'{method} åˆ†æå®Œæˆï¼å…±åˆ†æ {analysis_result["analyzed_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in analysis_result.get('warnings', []):
                        messages.warning(request, f'{method} è­¦å‘Šï¼š{warning}')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                    
                    # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
                    for error in analysis_result.get('errors', []):
                        messages.error(request, f'{method} éŒ¯èª¤ï¼š{error}')
            
            # æ¢å¾©åŸå§‹åˆ†ææ–¹æ³•
            project.analysis_method = original_method
            
            # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
            if total_success > 0:
                project.status = 'completed'
                project.error_message = ''
                project.save()
                messages.success(request, f'å¤šæ–¹æ³•åˆ†æå®Œæˆï¼æˆåŠŸå®Œæˆ {total_success}/{len(selected_methods)} ç¨®æ–¹æ³•çš„åˆ†æ')
                return redirect('liquefaction:results', pk=project.pk)
            else:
                project.status = 'error'
                project.error_message = '; '.join(total_errors)
                project.save()
                return redirect('liquefaction:project_detail', pk=project.pk)
                
        except Exception as e:
            messages.error(request, f'åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
            
            return redirect('liquefaction:project_detail', pk=project.pk)
    
    # GET è«‹æ±‚ï¼Œé¡¯ç¤ºåˆ†æç¢ºèªé é¢
    context = {
        'project': project,
        'boreholes_count': BoreholeData.objects.filter(project=project).count(),
        'layers_count': SoilLayer.objects.filter(borehole__project=project).count(),
        'available_methods': AnalysisProject._meta.get_field('analysis_method').choices,
    }
    
    return render(request, 'liquefaction/analyze.html', context)

# æ·»åŠ ä¸€å€‹æ–°çš„ view ç”¨æ–¼é‡ç½®å°ˆæ¡ˆç‹€æ…‹
@login_required
def reset_project_status(request, pk):
    """é‡ç½®å°ˆæ¡ˆç‹€æ…‹"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        old_status = project.status
        project.status = 'pending'
        project.error_message = ''
        project.save()
        
        messages.success(request, f'å°ˆæ¡ˆç‹€æ…‹å·²å¾ "{project.get_status_display()}" é‡ç½®ç‚º "ç­‰å¾…åˆ†æ"')
        print(f"å°ˆæ¡ˆ {project.name} ç‹€æ…‹å·²å¾ {old_status} é‡ç½®ç‚º pending")
        
    return redirect('liquefaction:project_detail', pk=project.pk)


@login_required
def results(request, pk):
    """æŸ¥çœ‹åˆ†æçµæœ - æ–°å¢æ–¹æ³•ç¯©é¸"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
    total_results = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).count()
    
    if total_results == 0:
        messages.warning(request, 'å°ˆæ¡ˆå°šæœªæœ‰åˆ†æçµæœ')
        return redirect('liquefaction:project_detail', pk=project.pk)
    
    # ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•ç²å–å¯ç”¨åˆ†ææ–¹æ³•
    available_methods_raw = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).values_list('analysis_method', flat=True).distinct().order_by('analysis_method')

    # è½‰æ›ç‚ºåˆ—è¡¨ä¸¦éæ¿¾ç©ºå€¼
    available_methods_list = [method for method in available_methods_raw if method]

    # å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±æ•—ï¼Œæ‰‹å‹•æª¢æŸ¥æ¯å€‹æ–¹æ³•
    if not available_methods_list:
        all_methods = ['HBF', 'NCEER', 'AIJ', 'JRA']
        available_methods_list = []
        for method in all_methods:
            if AnalysisResult.objects.filter(
                soil_layer__borehole__project=project,
                analysis_method=method
            ).exists():
                available_methods_list.append(method)
    
    # ç²å–æ–¹æ³•åç¨±å°æ‡‰
    method_choices = dict(AnalysisProject._meta.get_field('analysis_method').choices)
    available_methods_display = [
        (method, method_choices.get(method, method)) 
        for method in available_methods_raw
    ]
    
    print(f"ğŸ” é¡¯ç¤ºç”¨çš„æ–¹æ³•å°æ‡‰: {available_methods_display}")
    
    # ç²å–æ‰€æœ‰åˆ†æçµæœ
    results = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).select_related('soil_layer', 'soil_layer__borehole').order_by(
        'soil_layer__borehole__borehole_id', 'soil_layer__top_depth', 'analysis_method'
    )
    
    # æ‡‰ç”¨ç¯©é¸æ¢ä»¶
    borehole_filter = request.GET.get('borehole', '')
    if borehole_filter:
        results = results.filter(soil_layer__borehole__borehole_id=borehole_filter)
    
    # æ–°å¢ï¼šåˆ†ææ–¹æ³•ç¯©é¸
    method_filter = request.GET.get('method', '')
    if method_filter:
        results = results.filter(analysis_method=method_filter)
        print(f"ğŸ” ç¯©é¸æ–¹æ³•: {method_filter}, çµæœæ•¸é‡: {results.count()}")
    
    lpi_filter = request.GET.get('lpi', '')
    if lpi_filter == 'low':
        results = results.filter(lpi_design__lt=5.0)
    elif lpi_filter == 'medium':
        results = results.filter(lpi_design__gte=5.0, lpi_design__lte=15.0)
    elif lpi_filter == 'high':
        results = results.filter(lpi_design__gt=15.0)
    
    print(f"ğŸ” æœ€çµ‚çµæœæ•¸é‡: {results.count()}")
    
    context = {
        'project': project,
        'results': results,
        'available_methods': available_methods_display,
        'method_filter': method_filter,
        'lpi_filter': lpi_filter,  
    }
    
    return render(request, 'liquefaction/results.html', context)

from django.db.models.fields.related import ForeignKey, OneToOneField, ManyToOneRel

@login_required
def export_results(request, pk):
    """åŒ¯å‡ºåˆ†æçµæœ - æ”¯æ´å¤šæ–¹æ³• - åŒ…å«æ‰€æœ‰è¨ˆç®—åƒæ•¸"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
    total_results = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).count()
    
    if total_results == 0:
        messages.error(request, 'å°ˆæ¡ˆå°šæœªæœ‰åˆ†æçµæœï¼Œç„¡æ³•åŒ¯å‡º')
        return redirect('liquefaction:project_detail', pk=project.pk)
    
    try:
        import csv
        from django.http import HttpResponse
        from datetime import datetime
        
        # ç²å–é¸æ“‡çš„æ–¹æ³•ï¼ˆå¦‚æœæœ‰ï¼‰
        method_filter = request.GET.get('method', '')
        export_type = request.GET.get('type', 'csv')
        
        # å‰µå»º HTTP éŸ¿æ‡‰
        if method_filter:
            filename = f"{project.name}_{method_filter}_detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
        else:
            filename = f"{project.name}_all_methods_detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
            
        response = HttpResponse(content_type='text/csv; charset=utf-8')
        response['Content-Disposition'] = f'attachment; filename="{filename}"'
        
        # æ·»åŠ  BOM ä»¥ç¢ºä¿ Excel æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡
        response.write('\ufeff')
        
        writer = csv.writer(response)
        
        # åœ¨ views.py çš„ export_results å‡½æ•¸ä¸­ä¿®æ”¹æ¨™é¡Œè¡Œéƒ¨åˆ†
        headers = [
            # åŸºæœ¬è³‡è¨Š
            'é‘½å­”ç·¨è™Ÿ', 'åˆ†ææ–¹æ³•', 'æ·±åº¦ä¸Šé™(m)', 'æ·±åº¦ä¸‹é™(m)', 'åœŸå±¤åšåº¦(m)',
            'åœŸå£¤åˆ†é¡(USCS)', 'SPT-N', 'å¡‘æ€§æŒ‡æ•¸(%)', 'ç´°æ–™å«é‡(%)', 'å–æ¨£ç·¨è™Ÿ',
            
            # åº§æ¨™å’ŒåŸºæœ¬åƒæ•¸
            'TWD97_X', 'TWD97_Y', 'åœ°è¡¨é«˜ç¨‹(m)', 'åœ°ä¸‹æ°´ä½æ·±åº¦(m)',
            
            # åœ°éœ‡åƒæ•¸
            'åŸå¸‚', 'åŸºæº–Mw', 'SDS', 'SMS', 'è³‡æ–™ä¾†æº', 'é„°è¿‘æ–·å±¤',
            
            # ä¸­é–“è¨ˆç®—åƒæ•¸
            'åœŸå±¤æ·±åº¦(m)', 'åœŸå±¤ä¸­é»æ·±åº¦(m)', 'åˆ†æé»æ·±åº¦(m)',
            'ç¸½å‚ç›´æ‡‰åŠ›Ïƒv(t/mÂ²)', 'æœ‰æ•ˆå‚ç›´æ‡‰åŠ›Ïƒ\'v_CSR(t/mÂ²)', 'æœ‰æ•ˆå‚ç›´æ‡‰åŠ›Ïƒ\'v_CRR(t/mÂ²)',
            'N60', 'N1_60', 'N1_60cs', 'å‰ªåŠ›æ³¢é€ŸVs(m/s)', 'CRR_7.5',
            
            # è¨­è¨ˆåœ°éœ‡è©³ç´°åƒæ•¸
            'è¨­è¨ˆåœ°éœ‡_Mw', 'è¨­è¨ˆåœ°éœ‡_A_value(g)', 'è¨­è¨ˆåœ°éœ‡_SD_S', 'è¨­è¨ˆåœ°éœ‡_SM_S',
            'è¨­è¨ˆåœ°éœ‡_MSF', 'è¨­è¨ˆåœ°éœ‡_rd', 'è¨­è¨ˆåœ°éœ‡_CSR', 'è¨­è¨ˆåœ°éœ‡_CRR', 
            'è¨­è¨ˆåœ°éœ‡_FS', 'è¨­è¨ˆåœ°éœ‡_LPI',
            
            # ä¸­å°åœ°éœ‡è©³ç´°åƒæ•¸
            'ä¸­å°åœ°éœ‡_Mw', 'ä¸­å°åœ°éœ‡_A_value(g)', 'ä¸­å°åœ°éœ‡_SD_S', 'ä¸­å°åœ°éœ‡_SM_S',
            'ä¸­å°åœ°éœ‡_MSF', 'ä¸­å°åœ°éœ‡_rd', 'ä¸­å°åœ°éœ‡_CSR', 'ä¸­å°åœ°éœ‡_CRR', 
            'ä¸­å°åœ°éœ‡_FS', 'ä¸­å°åœ°éœ‡_LPI',
            
            # æœ€å¤§åœ°éœ‡è©³ç´°åƒæ•¸
            'æœ€å¤§åœ°éœ‡_Mw', 'æœ€å¤§åœ°éœ‡_A_value(g)', 'æœ€å¤§åœ°éœ‡_SD_S', 'æœ€å¤§åœ°éœ‡_SM_S',
            'æœ€å¤§åœ°éœ‡_MSF', 'æœ€å¤§åœ°éœ‡_rd', 'æœ€å¤§åœ°éœ‡_CSR', 'æœ€å¤§åœ°éœ‡_CRR', 
            'æœ€å¤§åœ°éœ‡_FS', 'æœ€å¤§åœ°éœ‡_LPI',
            
            # é¡å¤–è³‡è¨Š
            'å–®ä½é‡(t/mÂ³)', 'å«æ°´é‡(%)', 'æ¶²æ€§é™åº¦(%)', 'åˆ†ææ™‚é–“'
        ]

        # æ ¹æ“šåˆ†ææ–¹æ³•æ·»åŠ ä¸åŒçš„Nå€¼ç›¸é—œæ¬„ä½
        if method_filter == 'JRA':
            headers.extend(['N72', 'N1_72', 'C1', 'C2', 'Na', 'å‰ªåŠ›æ³¢é€ŸVs(m/s)', 'CRR_7.5'])
        elif method_filter == ['AIJ']:
            headers.extend(['N72', 'N1_72', 'Na', 'å‰ªåŠ›æ³¢é€ŸVs(m/s)', 'CRR_7.5'])
        else:
            headers.extend(['N60', 'N1_60', 'N1_60cs', 'å‰ªåŠ›æ³¢é€ŸVs(m/s)', 'CRR_7.5'])

        # å…¶é¤˜æ¬„ä½ä¿æŒä¸è®Š...
        writer.writerow(headers)
        
        # ç²å–åˆ†æçµæœ
        results = AnalysisResult.objects.filter(
            soil_layer__borehole__project=project
        ).select_related('soil_layer', 'soil_layer__borehole').order_by(
            'soil_layer__borehole__borehole_id', 'soil_layer__top_depth', 'analysis_method'
        )
        
        # æ‡‰ç”¨æ–¹æ³•ç¯©é¸
        if method_filter:
            results = results.filter(analysis_method=method_filter)
        
        # ===== ä¿®æ”¹ï¼šå¯«å…¥åŒ…å«æ‰€æœ‰åƒæ•¸çš„è©³ç´°è³‡æ–™è¡Œ =====
        for result in results:
            soil_layer = result.soil_layer
            borehole = soil_layer.borehole
            
            # å®‰å…¨å–å€¼å‡½æ•¸
            def safe_value(val):
                if val is None:
                    return ''
                elif isinstance(val, float):
                    return f"{val:.6f}" if abs(val) < 1000 else f"{val:.2f}"
                else:
                    return str(val)
            
            row = [
                # åŸºæœ¬è³‡è¨Š
                borehole.borehole_id,
                result.analysis_method,
                safe_value(soil_layer.top_depth),
                safe_value(soil_layer.bottom_depth),
                safe_value(soil_layer.thickness) if hasattr(soil_layer, 'thickness') else safe_value(soil_layer.bottom_depth - soil_layer.top_depth),
                soil_layer.uscs or '',
                safe_value(soil_layer.spt_n),
                safe_value(soil_layer.plastic_index),
                safe_value(soil_layer.fines_content),
                soil_layer.sample_id or '',
                
                # åº§æ¨™å’ŒåŸºæœ¬åƒæ•¸
                safe_value(borehole.twd97_x),
                safe_value(borehole.twd97_y),
                safe_value(borehole.surface_elevation),
                safe_value(borehole.water_depth),
                
                # åœ°éœ‡åƒæ•¸
                borehole.city or '',
                safe_value(borehole.base_mw),
                safe_value(borehole.sds),
                safe_value(borehole.sms),
                borehole.data_source or '',
                borehole.nearby_fault or '',
                
                # ä¸­é–“è¨ˆç®—åƒæ•¸
                safe_value(result.soil_depth),
                safe_value(result.mid_depth),
                safe_value(result.analysis_depth),
                safe_value(result.sigma_v),
                safe_value(result.sigma_v_csr),
                safe_value(result.sigma_v_crr),
                safe_value(result.n60),
                safe_value(result.n1_60),
                safe_value(result.n1_60cs),
                safe_value(result.vs),
                safe_value(result.crr_7_5),
                
                # è¨­è¨ˆåœ°éœ‡è©³ç´°åƒæ•¸
                safe_value(result.mw_design),
                safe_value(result.a_value_design),
                safe_value(result.sd_s_design),
                safe_value(result.sm_s_design),
                safe_value(result.msf_design),
                safe_value(result.rd_design),
                safe_value(result.csr_design),
                safe_value(result.crr_design),
                safe_value(result.fs_design),
                safe_value(result.lpi_design),
                
                # ä¸­å°åœ°éœ‡è©³ç´°åƒæ•¸
                safe_value(result.mw_mid),
                safe_value(result.a_value_mid),
                safe_value(result.sd_s_mid),
                safe_value(result.sm_s_mid),
                safe_value(result.msf_mid),
                safe_value(result.rd_mid),
                safe_value(result.csr_mid),
                safe_value(result.crr_mid),
                safe_value(result.fs_mid),
                safe_value(result.lpi_mid),
                
                # æœ€å¤§åœ°éœ‡è©³ç´°åƒæ•¸
                safe_value(result.mw_max),
                safe_value(result.a_value_max),
                safe_value(result.sd_s_max),
                safe_value(result.sm_s_max),
                safe_value(result.msf_max),
                safe_value(result.rd_max),
                safe_value(result.csr_max),
                safe_value(result.crr_max),
                safe_value(result.fs_max),
                safe_value(result.lpi_max),
                
                # é¡å¤–è³‡è¨Š
                safe_value(soil_layer.unit_weight),
                safe_value(soil_layer.water_content),
                safe_value(soil_layer.liquid_limit),
                result.created_at.strftime('%Y-%m-%d %H:%M:%S') if result.created_at else ''
            ]
            writer.writerow(row)
        
        return response
        
    except Exception as e:
        messages.error(request, f'åŒ¯å‡ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)
    
def api_seismic_data(request):
    """APIï¼šç²å–åœ°éœ‡åƒæ•¸è³‡æ–™"""
    city = request.GET.get('city', '')
    district = request.GET.get('district', '')
    village = request.GET.get('village', '')
    
    # é€™è£¡å°‡ä¾†æœƒå¯¦ä½œåœ°éœ‡åƒæ•¸æŸ¥è©¢é‚è¼¯
    return JsonResponse({
        'city': city,
        'district': district,
        'village': village,
        'seismic_data': {},
        'message': 'API é–‹ç™¼ä¸­'
    })


@login_required
def reanalyze(request, pk):
    """é‡æ–°åŸ·è¡Œæ¶²åŒ–åˆ†æ - æ”¯æ´å¤šæ–¹æ³•"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            # å–å¾—é¸æ“‡çš„åˆ†ææ–¹æ³•
            selected_methods = request.POST.getlist('analysis_methods')
            if not selected_methods:
                messages.error(request, 'è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®åˆ†ææ–¹æ³•')
                return redirect('liquefaction:reanalyze', pk=project.pk)
            
            print(f"=== é–‹å§‹é‡æ–°åˆ†æå°ˆæ¡ˆ {project.name}ï¼Œæ–¹æ³•ï¼š{selected_methods} ===")
            
            # æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹
            if project.status == 'processing':
                messages.warning(request, 'å°ˆæ¡ˆæ­£åœ¨åˆ†æä¸­ï¼Œè«‹ç¨å€™...')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‘½å­”è³‡æ–™
            boreholes_count = BoreholeData.objects.filter(project=project).count()
            if boreholes_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰é‘½å­”è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åœŸå±¤è³‡æ–™
            layers_count = SoilLayer.objects.filter(borehole__project=project).count()
            if layers_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰åœŸå±¤è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æ¸…é™¤é¸ä¸­æ–¹æ³•çš„ç¾æœ‰åˆ†æçµæœ
            for method in selected_methods:
                deleted_count = AnalysisResult.objects.filter(
                    soil_layer__borehole__project=project,
                    analysis_method=method
                ).count()
                
                AnalysisResult.objects.filter(
                    soil_layer__borehole__project=project,
                    analysis_method=method
                ).delete()
                
                print(f"å·²æ¸…é™¤ {method} æ–¹æ³•çš„ {deleted_count} å€‹ç¾æœ‰åˆ†æçµæœ")
            
            # é‡è¨­éŒ¯èª¤è¨Šæ¯
            project.error_message = ''
            project.save()
            
            print("æ­£åœ¨è¼‰å…¥åˆ†æå¼•æ“...")
            from .services.analysis_engine import LiquefactionAnalysisEngine
            
            total_success = 0
            total_errors = []
            
            for method in selected_methods:
                print(f"é–‹å§‹é‡æ–°åŸ·è¡Œ {method} åˆ†æ...")
                
                # å»ºç«‹å°ˆé–€é‡å°è©²æ–¹æ³•çš„åˆ†æå¼•æ“å¯¦ä¾‹
                analysis_engine = LiquefactionAnalysisEngine(project, analysis_method=method)
                analysis_result = analysis_engine.run_analysis()
                
                print(f"{method} é‡æ–°åˆ†æçµæœ: {analysis_result}")
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(
                        request, 
                        f'{method} é‡æ–°åˆ†æå®Œæˆï¼å…±åˆ†æ {analysis_result["analyzed_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in analysis_result.get('warnings', []):
                        messages.warning(request, f'{method} è­¦å‘Šï¼š{warning}')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} é‡æ–°åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                    
                    # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
                    for error in analysis_result.get('errors', []):
                        messages.error(request, f'{method} éŒ¯èª¤ï¼š{error}')
            
            # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
            if total_success > 0:
                project.status = 'completed'
                project.error_message = ''
                project.save()
                messages.success(request, f'é‡æ–°åˆ†æå®Œæˆï¼æˆåŠŸå®Œæˆ {total_success}/{len(selected_methods)} ç¨®æ–¹æ³•çš„åˆ†æ')
                return redirect('liquefaction:results', pk=project.pk)
            else:
                project.status = 'error'
                project.error_message = '; '.join(total_errors)
                project.save()
                return redirect('liquefaction:project_detail', pk=project.pk)
                
        except Exception as e:
            messages.error(request, f'é‡æ–°åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
            
            return redirect('liquefaction:project_detail', pk=project.pk)
    
    # GET è«‹æ±‚ï¼Œé¡¯ç¤ºé‡æ–°åˆ†æç¢ºèªé é¢
    # å–å¾—ç¾æœ‰çš„åˆ†æçµæœçµ±è¨ˆ
    existing_results_by_method = {}
    for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
        count = AnalysisResult.objects.filter(
            soil_layer__borehole__project=project,
            analysis_method=method_code
        ).count()
        if count > 0:
            existing_results_by_method[method_code] = {
                'name': method_name,
                'count': count
            }
    
    context = {
        'project': project,
        'boreholes_count': BoreholeData.objects.filter(project=project).count(),
        'layers_count': SoilLayer.objects.filter(borehole__project=project).count(),
        'existing_results_by_method': existing_results_by_method,
        'available_methods': AnalysisProject._meta.get_field('analysis_method').choices,
    }
    
    return render(request, 'liquefaction/reanalyze.html', context)

@login_required
def download_analysis_file(request, pk, filename):
    """ä¸‹è¼‰åˆ†æçµæœæª”æ¡ˆ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    file_path = os.path.join(project.get_output_directory(), filename)
    
    if not os.path.exists(file_path) or not filename.startswith(str(project.id)):
        raise Http404("æª”æ¡ˆä¸å­˜åœ¨")
    
    return FileResponse(
        open(file_path, 'rb'),
        as_attachment=True,
        filename=filename
    )

@login_required
def project_files(request, pk):
    """æŸ¥çœ‹å°ˆæ¡ˆæª”æ¡ˆåˆ—è¡¨"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    files = project.list_output_files()
    
    context = {
        'project': project,
        'files': files,
    }
    
    return render(request, 'liquefaction/project_files.html', context)


# åœ¨ src/liquefaction/views.py ä¸­æ–°å¢ä»¥ä¸‹è¦–åœ–

@login_required
def borehole_data(request, pk):
    """é‘½äº•æ•¸æ“šç¸½è¦½è¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # å–å¾—æ‰€æœ‰é‘½å­”æ•¸æ“š
    boreholes = BoreholeData.objects.filter(project=project).prefetch_related('soil_layers').order_by('borehole_id')
    
    # æœå°‹å’Œç¯©é¸
    search_query = request.GET.get('search', '')
    if search_query:
        boreholes = boreholes.filter(borehole_id__icontains=search_query)
    
    # ç‚ºæ¯å€‹é‘½å­”è¨ˆç®—çµ±è¨ˆè³‡è¨Š
    borehole_stats = []
    for borehole in boreholes:
        soil_layers = borehole.soil_layers.all().order_by('top_depth')
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        total_layers = soil_layers.count()
        max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
        min_n_value = min([layer.spt_n for layer in soil_layers if layer.spt_n is not None]) if soil_layers else None
        max_n_value = max([layer.spt_n for layer in soil_layers if layer.spt_n is not None]) if soil_layers else None
        avg_n_value = sum([layer.spt_n for layer in soil_layers if layer.spt_n is not None]) / total_layers if total_layers > 0 else None
        
        # åœŸå£¤é¡å‹åˆ†å¸ƒ
        soil_types = list(set([layer.uscs for layer in soil_layers if layer.uscs]))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
        has_analysis = AnalysisResult.objects.filter(soil_layer__borehole=borehole).exists()
        analysis_methods = list(set(AnalysisResult.objects.filter(
            soil_layer__borehole=borehole
        ).values_list('analysis_method', flat=True)))
        
        borehole_stats.append({
            'borehole': borehole,
            'total_layers': total_layers,
            'max_depth': max_depth,
            'min_n_value': min_n_value,
            'max_n_value': max_n_value,
            'avg_n_value': avg_n_value,
            'soil_types': soil_types,
            'has_analysis': has_analysis,
            'analysis_methods': analysis_methods,
        })
    
    # åˆ†é 
    from django.core.paginator import Paginator
    paginator = Paginator(borehole_stats, 10)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'project': project,
        'page_obj': page_obj,
        'search_query': search_query,
        'total_boreholes': boreholes.count(),
    }
    
    return render(request, 'liquefaction/borehole_data.html', context)


@login_required
def borehole_detail(request, pk, borehole_id):
    """å–®å€‹é‘½å­”è©³ç´°æ•¸æ“šè¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    borehole = get_object_or_404(BoreholeData, project=project, borehole_id=borehole_id)
    
    # å–å¾—åœŸå±¤æ•¸æ“š
    soil_layers = SoilLayer.objects.filter(borehole=borehole).order_by('top_depth')
    
    # æ ¹æ“šä½ çš„å¯¦éš›æ¨¡å‹è™•ç†æ•¸æ“š
    for layer in soil_layers:
        # FCå€¼è™•ç† - å„ªå…ˆä½¿ç”¨ FC æ¬„ä½ï¼Œå…¶æ¬¡æ˜¯ fines_content
        if layer.FC is not None:
            layer.fc_value = layer.FC
        elif layer.fines_content is not None:
            layer.fc_value = layer.fines_content
        # å¦‚æœæ²’æœ‰ç´°æ–™æ¬„ä½ï¼Œç”¨ç²‰åœŸ+é»åœŸè¨ˆç®—
        elif (layer.silt_percent is not None and layer.clay_percent is not None):
            layer.fc_value = layer.silt_percent + layer.clay_percent
        else:
            layer.fc_value = None
        
        # è™•ç†Nå€¼ - å„ªå…ˆä½¿ç”¨ spt_nï¼Œå…¶æ¬¡æ˜¯ n_value
        if layer.spt_n is not None:
            layer.n_val = layer.spt_n
        elif layer.n_value is not None:
            layer.n_val = layer.n_value
        else:
            layer.n_val = None
        
        # çµ±ä¸€åœŸå£¤åˆ†é¡å·²ç¶“ç›´æ¥å¯ç”¨
        layer.soil_class = layer.uscs if layer.uscs else None
        
        # å–®ä½é‡è™•ç†
        layer.unit_wt = layer.unit_weight if layer.unit_weight is not None else None
        
        # åšåº¦å·²ç¶“åœ¨æ¨¡å‹çš„propertyä¸­å®šç¾©äº†ï¼Œç›´æ¥ä½¿ç”¨
        # layer.thickness å·²ç¶“å¯ä»¥ç›´æ¥ä½¿ç”¨
        
        # Debugè¼¸å‡ºï¼ˆå¯é¸ï¼Œç”¨æ–¼æ’æŸ¥å•é¡Œï¼‰
        print(f"Layer {layer.id}: FC={layer.fc_value}, N={layer.n_val}, USCS={layer.soil_class}")
    
    # å–å¾—åˆ†æçµæœï¼ˆå¦‚æœæœ‰ï¼‰
    analysis_results = {}
    if hasattr(AnalysisProject, '_meta'):
        try:
            for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
                results = AnalysisResult.objects.filter(
                    soil_layer__borehole=borehole,
                    analysis_method=method_code
                ).order_by('soil_layer__top_depth')
                
                if results.exists():
                    analysis_results[method_code] = {
                        'name': method_name,
                        'results': results
                    }
        except:
            # å¦‚æœæ²’æœ‰analysis_methodæ¬„ä½æˆ–AnalysisResultæ¨¡å‹ï¼Œè·³é
            pass
    
    # è¨ˆç®—é‘½å­”çµ±è¨ˆ
    total_layers = soil_layers.count()
    max_depth = 0
    if soil_layers:
        depth_values = []
        for layer in soil_layers:
            if hasattr(layer, 'bottom_depth') and layer.bottom_depth is not None:
                depth_values.append(layer.bottom_depth)
        max_depth = max(depth_values) if depth_values else 0
    
    # Nå€¼çµ±è¨ˆ
    n_values = [layer.n_val for layer in soil_layers if layer.n_val is not None]
    n_stats = {
        'count': len(n_values),
        'min': min(n_values) if n_values else None,
        'max': max(n_values) if n_values else None,
        'avg': sum(n_values) / len(n_values) if n_values else None,
    }
    
    # FCå€¼çµ±è¨ˆ
    fc_values = [layer.fc_value for layer in soil_layers if layer.fc_value is not None]
    fc_stats = {
        'count': len(fc_values),
        'min': min(fc_values) if fc_values else None,
        'max': max(fc_values) if fc_values else None,
        'avg': sum(fc_values) / len(fc_values) if fc_values else None,
    }
    
    # åœŸå£¤é¡å‹åˆ†å¸ƒ
    soil_type_counts = {}
    for layer in soil_layers:
        if layer.soil_class:
            soil_type_counts[layer.soil_class] = soil_type_counts.get(layer.soil_class, 0) + 1
    
    # æ·±åº¦åˆ†å¸ƒï¼ˆæ¯5ç±³ä¸€çµ„ï¼‰
    depth_distribution = {}
    for layer in soil_layers:
        if hasattr(layer, 'top_depth') and layer.top_depth is not None:
            depth_group = int(layer.top_depth // 5) * 5
            key = f"{depth_group}-{depth_group + 5}m"
            depth_distribution[key] = depth_distribution.get(key, 0) + 1
    
    # FCå«é‡åˆ†å¸ƒçµ±è¨ˆ (ç”¨æ–¼åˆ†ææ¶²åŒ–æ½›èƒ½)
    fc_distribution = {
        'ä½FC(<15%)': 0,
        'ä¸­FC(15-35%)': 0, 
        'é«˜FC(>35%)': 0
    }
    
    for layer in soil_layers:
        if layer.fc_value is not None:
            if layer.fc_value < 15:
                fc_distribution['ä½FC(<15%)'] += 1
            elif layer.fc_value <= 35:
                fc_distribution['ä¸­FC(15-35%)'] += 1
            else:
                fc_distribution['é«˜FC(>35%)'] += 1
    
    context = {
        'project': project,
        'borehole': borehole,
        'soil_layers': soil_layers,
        'analysis_results': analysis_results,
        'total_layers': total_layers,
        'max_depth': max_depth,
        'n_stats': n_stats,
        'fc_stats': fc_stats,  # FC çµ±è¨ˆ
        'soil_type_counts': soil_type_counts,
        'depth_distribution': depth_distribution,
        'fc_distribution': fc_distribution,  # FC åˆ†å¸ƒçµ±è¨ˆ
    }
    
    return render(request, 'liquefaction/borehole_detail.html', context)
@login_required
def borehole_data(request, pk):
    """é‘½äº•æ•¸æ“šç¸½è¦½è¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # å–å¾—æ‰€æœ‰é‘½å­”æ•¸æ“š
    boreholes = BoreholeData.objects.filter(project=project).prefetch_related('soil_layers').order_by('borehole_id')
    
    # æœå°‹å’Œç¯©é¸
    search_query = request.GET.get('search', '')
    if search_query:
        boreholes = boreholes.filter(borehole_id__icontains=search_query)
    
    # ç‚ºæ¯å€‹é‘½å­”è¨ˆç®—çµ±è¨ˆè³‡è¨Š
    borehole_stats = []
    for borehole in boreholes:
        soil_layers = borehole.soil_layers.all().order_by('top_depth')
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        total_layers = soil_layers.count()
        max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
        n_values = [layer.spt_n for layer in soil_layers if layer.spt_n is not None]
        min_n_value = min(n_values) if n_values else None
        max_n_value = max(n_values) if n_values else None
        avg_n_value = sum(n_values) / len(n_values) if n_values else None
        
        # åœŸå£¤é¡å‹åˆ†å¸ƒ
        soil_types = list(set([layer.uscs for layer in soil_layers if layer.uscs]))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
        has_analysis = AnalysisResult.objects.filter(soil_layer__borehole=borehole).exists()
        analysis_methods = list(set(AnalysisResult.objects.filter(
            soil_layer__borehole=borehole
        ).values_list('analysis_method', flat=True)))
        
        borehole_stats.append({
            'borehole': borehole,
            'total_layers': total_layers,
            'max_depth': max_depth,
            'min_n_value': min_n_value,
            'max_n_value': max_n_value,
            'avg_n_value': avg_n_value,
            'soil_types': soil_types,
            'has_analysis': has_analysis,
            'analysis_methods': analysis_methods,
        })
    
    # åˆ†é 
    from django.core.paginator import Paginator
    paginator = Paginator(borehole_stats, 10)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'project': project,
        'page_obj': page_obj,
        'search_query': search_query,
        'total_boreholes': boreholes.count(),
    }
    
    return render(request, 'liquefaction/borehole_data.html', context)


@login_required
def borehole_detail(request, pk, borehole_id):
    """å–®å€‹é‘½å­”è©³ç´°æ•¸æ“šè¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    borehole = get_object_or_404(BoreholeData, project=project, borehole_id=borehole_id)
    
    # å–å¾—åœŸå±¤æ•¸æ“š
    soil_layers = SoilLayer.objects.filter(borehole=borehole).order_by('top_depth')
    
    # å–å¾—åˆ†æçµæœï¼ˆå¦‚æœæœ‰ï¼‰
    analysis_results = {}
    for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
        results = AnalysisResult.objects.filter(
            soil_layer__borehole=borehole,
            analysis_method=method_code
        ).order_by('soil_layer__top_depth')
        
        if results.exists():
            analysis_results[method_code] = {
                'name': method_name,
                'results': results
            }
    
    # è¨ˆç®—é‘½å­”çµ±è¨ˆ
    total_layers = soil_layers.count()
    max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
    
    # Nå€¼çµ±è¨ˆ
    n_values = [layer.spt_n for layer in soil_layers if layer.spt_n is not None]
    n_stats = {
        'count': len(n_values),
        'min': min(n_values) if n_values else None,
        'max': max(n_values) if n_values else None,
        'avg': sum(n_values) / len(n_values) if n_values else None,
    }
    
    context = {
        'project': project,
        'borehole': borehole,
        'soil_layers': soil_layers,
        'analysis_results': analysis_results,
        'total_layers': total_layers,
        'max_depth': max_depth,
        'n_stats': n_stats,
    }
    
    return render(request, 'liquefaction/borehole_detail.html', context)

# åœ¨ views.py ä¸­åŠ å…¥ä»¥ä¸‹å‡½æ•¸

@login_required
def download_analysis_outputs(request, pk):
    """ä¸‹è¼‰å°ˆæ¡ˆçš„åˆ†æè¼¸å‡ºè³‡æ–™å¤¾"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        import tempfile
        import zipfile
        import shutil
        import glob
        from datetime import datetime
        from django.http import FileResponse, Http404
        from django.conf import settings
        
        # å°‹æ‰¾å°ˆæ¡ˆçš„è¼¸å‡ºç›®éŒ„
        output_dirs = _find_project_output_directories(project)
        
        if not output_dirs:
            messages.error(request, 'æ‰¾ä¸åˆ°åˆ†æè¼¸å‡ºæª”æ¡ˆ')
            return redirect('liquefaction:results', pk=project.pk)
        
        # å‰µå»ºè‡¨æ™‚ZIPæª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            temp_zip_path = temp_zip.name
        
        try:
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                total_files = 0
                
                for output_dir in output_dirs:
                    if os.path.exists(output_dir):
                        print(f"æ­£åœ¨æ‰“åŒ…ç›®éŒ„ï¼š{output_dir}")
                        
                        # å–å¾—ç›®éŒ„åç¨±ä½œç‚ºZIPå…§çš„æ ¹ç›®éŒ„
                        dir_name = os.path.basename(output_dir)
                        
                        # éæ­¸æ·»åŠ ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
                        for root, dirs, files in os.walk(output_dir):
                            for file in files:
                                file_path = os.path.join(root, file)
                                # è¨ˆç®—åœ¨ZIPä¸­çš„ç›¸å°è·¯å¾‘
                                arcname = os.path.relpath(file_path, os.path.dirname(output_dir))
                                zipf.write(file_path, arcname)
                                total_files += 1
                                print(f"  æ·»åŠ æª”æ¡ˆï¼š{arcname}")
                
                if total_files == 0:
                    messages.warning(request, 'åˆ†æè¼¸å‡ºç›®éŒ„ä¸­æ²’æœ‰æª”æ¡ˆ')
                    os.unlink(temp_zip_path)
                    return redirect('liquefaction:results', pk=project.pk)
                
                print(f"ç¸½å…±æ‰“åŒ…äº† {total_files} å€‹æª”æ¡ˆ")
            
            # ç”Ÿæˆä¸‹è¼‰æª”å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"{project.name}_åˆ†æè¼¸å‡º_{timestamp}.zip"
            
            # è¿”å›æª”æ¡ˆéŸ¿æ‡‰
            response = FileResponse(
                open(temp_zip_path, 'rb'),
                as_attachment=True,
                filename=download_filename
            )
            response['Content-Type'] = 'application/zip'
            
            # è¨»å†Šæ¸…ç†å‡½æ•¸ï¼ˆç•¶éŸ¿æ‡‰å®Œæˆå¾Œåˆªé™¤è‡¨æ™‚æª”æ¡ˆï¼‰
            def cleanup_temp_file():
                try:
                    os.unlink(temp_zip_path)
                    print(f"å·²æ¸…ç†è‡¨æ™‚æª”æ¡ˆï¼š{temp_zip_path}")
                except:
                    pass
            
            # é€™è£¡æˆ‘å€‘ä¸èƒ½ç›´æ¥æ¸…ç†ï¼Œå› ç‚ºæª”æ¡ˆé‚„åœ¨ä½¿ç”¨ä¸­
            # å¯ä»¥è€ƒæ…®ä½¿ç”¨å¾Œå°ä»»å‹™ä¾†æ¸…ç†ï¼Œæˆ–è€…ä¾è³´ç³»çµ±çš„è‡¨æ™‚æª”æ¡ˆæ¸…ç†
            
            return response
            
        except Exception as e:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e
            
    except Exception as e:
        messages.error(request, f'ä¸‹è¼‰åˆ†æè¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)



def _find_project_output_directories(project):
    """ç°¡å–®ç‰ˆæœ¬ - åŸºæ–¼ç›®éŒ„çµæ§‹æœå°‹"""
    import glob
    from django.conf import settings
    
    output_dirs = []
    
    try:
        analysis_output_root = getattr(settings, 'ANALYSIS_OUTPUT_ROOT', 
                                      os.path.join(settings.MEDIA_ROOT, 'analysis_outputs'))
        
        print(f"ğŸ” æœå°‹æ ¹ç›®éŒ„ï¼š{analysis_output_root}")
        
        if not os.path.exists(analysis_output_root):
            print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨ï¼š{analysis_output_root}")
            return []
        
        # å–å¾—å°ˆæ¡ˆIDçš„å‰8ä½ï¼ˆå¾æˆªåœ–çœ‹ï¼Œè³‡æ–™å¤¾åç¨±ä»¥æ­¤é–‹é ­ï¼‰
        project_id_short = str(project.id)[:8]
        print(f"ğŸ” æœå°‹å°ˆæ¡ˆIDï¼š{project_id_short}")
        
        # åˆ—å‡ºæ‰€æœ‰å­ç›®éŒ„ï¼Œå°‹æ‰¾ä»¥å°ˆæ¡ˆIDé–‹é ­çš„ç›®éŒ„
        try:
            for item in os.listdir(analysis_output_root):
                item_path = os.path.join(analysis_output_root, item)
                
                if os.path.isdir(item_path):
                    print(f"ğŸ“ æª¢æŸ¥ç›®éŒ„ï¼š{item}")
                    
                    # æª¢æŸ¥ç›®éŒ„åæ˜¯å¦åŒ…å«å°ˆæ¡ˆID
                    if project_id_short in item:
                        output_dirs.append(item_path)
                        print(f"âœ… æ‰¾åˆ°åŒ¹é…ç›®éŒ„ï¼š{item}")
                    
                    # ä¹Ÿæª¢æŸ¥æ˜¯å¦åŒ…å«å°ˆæ¡ˆåç¨±ï¼ˆå®‰å…¨çš„æƒ…æ³ä¸‹ï¼‰
                    elif len(project.name) > 3:
                        safe_name = "".join(c for c in project.name if c.isalnum() or c in ('-', '_'))
                        if safe_name and safe_name in item:
                            output_dirs.append(item_path)
                            print(f"âœ… æ‰¾åˆ°å°ˆæ¡ˆåç¨±åŒ¹é…ç›®éŒ„ï¼š{item}")
            
        except Exception as e:
            print(f"âŒ åˆ—å‡ºç›®éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        
        print(f"ğŸ¯ æ‰¾åˆ° {len(output_dirs)} å€‹ç›®éŒ„")
        return output_dirs
        
    except Exception as e:
        print(f"âŒ æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return []

# åŒæ™‚ç°¡åŒ– get_analysis_outputs_info å‡½æ•¸

@login_required 
def get_analysis_outputs_info(request, pk):
    """ç°¡åŒ–ç‰ˆæœ¬çš„è¼¸å‡ºè³‡è¨Šç²å–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        print(f"ğŸ” æŸ¥æ‰¾å°ˆæ¡ˆè¼¸å‡ºï¼š{project.name} (ID: {str(project.id)[:8]})")
        
        output_dirs = _find_project_output_directories(project)
        
        output_info = {
            'has_outputs': len(output_dirs) > 0,
            'directories': [],
            'total_files': 0,
            'total_size': 0,
            'debug_info': {
                'project_id': str(project.id)[:8] + "...",
                'project_name': project.name,
                'found_dirs': len(output_dirs),
            }
        }
        
        for output_dir in output_dirs:
            if os.path.exists(output_dir):
                dir_info = {
                    'path': output_dir,
                    'name': os.path.basename(output_dir),
                    'relative_path': os.path.basename(output_dir),  # ç”¨æ–¼ä¸‹è¼‰
                    'files': [],
                    'file_count': 0,
                    'size': 0
                }
                
                # åˆ—å‡ºç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
                try:
                    for root, dirs, files in os.walk(output_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            relative_path = os.path.relpath(file_path, output_dir)
                            
                            try:
                                file_size = os.path.getsize(file_path)
                                file_modified = os.path.getmtime(file_path)
                                
                                dir_info['files'].append({
                                    'name': file,
                                    'path': relative_path,
                                    'size': file_size,
                                    'modified': datetime.fromtimestamp(file_modified).strftime('%Y-%m-%d %H:%M:%S')
                                })
                                
                                dir_info['size'] += file_size
                                dir_info['file_count'] += 1
                                
                            except OSError:
                                continue
                
                except Exception as e:
                    print(f"âŒ è™•ç†ç›®éŒ„ {output_dir} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    continue
                
                if dir_info['file_count'] > 0:
                    output_info['directories'].append(dir_info)
                    output_info['total_files'] += dir_info['file_count']
                    output_info['total_size'] += dir_info['size']
                    print(f"âœ… ç›®éŒ„ {dir_info['name']} åŒ…å« {dir_info['file_count']} å€‹æª”æ¡ˆ")
        
        print(f"ğŸ¯ ç¸½è¨ˆï¼š{output_info['total_files']} å€‹æª”æ¡ˆ")
        
        return JsonResponse(output_info)
        
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼š{e}")
        return JsonResponse({
            'error': str(e),
            'has_outputs': False,
            'debug_info': {
                'project_id': str(project.id)[:8] + "...",
                'project_name': project.name,
                'error_details': str(e)
            }
        })

@login_required
def download_analysis_outputs(request, pk):
    """ä¸‹è¼‰å°ˆæ¡ˆçš„åˆ†æè¼¸å‡ºè³‡æ–™å¤¾ - æ”¹é€²ç‰ˆæœ¬"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        import tempfile
        import zipfile
        from datetime import datetime
        from django.http import FileResponse
        
        print(f"ğŸ” é–‹å§‹æº–å‚™ä¸‹è¼‰å°ˆæ¡ˆè¼¸å‡ºï¼š{project.name}")
        
        # å°‹æ‰¾å°ˆæ¡ˆçš„è¼¸å‡ºç›®éŒ„
        output_dirs = _find_project_output_directories(project)
        
        if not output_dirs:
            messages.error(request, 'æ‰¾ä¸åˆ°åˆ†æè¼¸å‡ºæª”æ¡ˆã€‚è«‹æª¢æŸ¥åˆ†ææ˜¯å¦å·²å®Œæˆï¼Œæˆ–æª”æ¡ˆæ˜¯å¦å·²è¢«æ¸…ç†ã€‚')
            return redirect('liquefaction:results', pk=project.pk)
        
        # å‰µå»ºè‡¨æ™‚ZIPæª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            temp_zip_path = temp_zip.name
        
        try:
            total_files = 0
            
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for output_dir in output_dirs:
                    if os.path.exists(output_dir):
                        print(f"ğŸ“ æ­£åœ¨æ‰“åŒ…ç›®éŒ„ï¼š{output_dir}")
                        
                        # å–å¾—ç›®éŒ„åç¨±ä½œç‚ºZIPå…§çš„æ ¹ç›®éŒ„
                        dir_name = os.path.basename(output_dir) if output_dir != os.path.dirname(output_dir) else "analysis_outputs"
                        
                        # éæ­¸æ·»åŠ ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
                        for root, dirs, files in os.walk(output_dir):
                            for file in files:
                                file_path = os.path.join(root, file)
                                
                                # è¨ˆç®—åœ¨ZIPä¸­çš„ç›¸å°è·¯å¾‘
                                if root == output_dir:
                                    # æª”æ¡ˆåœ¨æ ¹ç›®éŒ„
                                    arcname = os.path.join(dir_name, file)
                                else:
                                    # æª”æ¡ˆåœ¨å­ç›®éŒ„
                                    rel_path = os.path.relpath(file_path, output_dir)
                                    arcname = os.path.join(dir_name, rel_path)
                                
                                zipf.write(file_path, arcname)
                                total_files += 1
                                print(f"ğŸ“„ æ·»åŠ æª”æ¡ˆï¼š{arcname}")
            
            if total_files == 0:
                messages.warning(request, 'åˆ†æè¼¸å‡ºç›®éŒ„ä¸­æ²’æœ‰æª”æ¡ˆ')
                os.unlink(temp_zip_path)
                return redirect('liquefaction:results', pk=project.pk)
            
            print(f"âœ… ç¸½å…±æ‰“åŒ…äº† {total_files} å€‹æª”æ¡ˆ")
            
            # ç”Ÿæˆä¸‹è¼‰æª”å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"{project.name}_åˆ†æè¼¸å‡º_{timestamp}.zip"
            
            # è¿”å›æª”æ¡ˆéŸ¿æ‡‰
            response = FileResponse(
                open(temp_zip_path, 'rb'),
                as_attachment=True,
                filename=download_filename
            )
            response['Content-Type'] = 'application/zip'
            
            print(f"ğŸ¯ é–‹å§‹ä¸‹è¼‰ï¼š{download_filename}")
            return response
            
        except Exception as e:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e
            
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰åˆ†æè¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        print(traceback.format_exc())
        
        messages.error(request, f'ä¸‹è¼‰åˆ†æè¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)

def _format_file_size(size_bytes):
    """æ ¼å¼åŒ–æª”æ¡ˆå¤§å°"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"


@login_required
def download_borehole_report(request, pk, borehole_id):
    """ä¸‹è¼‰å–®å€‹é‘½å­”çš„å®Œæ•´å ±è¡¨è³‡æ–™å¤¾"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    borehole = get_object_or_404(BoreholeData, project=project, borehole_id=borehole_id)
    
    try:
        import tempfile
        import zipfile
        from datetime import datetime
        from django.http import FileResponse
        
        print(f"ğŸ” é–‹å§‹ç”Ÿæˆé‘½å­” {borehole_id} çš„å ±è¡¨...")
        
        # ç²å–è©²é‘½å­”çš„åˆ†æçµæœæ•¸æ“š
        soil_layers = SoilLayer.objects.filter(borehole=borehole).prefetch_related('analysis_result')
        
        if not soil_layers.exists():
            messages.error(request, f'é‘½å­” {borehole_id} æ²’æœ‰åœŸå±¤æ•¸æ“š')
            return redirect('liquefaction:borehole_detail', pk=project.pk, borehole_id=borehole_id)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
        analysis_results = AnalysisResult.objects.filter(soil_layer__borehole=borehole)
        if not analysis_results.exists():
            messages.error(request, f'é‘½å­” {borehole_id} æ²’æœ‰åˆ†æçµæœï¼Œè«‹å…ˆé€²è¡Œæ¶²åŒ–åˆ†æ')
            return redirect('liquefaction:borehole_detail', pk=project.pk, borehole_id=borehole_id)
        
        # è½‰æ›æ•¸æ“šç‚ºDataFrameæ ¼å¼ï¼ˆé¡ä¼¼HBFè¼¸å‡ºæ ¼å¼ï¼‰
        borehole_data = _convert_borehole_to_dataframe(borehole, soil_layers, analysis_results)
        
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„
        with tempfile.TemporaryDirectory() as temp_dir:
            borehole_dir = os.path.join(temp_dir, f"é‘½å­”_{borehole_id}")
            os.makedirs(borehole_dir)
            
            # ç”Ÿæˆå ±è¡¨æª”æ¡ˆ
            report_files = _generate_borehole_reports(borehole_data, borehole_id, borehole_dir)
            
            if not report_files:
                messages.error(request, f'ç”Ÿæˆé‘½å­” {borehole_id} å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤')
                return redirect('liquefaction:borehole_detail', pk=project.pk, borehole_id=borehole_id)
            
            # å‰µå»ºZIPæª”æ¡ˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"é‘½å­”_{borehole_id}_å ±è¡¨_{timestamp}.zip"
            
            # å‰µå»ºè‡¨æ™‚ZIPæª”æ¡ˆ
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
                temp_zip_path = temp_zip.name
            
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # éæ­·é‘½å­”ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
                for root, dirs, files in os.walk(borehole_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, temp_dir)
                        zipf.write(file_path, arcname)
                        print(f"ğŸ“„ æ·»åŠ æª”æ¡ˆï¼š{arcname}")
            
            print(f"âœ… å ±è¡¨ZIPæª”æ¡ˆå‰µå»ºå®Œæˆï¼š{zip_filename}")
            
            # è¿”å›æª”æ¡ˆéŸ¿æ‡‰
            response = FileResponse(
                open(temp_zip_path, 'rb'),
                as_attachment=True,
                filename=zip_filename
            )
            response['Content-Type'] = 'application/zip'
            
            # è¨»å†Šæ¸…ç†å‡½æ•¸ï¼ˆç•¶éŸ¿æ‡‰å®Œæˆå¾Œåˆªé™¤è‡¨æ™‚æª”æ¡ˆï¼‰
            # æ³¨æ„ï¼šé€™è£¡éœ€è¦å°å¿ƒè™•ç†è‡¨æ™‚æª”æ¡ˆæ¸…ç†
            
            return response
            
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰é‘½å­”å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        print(traceback.format_exc())
        
        messages.error(request, f'ä¸‹è¼‰é‘½å­” {borehole_id} å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:borehole_detail', pk=project.pk, borehole_id=borehole_id)


def _convert_borehole_to_dataframe(borehole, soil_layers, analysis_results):
    """å°‡æ•¸æ“šåº«ä¸­çš„é‘½å­”æ•¸æ“šè½‰æ›ç‚ºDataFrameæ ¼å¼"""
    data = []
    
    # æŒ‰åˆ†ææ–¹æ³•åˆ†çµ„
    results_by_method = {}
    for result in analysis_results:
        method = result.analysis_method
        if method not in results_by_method:
            results_by_method[method] = {}
        results_by_method[method][result.soil_layer.id] = result
    
    for layer in soil_layers:
        # åŸºæœ¬åœŸå±¤ä¿¡æ¯
        base_row = {
            'é‘½å­”ç·¨è™Ÿ': borehole.borehole_id,
            'TWD97_X': borehole.twd97_x,
            'TWD97_Y': borehole.twd97_y,
            'ä¸Šé™æ·±åº¦(å…¬å°º)': layer.top_depth,
            'ä¸‹é™æ·±åº¦(å…¬å°º)': layer.bottom_depth,
            'çµ±ä¸€åœŸå£¤åˆ†é¡': layer.uscs or '',
            'N': layer.spt_n,
            'å¡‘æ€§æŒ‡æ•¸(%)': layer.plastic_index,
            'ç´°æ–™(%)': layer.fines_content,
            'çµ±é«”å–®ä½é‡(t/m3)': layer.unit_weight,
            'water_depth(m)': borehole.water_depth,
            'é‘½å­”åœ°è¡¨é«˜ç¨‹': borehole.surface_elevation,
        }
        
        # ç‚ºæ¯å€‹åˆ†ææ–¹æ³•å‰µå»ºä¸€è¡Œæ•¸æ“š
        for method, results in results_by_method.items():
            if layer.id in results:
                result = results[layer.id]
                row = base_row.copy()
                row.update({
                    'åˆ†ææ–¹æ³•': method,
                    'åœŸå±¤æ·±åº¦': result.analysis_depth,
                    'ç´¯è¨ˆsigmav': result.sigma_v,
                    'sigma_v_CSR': result.sigma_v_csr,
                    'N1_60cs': result.n1_60cs,
                    'CRR_7_5': result.crr_7_5,
                    'FS_Design': result.fs_design,
                    'FS_MidEq': result.fs_mid,
                    'FS_MaxEq': result.fs_max,
                    'LPI_Design': result.lpi_design,
                    'LPI_MidEq': result.lpi_mid,
                    'LPI_MaxEq': result.lpi_max,
                    'Vs': result.vs,
                    # æ·»åŠ æ›´å¤šéœ€è¦çš„æ¬„ä½...
                })
                data.append(row)
    
    return pd.DataFrame(data)


def _generate_borehole_reports(borehole_data, borehole_id, output_dir):
    """ç”Ÿæˆå–®å€‹é‘½å­”çš„æ‰€æœ‰å ±è¡¨æª”æ¡ˆ"""
    generated_files = []
    
    try:
        # 1. ç”ŸæˆCSVåŸå§‹æ•¸æ“š
        csv_filename = f"{borehole_id}_åŸå§‹è³‡æ–™.csv"
        csv_path = os.path.join(output_dir, csv_filename)
        borehole_data.to_csv(csv_path, index=False, encoding='utf-8-sig')
        generated_files.append(csv_path)
        print(f"âœ… å·²ç”ŸæˆCSVï¼š{csv_filename}")
        
        # 2. ç”ŸæˆExcelå ±è¡¨ï¼ˆå¦‚æœreportæ¨¡çµ„å¯ç”¨ï¼‰
        try:
            from liquefaction.services.report import create_liquefaction_excel_from_dataframe
            excel_filename = f"{borehole_id}_æ¶²åŒ–åˆ†æå ±è¡¨.xlsx"
            excel_path = os.path.join(output_dir, excel_filename)
            
            # åªä½¿ç”¨ç¬¬ä¸€å€‹åˆ†ææ–¹æ³•çš„æ•¸æ“šä¾†ç”ŸæˆExcelï¼ˆé¿å…é‡è¤‡ï¼‰
            first_method_data = borehole_data[borehole_data['åˆ†ææ–¹æ³•'] == borehole_data['åˆ†ææ–¹æ³•'].iloc[0]]
            create_liquefaction_excel_from_dataframe(first_method_data, excel_path)
            generated_files.append(excel_path)
            print(f"âœ… å·²ç”ŸæˆExcelï¼š{excel_filename}")
            
        except Exception as e:
            print(f"âš ï¸ Excelå ±è¡¨ç”Ÿæˆå¤±æ•—ï¼š{e}")
        
        # 3. ç”Ÿæˆåœ–è¡¨ï¼ˆå¦‚æœreportæ¨¡çµ„å¯ç”¨ï¼‰
        try:
            from liquefaction.services.report import LiquefactionChartGenerator
            
            chart_generator = LiquefactionChartGenerator(
                n_chart_size=(10, 8),
                fs_chart_size=(12, 8),
                soil_chart_size=(4, 10)
            )
            
            # ä½¿ç”¨ç¬¬ä¸€å€‹åˆ†ææ–¹æ³•çš„æ•¸æ“šä¾†ç”Ÿæˆåœ–è¡¨
            first_method_data = borehole_data[borehole_data['åˆ†ææ–¹æ³•'] == borehole_data['åˆ†ææ–¹æ³•'].iloc[0]]
            
            # Nå€¼åœ–è¡¨
            try:
                chart1 = chart_generator.generate_depth_n_chart(first_method_data, borehole_id, output_dir)
                if chart1:
                    generated_files.append(chart1)
                    print(f"âœ… å·²ç”ŸæˆNå€¼åœ–è¡¨")
            except Exception as e:
                print(f"âš ï¸ Nå€¼åœ–è¡¨ç”Ÿæˆå¤±æ•—ï¼š{e}")
            
            # FSåœ–è¡¨
            try:
                chart2 = chart_generator.generate_depth_fs_chart(first_method_data, borehole_id, output_dir)
                if chart2:
                    generated_files.append(chart2)
                    print(f"âœ… å·²ç”ŸæˆFSåœ–è¡¨")
            except Exception as e:
                print(f"âš ï¸ FSåœ–è¡¨ç”Ÿæˆå¤±æ•—ï¼š{e}")
            
            # åœŸå£¤æŸ±ç‹€åœ–
            try:
                chart3 = chart_generator.generate_soil_column_chart(first_method_data, borehole_id, output_dir)
                if chart3:
                    generated_files.append(chart3)
                    print(f"âœ… å·²ç”ŸæˆåœŸå£¤æŸ±ç‹€åœ–")
            except Exception as e:
                print(f"âš ï¸ åœŸå£¤æŸ±ç‹€åœ–ç”Ÿæˆå¤±æ•—ï¼š{e}")
                
        except Exception as e:
            print(f"âš ï¸ åœ–è¡¨ç”Ÿæˆæ¨¡çµ„è¼‰å…¥å¤±æ•—ï¼š{e}")
        
        # 4. ç”Ÿæˆæ‘˜è¦æ–‡ä»¶
        try:
            summary_filename = f"{borehole_id}_æ¶²åŒ–åˆ†ææ‘˜è¦.txt"
            summary_path = os.path.join(output_dir, summary_filename)
            
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(f"é‘½å­” {borehole_id} æ¶²åŒ–åˆ†ææ‘˜è¦\n")
                f.write("="*50 + "\n\n")
                
                # åŸºæœ¬è³‡è¨Š
                first_row = borehole_data.iloc[0]
                f.write(f"åº§æ¨™ (TWD97): ({first_row.get('TWD97_X', '')}, {first_row.get('TWD97_Y', '')})\n")
                f.write(f"åˆ†ææ–¹æ³•: {', '.join(borehole_data['åˆ†ææ–¹æ³•'].unique())}\n")
                f.write(f"åˆ†æå±¤æ•¸: {len(borehole_data['é‘½å­”ç·¨è™Ÿ'].unique()) if 'é‘½å­”ç·¨è™Ÿ' in borehole_data.columns else len(borehole_data) // len(borehole_data['åˆ†ææ–¹æ³•'].unique())}\n\n")
                
                # å„æƒ…å¢ƒLPIç¸½è¨ˆï¼ˆä»¥ç¬¬ä¸€å€‹åˆ†ææ–¹æ³•ç‚ºä¾‹ï¼‰
                first_method_data = borehole_data[borehole_data['åˆ†ææ–¹æ³•'] == borehole_data['åˆ†ææ–¹æ³•'].iloc[0]]
                for scenario in ['Design', 'MidEq', 'MaxEq']:
                    lpi_col = f'LPI_{scenario}'
                    if lpi_col in first_method_data.columns:
                        total_lpi = sum(float(x) for x in first_method_data[lpi_col] if x != '-' and pd.notna(x))
                        f.write(f"{scenario} æƒ…å¢ƒç¸½LPI: {total_lpi:.3f}\n")
            
            generated_files.append(summary_path)
            print(f"âœ… å·²ç”Ÿæˆæ‘˜è¦ï¼š{summary_filename}")
            
        except Exception as e:
            print(f"âš ï¸ æ‘˜è¦æª”æ¡ˆç”Ÿæˆå¤±æ•—ï¼š{e}")
        
        return generated_files
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆé‘½å­”å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return []
    


@login_required
def download_single_directory(request, pk, dir_name):
    """ä¸‹è¼‰å–®ä¸€è³‡æ–™å¤¾ - ç°¡åŒ–ç‰ˆæœ¬"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        import tempfile
        import zipfile
        import urllib.parse
        from datetime import datetime
        from django.http import FileResponse
        from django.conf import settings
        
        # è§£ç¢¼ç›®éŒ„åç¨±
        decoded_dir_name = urllib.parse.unquote(dir_name)
        print(f"ğŸ” è«‹æ±‚ä¸‹è¼‰ç›®éŒ„ï¼š{decoded_dir_name}")
        
        # å»ºæ§‹å®Œæ•´è·¯å¾‘
        analysis_output_root = getattr(settings, 'ANALYSIS_OUTPUT_ROOT', 
                                      os.path.join(settings.MEDIA_ROOT, 'analysis_outputs'))
        target_dir = os.path.join(analysis_output_root, decoded_dir_name)
        
        if not os.path.exists(target_dir):
            messages.error(request, f'æ‰¾ä¸åˆ°è³‡æ–™å¤¾ï¼š{decoded_dir_name}')
            return redirect('liquefaction:results', pk=project.pk)
        
        # åŸºæœ¬å®‰å…¨æª¢æŸ¥ï¼šç¢ºä¿ç›®éŒ„åŒ…å«å°ˆæ¡ˆID
        project_id_short = str(project.id)[:8]
        if project_id_short not in decoded_dir_name:
            messages.error(request, 'è©²è³‡æ–™å¤¾ä¸å±¬æ–¼ç•¶å‰å°ˆæ¡ˆ')
            return redirect('liquefaction:results', pk=project.pk)
        
        print(f"ğŸ“ æº–å‚™æ‰“åŒ…ï¼š{target_dir}")
        
        # å‰µå»ºZIPæª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            temp_zip_path = temp_zip.name
        
        total_files = 0
        
        with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(target_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    
                    # åœ¨ZIPä¸­çš„è·¯å¾‘
                    if root == target_dir:
                        arcname = os.path.join(decoded_dir_name, file)
                    else:
                        rel_path = os.path.relpath(file_path, target_dir)
                        arcname = os.path.join(decoded_dir_name, rel_path)
                    
                    zipf.write(file_path, arcname)
                    total_files += 1
        
        if total_files == 0:
            messages.warning(request, f'è³‡æ–™å¤¾ {decoded_dir_name} ä¸­æ²’æœ‰æª”æ¡ˆ')
            os.unlink(temp_zip_path)
            return redirect('liquefaction:results', pk=project.pk)
        
        # ç”Ÿæˆä¸‹è¼‰æª”å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        download_filename = f"{project.name}_{decoded_dir_name}_{timestamp}.zip"
        
        response = FileResponse(
            open(temp_zip_path, 'rb'),
            as_attachment=True,
            filename=download_filename
        )
        response['Content-Type'] = 'application/zip'
        
        print(f"ğŸ¯ é–‹å§‹ä¸‹è¼‰ï¼š{download_filename} ({total_files} å€‹æª”æ¡ˆ)")
        return response
        
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰éŒ¯èª¤ï¼š{e}")
        messages.error(request, f'ä¸‹è¼‰è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)