from django.shortcuts import render, get_object_or_404, redirect
from django.contrib.auth.decorators import login_required
from django.contrib import messages
from django.http import JsonResponse, HttpResponse
from django.core.paginator import Paginator
from django.db.models import Q
from django.utils import timezone
import json
import os
from .models import AnalysisProject, BoreholeData, SoilLayer, AnalysisResult, Project
from django.http import FileResponse, Http404
from django.contrib.auth.decorators import login_required
from datetime import datetime
import glob
from django.conf import settings

def project_list(request):
    projects = Project.objects.all().order_by('-created_at')
    return render(request, 'liquefaction/project_list.html', {'projects': projects})

def index(request):
    """é¦–é è¦–åœ–"""
    context = {
        'title': 'åœŸå£¤æ¶²åŒ–åˆ†æç³»çµ±',
        'description': 'åœŸå£¤æ¶²åŒ–æ½›èƒ½åˆ†æå·¥å…·',
    }
    
    if request.user.is_authenticated:
        # å¦‚æœç”¨æˆ¶å·²ç™»å…¥ï¼Œé¡¯ç¤ºæœ€è¿‘çš„å°ˆæ¡ˆ
        recent_projects = AnalysisProject.objects.filter(
            user=request.user
        ).order_by('-updated_at')[:5]
        context['recent_projects'] = recent_projects
        
        # çµ±è¨ˆè³‡æ–™
        context['stats'] = {
            'total_projects': AnalysisProject.objects.filter(user=request.user).count(),
            'completed_projects': AnalysisProject.objects.filter(
                user=request.user, status='completed'
            ).count(),
            'processing_projects': AnalysisProject.objects.filter(
                user=request.user, status='processing'
            ).count(),
        }
    
    return render(request, 'liquefaction/index.html', context)


@login_required
def project_list(request):
    """å°ˆæ¡ˆåˆ—è¡¨è¦–åœ–"""
    projects = AnalysisProject.objects.filter(user=request.user).order_by('-updated_at')
    
    # æœç´¢åŠŸèƒ½
    search_query = request.GET.get('search', '')
    if search_query:
        projects = projects.filter(
            Q(name__icontains=search_query) | 
            Q(description__icontains=search_query)
        )
    
    # ç‹€æ…‹ç¯©é¸
    status_filter = request.GET.get('status', '')
    if status_filter:
        projects = projects.filter(status=status_filter)
    
    # åˆ†é 
    paginator = Paginator(projects, 10)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'page_obj': page_obj,
        'search_query': search_query,
        'status_filter': status_filter,
        'status_choices': AnalysisProject.STATUS_CHOICES,
    }
    
    return render(request, 'liquefaction/project_list.html', context)


@login_required
def project_create(request):
    """å‰µå»ºæ–°å°ˆæ¡ˆ"""
    if request.method == 'POST':
        try:
            # è™•ç†è¡¨å–®æ•¸æ“š
            name = request.POST.get('name')
            description = request.POST.get('description', '')
            em_value = float(request.POST.get('em_value', 72))
            unit_weight_unit = request.POST.get('unit_weight_unit', 't/m3')
            use_fault_data = request.POST.get('use_fault_data') == 'on'
            
            # å‰µå»ºå°ˆæ¡ˆ
            project = AnalysisProject.objects.create(
                user=request.user,
                name=name,
                analysis_method='HBF',
                description=description,
                em_value=em_value,
                unit_weight_unit=unit_weight_unit,
                use_fault_data=use_fault_data,
            )
            
            # è™•ç†æª”æ¡ˆä¸Šå‚³ä¸¦ç«‹å³è™•ç†
            csv_processed = False

            if 'source_file' in request.FILES:
                project.source_file = request.FILES['source_file']
                project.save()  # å…ˆä¿å­˜æª”æ¡ˆè·¯å¾‘
                
                # ç«‹å³è™•ç† CSV æª”æ¡ˆ
                from .services.data_import_service import DataImportService
                import_service = DataImportService(project)

                import_result = import_service.import_csv_data(request.FILES['source_file'],
                                                               unit_weight_unit=unit_weight_unit )
                
                if import_result['success']:
                    summary = import_result['summary']
                    messages.success(
                        request, 
                        f'å°ˆæ¡ˆ "{name}" å‰µå»ºæˆåŠŸï¼å·²åŒ¯å…¥ {summary["imported_boreholes"]} å€‹é‘½å­”ï¼Œ{summary["imported_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in import_result.get('warnings', []):
                        messages.warning(request, f'è­¦å‘Šï¼š{warning}')
                        
                    csv_processed = True
                else:
                    messages.error(request, f'CSV æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{import_result["error"]}')
                    project.status = 'error'
                    project.error_message = import_result["error"]

            if 'fault_shapefile' in request.FILES:
                project.fault_shapefile = request.FILES['fault_shapefile']

            project.save()

            if not csv_processed:
                messages.success(request, f'å°ˆæ¡ˆ "{name}" å‰µå»ºæˆåŠŸï¼è«‹ä¸Šå‚³ CSV æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚')
            
            messages.success(request, f'å°ˆæ¡ˆ "{name}" å‰µå»ºæˆåŠŸï¼')
            return redirect('liquefaction:project_detail', pk=project.pk)
            
        except Exception as e:
            messages.error(request, f'å‰µå»ºå°ˆæ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
    
    context = {
        'unit_weight_units': AnalysisProject._meta.get_field('unit_weight_unit').choices,
    }
    
    return render(request, 'liquefaction/project_create.html', context)


@login_required
def project_detail(request, pk):
    """å°ˆæ¡ˆè©³æƒ…è¦–åœ– - æ–°å¢å¿«é€Ÿåˆ†æåŠŸèƒ½"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # è™•ç†å¿«é€Ÿåˆ†æè«‹æ±‚
    if request.method == 'POST':
        selected_methods = request.POST.getlist('analysis_methods')
        if not selected_methods:
            messages.error(request, 'è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®åˆ†ææ–¹æ³•')
            return redirect('liquefaction:project_detail', pk=project.pk)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
        boreholes_count = BoreholeData.objects.filter(project=project).count()
        if boreholes_count == 0:
            messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰é‘½å­”è³‡æ–™ï¼Œè«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆ')
            return redirect('liquefaction:project_detail', pk=project.pk)
        
        # åŸ·è¡Œåˆ†æ
        try:
            from .services.analysis_engine import LiquefactionAnalysisEngine
            
            total_success = 0
            total_errors = []
            
            for method in selected_methods:
                # æš«æ™‚æ›´æ–°å°ˆæ¡ˆçš„åˆ†ææ–¹æ³•
                original_method = project.analysis_method
                project.analysis_method = method
                project.save()
                
                # åŸ·è¡Œåˆ†æ
                analysis_engine = LiquefactionAnalysisEngine(project)
                analysis_result = analysis_engine.run_analysis()
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(request, f'{method} åˆ†æå®Œæˆï¼')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                
                # æ¢å¾©åŸå§‹åˆ†ææ–¹æ³•
                project.analysis_method = original_method
                project.save()
            
            if total_success > 0:
                project.status = 'completed'
                project.save()
                messages.success(request, f'åˆ†æå®Œæˆï¼æˆåŠŸå®Œæˆ {total_success} ç¨®æ–¹æ³•çš„åˆ†æ')
                return redirect('liquefaction:results', pk=project.pk)
            else:
                project.status = 'error'
                project.error_message = '; '.join(total_errors)
                project.save()
                
        except Exception as e:
            messages.error(request, f'åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
    
    # ç²å–é‘½å­”è³‡æ–™
    boreholes = BoreholeData.objects.filter(project=project).prefetch_related('soil_layers').order_by('borehole_id')
    
    # ç‚ºæ¯å€‹é‘½å­”è¨ˆç®—æœ€å¤§æ·±åº¦
    boreholes_with_stats = []
    for borehole in boreholes:
        soil_layers = borehole.soil_layers.all()
        max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
        
        borehole_data = {
            'borehole': borehole,
            'layers_count': soil_layers.count(),
            'max_depth': max_depth
        }
        boreholes_with_stats.append(borehole_data)
    
    # ç²å–åˆ†æçµæœçµ±è¨ˆ
    total_layers = SoilLayer.objects.filter(borehole__project=project).count()
    
    # çµ±è¨ˆå„æ–¹æ³•çš„åˆ†æçµæœ
    analysis_methods_stats = {}
    for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
        analyzed_count = AnalysisResult.objects.filter(
            soil_layer__borehole__project=project,
            analysis_method=method_code
        ).count()
        analysis_methods_stats[method_code] = {
            'name': method_name,
            'count': analyzed_count,
            'progress': (analyzed_count / total_layers * 100) if total_layers > 0 else 0
        }
    
    context = {
        'project': project,
        'boreholes': boreholes,
        'boreholes_with_stats': boreholes_with_stats,
        'total_layers': total_layers,
        'analysis_methods_stats': analysis_methods_stats,
        'available_methods': AnalysisProject._meta.get_field('analysis_method').choices,
    }
    
    return render(request, 'liquefaction/project_detail.html', context)



@login_required
def project_update(request, pk):
    """æ›´æ–°å°ˆæ¡ˆ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            project.name = request.POST.get('name', project.name)
            project.description = request.POST.get('description', project.description)
            project.analysis_method = request.POST.get('analysis_method', project.analysis_method)
            project.em_value = float(request.POST.get('em_value', project.em_value))
            project.unit_weight_unit = request.POST.get('unit_weight_unit', project.unit_weight_unit)
            project.use_fault_data = request.POST.get('use_fault_data') == 'on'
            
            # è™•ç†æ–°æª”æ¡ˆä¸Šå‚³
            if 'source_file' in request.FILES:
                project.source_file = request.FILES['source_file']
            
            if 'fault_shapefile' in request.FILES:
                project.fault_shapefile = request.FILES['fault_shapefile']
            
            project.save()
            
            messages.success(request, 'å°ˆæ¡ˆæ›´æ–°æˆåŠŸï¼')
            return redirect('liquefaction:project_detail', pk=project.pk)
            
        except Exception as e:
            messages.error(request, f'æ›´æ–°å°ˆæ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
    
    context = {
        'project': project,
        'analysis_methods': AnalysisProject._meta.get_field('analysis_method').choices,
        'unit_weight_units': AnalysisProject._meta.get_field('unit_weight_unit').choices,
    }
    
    return render(request, 'liquefaction/project_update.html', context)


@login_required
def project_delete(request, pk):
    """åˆªé™¤å°ˆæ¡ˆ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        project_name = project.name
        project.delete()
        messages.success(request, f'å°ˆæ¡ˆ "{project_name}" å·²æˆåŠŸåˆªé™¤ï¼')
        return redirect('liquefaction:project_list')
    
    return render(request, 'liquefaction/project_delete.html', {'project': project})



@login_required
def file_upload(request, pk):
    """æª”æ¡ˆä¸Šå‚³è™•ç†"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            if 'csv_file' not in request.FILES:
                messages.error(request, 'è«‹é¸æ“‡è¦ä¸Šå‚³çš„ CSV æª”æ¡ˆ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            csv_file = request.FILES['csv_file']
            
            # æª¢æŸ¥æª”æ¡ˆé¡å‹
            if not csv_file.name.endswith('.csv'):
                messages.error(request, 'è«‹ä¸Šå‚³ CSV æ ¼å¼çš„æª”æ¡ˆ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æª”æ¡ˆå¤§å° (é™åˆ¶ 10MB)
            if csv_file.size > 10 * 1024 * 1024:
                messages.error(request, 'æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é 10MB')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # ä½¿ç”¨ DataImportService åŒ¯å…¥è³‡æ–™
            from .services.data_import_service import DataImportService
            import_service = DataImportService(project)
            import_result = import_service.import_csv_data(
                csv_file,
                unit_weight_unit=project.unit_weight_unit)
            
            if import_result['success']:
                # åŒ¯å…¥æˆåŠŸ
                summary = import_result['summary']
                messages.success(
                    request, 
                    f'CSV æª”æ¡ˆä¸Šå‚³æˆåŠŸï¼å·²åŒ¯å…¥ {summary["imported_boreholes"]} å€‹é‘½å­”ï¼Œ{summary["imported_layers"]} å€‹åœŸå±¤ã€‚'
                )
                # æ–°å¢ï¼šé¡¯ç¤ºå–®ä½æª¢æ¸¬çµæœ
                if 'detected_unit' in import_result and import_result['detected_unit']:
                    if import_result.get('unit_consistency', True):
                        messages.info(request, f'âœ“ çµ±é«”å–®ä½é‡å–®ä½æª¢æ¸¬ï¼š{import_result["detected_unit"]}ï¼ˆèˆ‡å°ˆæ¡ˆè¨­å®šä¸€è‡´ï¼‰')
                    else:
                        messages.warning(request, f'âš ï¸ çµ±é«”å–®ä½é‡å–®ä½æª¢æ¸¬ï¼š{import_result["detected_unit"]}ï¼ˆèˆ‡å°ˆæ¡ˆè¨­å®š {project.unit_weight_unit} ä¸ä¸€è‡´ï¼‰')
                
                # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                for warning in import_result.get('warnings', []):
                    messages.warning(request, f'è­¦å‘Šï¼š{warning}')
                # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                for warning in import_result.get('warnings', []):
                    messages.warning(request, f'è­¦å‘Šï¼š{warning}')
                
                # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                for error in import_result.get('errors', []):
                    messages.error(request, f'éŒ¯èª¤ï¼š{error}')
                
                # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
                project.status = 'pending'  # ç­‰å¾…åˆ†æ
                project.error_message = ''
                project.save()
                
            else:
                # åŒ¯å…¥å¤±æ•—
                messages.error(request, f'CSV æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{import_result["error"]}')
                # å¦‚æœæ˜¯ç¼ºå°‘æ¬„ä½çš„å•é¡Œï¼Œæä¾›è©³ç´°è³‡è¨Š
                if 'missing_fields' in import_result:
                    messages.info(request, f'å¯ç”¨çš„æ¬„ä½ï¼š{", ".join(import_result["available_columns"])}')
                    messages.info(request, 'è«‹ç¢ºä¿ CSV æª”æ¡ˆåŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½ï¼Œæˆ–ä½¿ç”¨ç›¸æ‡‰çš„ä¸­æ–‡æ¬„ä½åç¨±')

                # é¡¯ç¤ºè©³ç´°éŒ¯èª¤è¨Šæ¯
                for error in import_result.get('errors', []):
                    messages.error(request, f'è©³ç´°éŒ¯èª¤ï¼š{error}')
                
                # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
                project.status = 'error'
                project.error_message = import_result["error"]
                project.save()
                
        except Exception as e:
            messages.error(request, f'æª”æ¡ˆä¸Šå‚³éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
    
    return redirect('liquefaction:project_detail', pk=project.pk)

# views.py ä¿®å¾©å°ˆæ¡ˆç‹€æ…‹å¡ä½çš„å•é¡Œ

@login_required
def analyze(request, pk):
    """åŸ·è¡Œæ¶²åŒ–åˆ†æ - æ”¯æ´å¤šæ–¹æ³•åˆ†æ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            # ç²å–é¸æ“‡çš„åˆ†ææ–¹æ³•
            selected_methods = request.POST.getlist('analysis_methods')
            if not selected_methods:
                messages.error(request, 'è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®åˆ†ææ–¹æ³•')
                return redirect('liquefaction:analyze', pk=project.pk)
            
            print(f"=== é–‹å§‹åˆ†æå°ˆæ¡ˆ {project.name}ï¼Œæ–¹æ³•ï¼š{selected_methods} ===")
            
            # æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹
            if project.status == 'processing':
                from django.utils import timezone
                import datetime
                
                time_diff = timezone.now() - project.updated_at
                if time_diff > datetime.timedelta(minutes=10):
                    print(f"âš ï¸ å°ˆæ¡ˆè™•ç†è¶…æ™‚ ({time_diff})ï¼Œé‡ç½®ç‹€æ…‹")
                    project.status = 'pending'
                    project.error_message = ''
                    project.save()
                    messages.warning(request, 'æª¢æ¸¬åˆ°ä¹‹å‰çš„åˆ†æå¯èƒ½ä¸­æ–·ï¼Œå·²é‡ç½®ç‹€æ…‹ã€‚')
                else:
                    print(f"âš ï¸ å°ˆæ¡ˆæ­£åœ¨è™•ç†ä¸­ï¼Œç­‰å¾…æ™‚é–“: {time_diff}")
                    messages.warning(request, f'å°ˆæ¡ˆæ­£åœ¨åˆ†æä¸­ï¼Œå·²åŸ·è¡Œ {time_diff}ï¼Œè«‹ç¨å€™...')
                    return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‘½å­”è³‡æ–™
            boreholes_count = BoreholeData.objects.filter(project=project).count()
            if boreholes_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰é‘½å­”è³‡æ–™ï¼Œè«‹å…ˆä¸Šå‚³ CSV æª”æ¡ˆ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åœŸå±¤è³‡æ–™
            layers_count = SoilLayer.objects.filter(borehole__project=project).count()
            if layers_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰åœŸå±¤è³‡æ–™')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            print("æ­£åœ¨è¼‰å…¥åˆ†æå¼•æ“...")
            from .services.analysis_engine import LiquefactionAnalysisEngine
            
            total_success = 0
            total_errors = []
            original_method = project.analysis_method
            
            for method in selected_methods:
                print(f"é–‹å§‹åŸ·è¡Œ {method} åˆ†æ...")
                
                # åªå»ºç«‹ä¸€æ¬¡åˆ†æå¼•æ“ï¼Œä¸¦å‚³å…¥æŒ‡å®šçš„æ–¹æ³•
                analysis_engine = LiquefactionAnalysisEngine(project, analysis_method=method)
                analysis_result = analysis_engine.run_analysis()
                
                print(f"{method} åˆ†æçµæœ: {analysis_result}")
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(
                        request, 
                        f'{method} åˆ†æå®Œæˆï¼å…±åˆ†æ {analysis_result["analyzed_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in analysis_result.get('warnings', []):
                        messages.warning(request, f'{method} è­¦å‘Šï¼š{warning}')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                    
                    # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
                    for error in analysis_result.get('errors', []):
                        messages.error(request, f'{method} éŒ¯èª¤ï¼š{error}')
                
                print(f"{method} åˆ†æçµæœ: {analysis_result}")
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(
                        request, 
                        f'{method} åˆ†æå®Œæˆï¼å…±åˆ†æ {analysis_result["analyzed_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in analysis_result.get('warnings', []):
                        messages.warning(request, f'{method} è­¦å‘Šï¼š{warning}')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                    
                    # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
                    for error in analysis_result.get('errors', []):
                        messages.error(request, f'{method} éŒ¯èª¤ï¼š{error}')
            
            # æ¢å¾©åŸå§‹åˆ†ææ–¹æ³•
            project.analysis_method = original_method
            
            # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
            if total_success > 0:
                project.status = 'completed'
                project.error_message = ''
                project.save()
                messages.success(request, f'å¤šæ–¹æ³•åˆ†æå®Œæˆï¼æˆåŠŸå®Œæˆ {total_success}/{len(selected_methods)} ç¨®æ–¹æ³•çš„åˆ†æ')
                return redirect('liquefaction:results', pk=project.pk)
            else:
                project.status = 'error'
                project.error_message = '; '.join(total_errors)
                project.save()
                return redirect('liquefaction:project_detail', pk=project.pk)
                
        except Exception as e:
            messages.error(request, f'åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
            
            return redirect('liquefaction:project_detail', pk=project.pk)
    
    # GET è«‹æ±‚ï¼Œé¡¯ç¤ºåˆ†æç¢ºèªé é¢
    context = {
        'project': project,
        'boreholes_count': BoreholeData.objects.filter(project=project).count(),
        'layers_count': SoilLayer.objects.filter(borehole__project=project).count(),
        'available_methods': AnalysisProject._meta.get_field('analysis_method').choices,
    }
    
    return render(request, 'liquefaction/analyze.html', context)

# æ·»åŠ ä¸€å€‹æ–°çš„ view ç”¨æ–¼é‡ç½®å°ˆæ¡ˆç‹€æ…‹
@login_required
def reset_project_status(request, pk):
    """é‡ç½®å°ˆæ¡ˆç‹€æ…‹"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        old_status = project.status
        project.status = 'pending'
        project.error_message = ''
        project.save()
        
        messages.success(request, f'å°ˆæ¡ˆç‹€æ…‹å·²å¾ "{project.get_status_display()}" é‡ç½®ç‚º "ç­‰å¾…åˆ†æ"')
        print(f"å°ˆæ¡ˆ {project.name} ç‹€æ…‹å·²å¾ {old_status} é‡ç½®ç‚º pending")
        
    return redirect('liquefaction:project_detail', pk=project.pk)


@login_required
def results(request, pk):
    """æŸ¥çœ‹åˆ†æçµæœ - æ–°å¢æ–¹æ³•ç¯©é¸"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
    total_results = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).count()
    
    if total_results == 0:
        messages.warning(request, 'å°ˆæ¡ˆå°šæœªæœ‰åˆ†æçµæœ')
        return redirect('liquefaction:project_detail', pk=project.pk)
    
    # ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•ç²å–å¯ç”¨åˆ†ææ–¹æ³•
    available_methods_raw = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).values_list('analysis_method', flat=True).distinct().order_by('analysis_method')

    # è½‰æ›ç‚ºåˆ—è¡¨ä¸¦éæ¿¾ç©ºå€¼
    available_methods_list = [method for method in available_methods_raw if method]

    # å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±æ•—ï¼Œæ‰‹å‹•æª¢æŸ¥æ¯å€‹æ–¹æ³•
    if not available_methods_list:
        all_methods = ['HBF', 'NCEER', 'AIJ', 'JRA']
        available_methods_list = []
        for method in all_methods:
            if AnalysisResult.objects.filter(
                soil_layer__borehole__project=project,
                analysis_method=method
            ).exists():
                available_methods_list.append(method)
    
    # ç²å–æ–¹æ³•åç¨±å°æ‡‰
    method_choices = dict(AnalysisProject._meta.get_field('analysis_method').choices)
    available_methods_display = [
        (method, method_choices.get(method, method)) 
        for method in available_methods_raw
    ]
    
    print(f"ğŸ” é¡¯ç¤ºç”¨çš„æ–¹æ³•å°æ‡‰: {available_methods_display}")
    
    # ç²å–æ‰€æœ‰åˆ†æçµæœ
    results = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).select_related('soil_layer', 'soil_layer__borehole').order_by(
        'soil_layer__borehole__borehole_id', 'soil_layer__top_depth', 'analysis_method'
    )
    
    # æ‡‰ç”¨ç¯©é¸æ¢ä»¶
    borehole_filter = request.GET.get('borehole', '')
    if borehole_filter:
        results = results.filter(soil_layer__borehole__borehole_id=borehole_filter)
    
    # æ–°å¢ï¼šåˆ†ææ–¹æ³•ç¯©é¸
    method_filter = request.GET.get('method', '')
    if method_filter:
        results = results.filter(analysis_method=method_filter)
        print(f"ğŸ” ç¯©é¸æ–¹æ³•: {method_filter}, çµæœæ•¸é‡: {results.count()}")
    
    lpi_filter = request.GET.get('lpi', '')
    if lpi_filter == 'low':
        results = results.filter(lpi_design__lt=5.0)
    elif lpi_filter == 'medium':
        results = results.filter(lpi_design__gte=5.0, lpi_design__lte=15.0)
    elif lpi_filter == 'high':
        results = results.filter(lpi_design__gt=15.0)
    
    print(f"ğŸ” æœ€çµ‚çµæœæ•¸é‡: {results.count()}")
    
    context = {
        'project': project,
        'results': results,
        'available_methods': available_methods_display,
        'method_filter': method_filter,
        'lpi_filter': lpi_filter,  
    }
    
    return render(request, 'liquefaction/results.html', context)

from django.db.models.fields.related import ForeignKey, OneToOneField, ManyToOneRel

@login_required
def export_results(request, pk):
    """åŒ¯å‡ºåˆ†æçµæœ - æ”¯æ´å¤šæ–¹æ³• - åŒ…å«æ‰€æœ‰è¨ˆç®—åƒæ•¸"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
    total_results = AnalysisResult.objects.filter(
        soil_layer__borehole__project=project
    ).count()
    
    if total_results == 0:
        messages.error(request, 'å°ˆæ¡ˆå°šæœªæœ‰åˆ†æçµæœï¼Œç„¡æ³•åŒ¯å‡º')
        return redirect('liquefaction:project_detail', pk=project.pk)
    
    try:
        import csv
        from django.http import HttpResponse
        from datetime import datetime
        
        # ç²å–é¸æ“‡çš„æ–¹æ³•ï¼ˆå¦‚æœæœ‰ï¼‰
        method_filter = request.GET.get('method', '')
        export_type = request.GET.get('type', 'csv')
        
        # å‰µå»º HTTP éŸ¿æ‡‰
        if method_filter:
            filename = f"{project.name}_{method_filter}_detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
        else:
            filename = f"{project.name}_all_methods_detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
            
        response = HttpResponse(content_type='text/csv; charset=utf-8')
        response['Content-Disposition'] = f'attachment; filename="{filename}"'
        
        # æ·»åŠ  BOM ä»¥ç¢ºä¿ Excel æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡
        response.write('\ufeff')
        
        writer = csv.writer(response)
        
        # ===== ä¿®æ”¹ï¼šåŒ…å«æ‰€æœ‰è¨ˆç®—åƒæ•¸çš„å®Œæ•´æ¨™é¡Œè¡Œ =====
        headers = [
            # åŸºæœ¬è³‡è¨Š
            'é‘½å­”ç·¨è™Ÿ', 'åˆ†ææ–¹æ³•', 'æ·±åº¦ä¸Šé™(m)', 'æ·±åº¦ä¸‹é™(m)', 'åœŸå±¤åšåº¦(m)',
            'åœŸå£¤åˆ†é¡(USCS)', 'SPT-N', 'å¡‘æ€§æŒ‡æ•¸(%)', 'ç´°æ–™å«é‡(%)', 'å–æ¨£ç·¨è™Ÿ',
            
            # åº§æ¨™å’ŒåŸºæœ¬åƒæ•¸
            'TWD97_X', 'TWD97_Y', 'åœ°è¡¨é«˜ç¨‹(m)', 'åœ°ä¸‹æ°´ä½æ·±åº¦(m)',
            
            # åœ°éœ‡åƒæ•¸
            'åŸå¸‚', 'åŸºæº–Mw', 'SDS', 'SMS', 'è³‡æ–™ä¾†æº', 'é„°è¿‘æ–·å±¤',
            
            # ä¸­é–“è¨ˆç®—åƒæ•¸
            'åœŸå±¤æ·±åº¦(m)', 'åœŸå±¤ä¸­é»æ·±åº¦(m)', 'åˆ†æé»æ·±åº¦(m)',
            'ç¸½å‚ç›´æ‡‰åŠ›Ïƒv(t/mÂ²)', 'æœ‰æ•ˆå‚ç›´æ‡‰åŠ›Ïƒ\'v_CSR(t/mÂ²)', 'æœ‰æ•ˆå‚ç›´æ‡‰åŠ›Ïƒ\'v_CRR(t/mÂ²)',
            'N60', 'N1_60', 'N1_60cs', 'å‰ªåŠ›æ³¢é€ŸVs(m/s)', 'CRR_7.5',
            
            # è¨­è¨ˆåœ°éœ‡è©³ç´°åƒæ•¸
            'è¨­è¨ˆåœ°éœ‡_Mw', 'è¨­è¨ˆåœ°éœ‡_A_value(g)', 'è¨­è¨ˆåœ°éœ‡_SD_S', 'è¨­è¨ˆåœ°éœ‡_SM_S',
            'è¨­è¨ˆåœ°éœ‡_MSF', 'è¨­è¨ˆåœ°éœ‡_rd', 'è¨­è¨ˆåœ°éœ‡_CSR', 'è¨­è¨ˆåœ°éœ‡_CRR', 
            'è¨­è¨ˆåœ°éœ‡_FS', 'è¨­è¨ˆåœ°éœ‡_LPI',
            
            # ä¸­å°åœ°éœ‡è©³ç´°åƒæ•¸
            'ä¸­å°åœ°éœ‡_Mw', 'ä¸­å°åœ°éœ‡_A_value(g)', 'ä¸­å°åœ°éœ‡_SD_S', 'ä¸­å°åœ°éœ‡_SM_S',
            'ä¸­å°åœ°éœ‡_MSF', 'ä¸­å°åœ°éœ‡_rd', 'ä¸­å°åœ°éœ‡_CSR', 'ä¸­å°åœ°éœ‡_CRR', 
            'ä¸­å°åœ°éœ‡_FS', 'ä¸­å°åœ°éœ‡_LPI',
            
            # æœ€å¤§åœ°éœ‡è©³ç´°åƒæ•¸
            'æœ€å¤§åœ°éœ‡_Mw', 'æœ€å¤§åœ°éœ‡_A_value(g)', 'æœ€å¤§åœ°éœ‡_SD_S', 'æœ€å¤§åœ°éœ‡_SM_S',
            'æœ€å¤§åœ°éœ‡_MSF', 'æœ€å¤§åœ°éœ‡_rd', 'æœ€å¤§åœ°éœ‡_CSR', 'æœ€å¤§åœ°éœ‡_CRR', 
            'æœ€å¤§åœ°éœ‡_FS', 'æœ€å¤§åœ°éœ‡_LPI',
            
            # é¡å¤–è³‡è¨Š
            'å–®ä½é‡(t/mÂ³)', 'å«æ°´é‡(%)', 'æ¶²æ€§é™åº¦(%)', 'åˆ†ææ™‚é–“'
        ]
        writer.writerow(headers)
        
        # ç²å–åˆ†æçµæœ
        results = AnalysisResult.objects.filter(
            soil_layer__borehole__project=project
        ).select_related('soil_layer', 'soil_layer__borehole').order_by(
            'soil_layer__borehole__borehole_id', 'soil_layer__top_depth', 'analysis_method'
        )
        
        # æ‡‰ç”¨æ–¹æ³•ç¯©é¸
        if method_filter:
            results = results.filter(analysis_method=method_filter)
        
        # ===== ä¿®æ”¹ï¼šå¯«å…¥åŒ…å«æ‰€æœ‰åƒæ•¸çš„è©³ç´°è³‡æ–™è¡Œ =====
        for result in results:
            soil_layer = result.soil_layer
            borehole = soil_layer.borehole
            
            # å®‰å…¨å–å€¼å‡½æ•¸
            def safe_value(val):
                if val is None:
                    return ''
                elif isinstance(val, float):
                    return f"{val:.6f}" if abs(val) < 1000 else f"{val:.2f}"
                else:
                    return str(val)
            
            row = [
                # åŸºæœ¬è³‡è¨Š
                borehole.borehole_id,
                result.analysis_method,
                safe_value(soil_layer.top_depth),
                safe_value(soil_layer.bottom_depth),
                safe_value(soil_layer.thickness) if hasattr(soil_layer, 'thickness') else safe_value(soil_layer.bottom_depth - soil_layer.top_depth),
                soil_layer.uscs or '',
                safe_value(soil_layer.spt_n),
                safe_value(soil_layer.plastic_index),
                safe_value(soil_layer.fines_content),
                soil_layer.sample_id or '',
                
                # åº§æ¨™å’ŒåŸºæœ¬åƒæ•¸
                safe_value(borehole.twd97_x),
                safe_value(borehole.twd97_y),
                safe_value(borehole.surface_elevation),
                safe_value(borehole.water_depth),
                
                # åœ°éœ‡åƒæ•¸
                borehole.city or '',
                safe_value(borehole.base_mw),
                safe_value(borehole.sds),
                safe_value(borehole.sms),
                borehole.data_source or '',
                borehole.nearby_fault or '',
                
                # ä¸­é–“è¨ˆç®—åƒæ•¸
                safe_value(result.soil_depth),
                safe_value(result.mid_depth),
                safe_value(result.analysis_depth),
                safe_value(result.sigma_v),
                safe_value(result.sigma_v_csr),
                safe_value(result.sigma_v_crr),
                safe_value(result.n60),
                safe_value(result.n1_60),
                safe_value(result.n1_60cs),
                safe_value(result.vs),
                safe_value(result.crr_7_5),
                
                # è¨­è¨ˆåœ°éœ‡è©³ç´°åƒæ•¸
                safe_value(result.mw_design),
                safe_value(result.a_value_design),
                safe_value(result.sd_s_design),
                safe_value(result.sm_s_design),
                safe_value(result.msf_design),
                safe_value(result.rd_design),
                safe_value(result.csr_design),
                safe_value(result.crr_design),
                safe_value(result.fs_design),
                safe_value(result.lpi_design),
                
                # ä¸­å°åœ°éœ‡è©³ç´°åƒæ•¸
                safe_value(result.mw_mid),
                safe_value(result.a_value_mid),
                safe_value(result.sd_s_mid),
                safe_value(result.sm_s_mid),
                safe_value(result.msf_mid),
                safe_value(result.rd_mid),
                safe_value(result.csr_mid),
                safe_value(result.crr_mid),
                safe_value(result.fs_mid),
                safe_value(result.lpi_mid),
                
                # æœ€å¤§åœ°éœ‡è©³ç´°åƒæ•¸
                safe_value(result.mw_max),
                safe_value(result.a_value_max),
                safe_value(result.sd_s_max),
                safe_value(result.sm_s_max),
                safe_value(result.msf_max),
                safe_value(result.rd_max),
                safe_value(result.csr_max),
                safe_value(result.crr_max),
                safe_value(result.fs_max),
                safe_value(result.lpi_max),
                
                # é¡å¤–è³‡è¨Š
                safe_value(soil_layer.unit_weight),
                safe_value(soil_layer.water_content),
                safe_value(soil_layer.liquid_limit),
                result.created_at.strftime('%Y-%m-%d %H:%M:%S') if result.created_at else ''
            ]
            writer.writerow(row)
        
        return response
        
    except Exception as e:
        messages.error(request, f'åŒ¯å‡ºçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)
    
def api_seismic_data(request):
    """APIï¼šç²å–åœ°éœ‡åƒæ•¸è³‡æ–™"""
    city = request.GET.get('city', '')
    district = request.GET.get('district', '')
    village = request.GET.get('village', '')
    
    # é€™è£¡å°‡ä¾†æœƒå¯¦ä½œåœ°éœ‡åƒæ•¸æŸ¥è©¢é‚è¼¯
    return JsonResponse({
        'city': city,
        'district': district,
        'village': village,
        'seismic_data': {},
        'message': 'API é–‹ç™¼ä¸­'
    })


@login_required
def reanalyze(request, pk):
    """é‡æ–°åŸ·è¡Œæ¶²åŒ–åˆ†æ - æ”¯æ´å¤šæ–¹æ³•"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    if request.method == 'POST':
        try:
            # å–å¾—é¸æ“‡çš„åˆ†ææ–¹æ³•
            selected_methods = request.POST.getlist('analysis_methods')
            if not selected_methods:
                messages.error(request, 'è«‹è‡³å°‘é¸æ“‡ä¸€ç¨®åˆ†ææ–¹æ³•')
                return redirect('liquefaction:reanalyze', pk=project.pk)
            
            print(f"=== é–‹å§‹é‡æ–°åˆ†æå°ˆæ¡ˆ {project.name}ï¼Œæ–¹æ³•ï¼š{selected_methods} ===")
            
            # æª¢æŸ¥å°ˆæ¡ˆç‹€æ…‹
            if project.status == 'processing':
                messages.warning(request, 'å°ˆæ¡ˆæ­£åœ¨åˆ†æä¸­ï¼Œè«‹ç¨å€™...')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‘½å­”è³‡æ–™
            boreholes_count = BoreholeData.objects.filter(project=project).count()
            if boreholes_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰é‘½å­”è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åœŸå±¤è³‡æ–™
            layers_count = SoilLayer.objects.filter(borehole__project=project).count()
            if layers_count == 0:
                messages.error(request, 'å°ˆæ¡ˆä¸­æ²’æœ‰åœŸå±¤è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ')
                return redirect('liquefaction:project_detail', pk=project.pk)
            
            # æ¸…é™¤é¸ä¸­æ–¹æ³•çš„ç¾æœ‰åˆ†æçµæœ
            for method in selected_methods:
                deleted_count = AnalysisResult.objects.filter(
                    soil_layer__borehole__project=project,
                    analysis_method=method
                ).count()
                
                AnalysisResult.objects.filter(
                    soil_layer__borehole__project=project,
                    analysis_method=method
                ).delete()
                
                print(f"å·²æ¸…é™¤ {method} æ–¹æ³•çš„ {deleted_count} å€‹ç¾æœ‰åˆ†æçµæœ")
            
            # é‡è¨­éŒ¯èª¤è¨Šæ¯
            project.error_message = ''
            project.save()
            
            print("æ­£åœ¨è¼‰å…¥åˆ†æå¼•æ“...")
            from .services.analysis_engine import LiquefactionAnalysisEngine
            
            total_success = 0
            total_errors = []
            
            for method in selected_methods:
                print(f"é–‹å§‹é‡æ–°åŸ·è¡Œ {method} åˆ†æ...")
                
                # å»ºç«‹å°ˆé–€é‡å°è©²æ–¹æ³•çš„åˆ†æå¼•æ“å¯¦ä¾‹
                analysis_engine = LiquefactionAnalysisEngine(project, analysis_method=method)
                analysis_result = analysis_engine.run_analysis()
                
                print(f"{method} é‡æ–°åˆ†æçµæœ: {analysis_result}")
                
                if analysis_result['success']:
                    total_success += 1
                    messages.success(
                        request, 
                        f'{method} é‡æ–°åˆ†æå®Œæˆï¼å…±åˆ†æ {analysis_result["analyzed_layers"]} å€‹åœŸå±¤ã€‚'
                    )
                    
                    # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯
                    for warning in analysis_result.get('warnings', []):
                        messages.warning(request, f'{method} è­¦å‘Šï¼š{warning}')
                else:
                    total_errors.append(f'{method}: {analysis_result["error"]}')
                    messages.error(request, f'{method} é‡æ–°åˆ†æå¤±æ•—ï¼š{analysis_result["error"]}')
                    
                    # é¡¯ç¤ºè©³ç´°éŒ¯èª¤
                    for error in analysis_result.get('errors', []):
                        messages.error(request, f'{method} éŒ¯èª¤ï¼š{error}')
            
            # æ›´æ–°å°ˆæ¡ˆç‹€æ…‹
            if total_success > 0:
                project.status = 'completed'
                project.error_message = ''
                project.save()
                messages.success(request, f'é‡æ–°åˆ†æå®Œæˆï¼æˆåŠŸå®Œæˆ {total_success}/{len(selected_methods)} ç¨®æ–¹æ³•çš„åˆ†æ')
                return redirect('liquefaction:results', pk=project.pk)
            else:
                project.status = 'error'
                project.error_message = '; '.join(total_errors)
                project.save()
                return redirect('liquefaction:project_detail', pk=project.pk)
                
        except Exception as e:
            messages.error(request, f'é‡æ–°åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
            project.status = 'error'
            project.error_message = str(e)
            project.save()
            
            return redirect('liquefaction:project_detail', pk=project.pk)
    
    # GET è«‹æ±‚ï¼Œé¡¯ç¤ºé‡æ–°åˆ†æç¢ºèªé é¢
    # å–å¾—ç¾æœ‰çš„åˆ†æçµæœçµ±è¨ˆ
    existing_results_by_method = {}
    for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
        count = AnalysisResult.objects.filter(
            soil_layer__borehole__project=project,
            analysis_method=method_code
        ).count()
        if count > 0:
            existing_results_by_method[method_code] = {
                'name': method_name,
                'count': count
            }
    
    context = {
        'project': project,
        'boreholes_count': BoreholeData.objects.filter(project=project).count(),
        'layers_count': SoilLayer.objects.filter(borehole__project=project).count(),
        'existing_results_by_method': existing_results_by_method,
        'available_methods': AnalysisProject._meta.get_field('analysis_method').choices,
    }
    
    return render(request, 'liquefaction/reanalyze.html', context)

@login_required
def download_analysis_file(request, pk, filename):
    """ä¸‹è¼‰åˆ†æçµæœæª”æ¡ˆ"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    file_path = os.path.join(project.get_output_directory(), filename)
    
    if not os.path.exists(file_path) or not filename.startswith(str(project.id)):
        raise Http404("æª”æ¡ˆä¸å­˜åœ¨")
    
    return FileResponse(
        open(file_path, 'rb'),
        as_attachment=True,
        filename=filename
    )

@login_required
def project_files(request, pk):
    """æŸ¥çœ‹å°ˆæ¡ˆæª”æ¡ˆåˆ—è¡¨"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    files = project.list_output_files()
    
    context = {
        'project': project,
        'files': files,
    }
    
    return render(request, 'liquefaction/project_files.html', context)


# åœ¨ src/liquefaction/views.py ä¸­æ–°å¢ä»¥ä¸‹è¦–åœ–

@login_required
def borehole_data(request, pk):
    """é‘½äº•æ•¸æ“šç¸½è¦½è¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # å–å¾—æ‰€æœ‰é‘½å­”æ•¸æ“š
    boreholes = BoreholeData.objects.filter(project=project).prefetch_related('soil_layers').order_by('borehole_id')
    
    # æœå°‹å’Œç¯©é¸
    search_query = request.GET.get('search', '')
    if search_query:
        boreholes = boreholes.filter(borehole_id__icontains=search_query)
    
    # ç‚ºæ¯å€‹é‘½å­”è¨ˆç®—çµ±è¨ˆè³‡è¨Š
    borehole_stats = []
    for borehole in boreholes:
        soil_layers = borehole.soil_layers.all().order_by('top_depth')
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        total_layers = soil_layers.count()
        max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
        min_n_value = min([layer.spt_n for layer in soil_layers if layer.spt_n is not None]) if soil_layers else None
        max_n_value = max([layer.spt_n for layer in soil_layers if layer.spt_n is not None]) if soil_layers else None
        avg_n_value = sum([layer.spt_n for layer in soil_layers if layer.spt_n is not None]) / total_layers if total_layers > 0 else None
        
        # åœŸå£¤é¡å‹åˆ†å¸ƒ
        soil_types = list(set([layer.uscs for layer in soil_layers if layer.uscs]))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
        has_analysis = AnalysisResult.objects.filter(soil_layer__borehole=borehole).exists()
        analysis_methods = list(set(AnalysisResult.objects.filter(
            soil_layer__borehole=borehole
        ).values_list('analysis_method', flat=True)))
        
        borehole_stats.append({
            'borehole': borehole,
            'total_layers': total_layers,
            'max_depth': max_depth,
            'min_n_value': min_n_value,
            'max_n_value': max_n_value,
            'avg_n_value': avg_n_value,
            'soil_types': soil_types,
            'has_analysis': has_analysis,
            'analysis_methods': analysis_methods,
        })
    
    # åˆ†é 
    from django.core.paginator import Paginator
    paginator = Paginator(borehole_stats, 10)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'project': project,
        'page_obj': page_obj,
        'search_query': search_query,
        'total_boreholes': boreholes.count(),
    }
    
    return render(request, 'liquefaction/borehole_data.html', context)


@login_required
def borehole_detail(request, pk, borehole_id):
    """å–®å€‹é‘½å­”è©³ç´°æ•¸æ“šè¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    borehole = get_object_or_404(BoreholeData, project=project, borehole_id=borehole_id)
    
    # å–å¾—åœŸå±¤æ•¸æ“š
    soil_layers = SoilLayer.objects.filter(borehole=borehole).order_by('top_depth')
    
    # æ ¹æ“šä½ çš„å¯¦éš›æ¨¡å‹è™•ç†æ•¸æ“š
    for layer in soil_layers:
        # FCå€¼è™•ç† - å„ªå…ˆä½¿ç”¨ FC æ¬„ä½ï¼Œå…¶æ¬¡æ˜¯ fines_content
        if layer.FC is not None:
            layer.fc_value = layer.FC
        elif layer.fines_content is not None:
            layer.fc_value = layer.fines_content
        # å¦‚æœæ²’æœ‰ç´°æ–™æ¬„ä½ï¼Œç”¨ç²‰åœŸ+é»åœŸè¨ˆç®—
        elif (layer.silt_percent is not None and layer.clay_percent is not None):
            layer.fc_value = layer.silt_percent + layer.clay_percent
        else:
            layer.fc_value = None
        
        # è™•ç†Nå€¼ - å„ªå…ˆä½¿ç”¨ spt_nï¼Œå…¶æ¬¡æ˜¯ n_value
        if layer.spt_n is not None:
            layer.n_val = layer.spt_n
        elif layer.n_value is not None:
            layer.n_val = layer.n_value
        else:
            layer.n_val = None
        
        # çµ±ä¸€åœŸå£¤åˆ†é¡å·²ç¶“ç›´æ¥å¯ç”¨
        layer.soil_class = layer.uscs if layer.uscs else None
        
        # å–®ä½é‡è™•ç†
        layer.unit_wt = layer.unit_weight if layer.unit_weight is not None else None
        
        # åšåº¦å·²ç¶“åœ¨æ¨¡å‹çš„propertyä¸­å®šç¾©äº†ï¼Œç›´æ¥ä½¿ç”¨
        # layer.thickness å·²ç¶“å¯ä»¥ç›´æ¥ä½¿ç”¨
        
        # Debugè¼¸å‡ºï¼ˆå¯é¸ï¼Œç”¨æ–¼æ’æŸ¥å•é¡Œï¼‰
        print(f"Layer {layer.id}: FC={layer.fc_value}, N={layer.n_val}, USCS={layer.soil_class}")
    
    # å–å¾—åˆ†æçµæœï¼ˆå¦‚æœæœ‰ï¼‰
    analysis_results = {}
    if hasattr(AnalysisProject, '_meta'):
        try:
            for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
                results = AnalysisResult.objects.filter(
                    soil_layer__borehole=borehole,
                    analysis_method=method_code
                ).order_by('soil_layer__top_depth')
                
                if results.exists():
                    analysis_results[method_code] = {
                        'name': method_name,
                        'results': results
                    }
        except:
            # å¦‚æœæ²’æœ‰analysis_methodæ¬„ä½æˆ–AnalysisResultæ¨¡å‹ï¼Œè·³é
            pass
    
    # è¨ˆç®—é‘½å­”çµ±è¨ˆ
    total_layers = soil_layers.count()
    max_depth = 0
    if soil_layers:
        depth_values = []
        for layer in soil_layers:
            if hasattr(layer, 'bottom_depth') and layer.bottom_depth is not None:
                depth_values.append(layer.bottom_depth)
        max_depth = max(depth_values) if depth_values else 0
    
    # Nå€¼çµ±è¨ˆ
    n_values = [layer.n_val for layer in soil_layers if layer.n_val is not None]
    n_stats = {
        'count': len(n_values),
        'min': min(n_values) if n_values else None,
        'max': max(n_values) if n_values else None,
        'avg': sum(n_values) / len(n_values) if n_values else None,
    }
    
    # FCå€¼çµ±è¨ˆ
    fc_values = [layer.fc_value for layer in soil_layers if layer.fc_value is not None]
    fc_stats = {
        'count': len(fc_values),
        'min': min(fc_values) if fc_values else None,
        'max': max(fc_values) if fc_values else None,
        'avg': sum(fc_values) / len(fc_values) if fc_values else None,
    }
    
    # åœŸå£¤é¡å‹åˆ†å¸ƒ
    soil_type_counts = {}
    for layer in soil_layers:
        if layer.soil_class:
            soil_type_counts[layer.soil_class] = soil_type_counts.get(layer.soil_class, 0) + 1
    
    # æ·±åº¦åˆ†å¸ƒï¼ˆæ¯5ç±³ä¸€çµ„ï¼‰
    depth_distribution = {}
    for layer in soil_layers:
        if hasattr(layer, 'top_depth') and layer.top_depth is not None:
            depth_group = int(layer.top_depth // 5) * 5
            key = f"{depth_group}-{depth_group + 5}m"
            depth_distribution[key] = depth_distribution.get(key, 0) + 1
    
    # FCå«é‡åˆ†å¸ƒçµ±è¨ˆ (ç”¨æ–¼åˆ†ææ¶²åŒ–æ½›èƒ½)
    fc_distribution = {
        'ä½FC(<15%)': 0,
        'ä¸­FC(15-35%)': 0, 
        'é«˜FC(>35%)': 0
    }
    
    for layer in soil_layers:
        if layer.fc_value is not None:
            if layer.fc_value < 15:
                fc_distribution['ä½FC(<15%)'] += 1
            elif layer.fc_value <= 35:
                fc_distribution['ä¸­FC(15-35%)'] += 1
            else:
                fc_distribution['é«˜FC(>35%)'] += 1
    
    context = {
        'project': project,
        'borehole': borehole,
        'soil_layers': soil_layers,
        'analysis_results': analysis_results,
        'total_layers': total_layers,
        'max_depth': max_depth,
        'n_stats': n_stats,
        'fc_stats': fc_stats,  # FC çµ±è¨ˆ
        'soil_type_counts': soil_type_counts,
        'depth_distribution': depth_distribution,
        'fc_distribution': fc_distribution,  # FC åˆ†å¸ƒçµ±è¨ˆ
    }
    
    return render(request, 'liquefaction/borehole_detail.html', context)
@login_required
def borehole_data(request, pk):
    """é‘½äº•æ•¸æ“šç¸½è¦½è¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    # å–å¾—æ‰€æœ‰é‘½å­”æ•¸æ“š
    boreholes = BoreholeData.objects.filter(project=project).prefetch_related('soil_layers').order_by('borehole_id')
    
    # æœå°‹å’Œç¯©é¸
    search_query = request.GET.get('search', '')
    if search_query:
        boreholes = boreholes.filter(borehole_id__icontains=search_query)
    
    # ç‚ºæ¯å€‹é‘½å­”è¨ˆç®—çµ±è¨ˆè³‡è¨Š
    borehole_stats = []
    for borehole in boreholes:
        soil_layers = borehole.soil_layers.all().order_by('top_depth')
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        total_layers = soil_layers.count()
        max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
        n_values = [layer.spt_n for layer in soil_layers if layer.spt_n is not None]
        min_n_value = min(n_values) if n_values else None
        max_n_value = max(n_values) if n_values else None
        avg_n_value = sum(n_values) / len(n_values) if n_values else None
        
        # åœŸå£¤é¡å‹åˆ†å¸ƒ
        soil_types = list(set([layer.uscs for layer in soil_layers if layer.uscs]))
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æçµæœ
        has_analysis = AnalysisResult.objects.filter(soil_layer__borehole=borehole).exists()
        analysis_methods = list(set(AnalysisResult.objects.filter(
            soil_layer__borehole=borehole
        ).values_list('analysis_method', flat=True)))
        
        borehole_stats.append({
            'borehole': borehole,
            'total_layers': total_layers,
            'max_depth': max_depth,
            'min_n_value': min_n_value,
            'max_n_value': max_n_value,
            'avg_n_value': avg_n_value,
            'soil_types': soil_types,
            'has_analysis': has_analysis,
            'analysis_methods': analysis_methods,
        })
    
    # åˆ†é 
    from django.core.paginator import Paginator
    paginator = Paginator(borehole_stats, 10)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'project': project,
        'page_obj': page_obj,
        'search_query': search_query,
        'total_boreholes': boreholes.count(),
    }
    
    return render(request, 'liquefaction/borehole_data.html', context)


@login_required
def borehole_detail(request, pk, borehole_id):
    """å–®å€‹é‘½å­”è©³ç´°æ•¸æ“šè¦–åœ–"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    borehole = get_object_or_404(BoreholeData, project=project, borehole_id=borehole_id)
    
    # å–å¾—åœŸå±¤æ•¸æ“š
    soil_layers = SoilLayer.objects.filter(borehole=borehole).order_by('top_depth')
    
    # å–å¾—åˆ†æçµæœï¼ˆå¦‚æœæœ‰ï¼‰
    analysis_results = {}
    for method_code, method_name in AnalysisProject._meta.get_field('analysis_method').choices:
        results = AnalysisResult.objects.filter(
            soil_layer__borehole=borehole,
            analysis_method=method_code
        ).order_by('soil_layer__top_depth')
        
        if results.exists():
            analysis_results[method_code] = {
                'name': method_name,
                'results': results
            }
    
    # è¨ˆç®—é‘½å­”çµ±è¨ˆ
    total_layers = soil_layers.count()
    max_depth = max([layer.bottom_depth for layer in soil_layers]) if soil_layers else 0
    
    # Nå€¼çµ±è¨ˆ
    n_values = [layer.spt_n for layer in soil_layers if layer.spt_n is not None]
    n_stats = {
        'count': len(n_values),
        'min': min(n_values) if n_values else None,
        'max': max(n_values) if n_values else None,
        'avg': sum(n_values) / len(n_values) if n_values else None,
    }
    
    context = {
        'project': project,
        'borehole': borehole,
        'soil_layers': soil_layers,
        'analysis_results': analysis_results,
        'total_layers': total_layers,
        'max_depth': max_depth,
        'n_stats': n_stats,
    }
    
    return render(request, 'liquefaction/borehole_detail.html', context)

# åœ¨ views.py ä¸­åŠ å…¥ä»¥ä¸‹å‡½æ•¸

@login_required
def download_analysis_outputs(request, pk):
    """ä¸‹è¼‰å°ˆæ¡ˆçš„åˆ†æè¼¸å‡ºè³‡æ–™å¤¾"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        import tempfile
        import zipfile
        import shutil
        import glob
        from datetime import datetime
        from django.http import FileResponse, Http404
        from django.conf import settings
        
        # å°‹æ‰¾å°ˆæ¡ˆçš„è¼¸å‡ºç›®éŒ„
        output_dirs = _find_project_output_directories(project)
        
        if not output_dirs:
            messages.error(request, 'æ‰¾ä¸åˆ°åˆ†æè¼¸å‡ºæª”æ¡ˆ')
            return redirect('liquefaction:results', pk=project.pk)
        
        # å‰µå»ºè‡¨æ™‚ZIPæª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            temp_zip_path = temp_zip.name
        
        try:
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                total_files = 0
                
                for output_dir in output_dirs:
                    if os.path.exists(output_dir):
                        print(f"æ­£åœ¨æ‰“åŒ…ç›®éŒ„ï¼š{output_dir}")
                        
                        # å–å¾—ç›®éŒ„åç¨±ä½œç‚ºZIPå…§çš„æ ¹ç›®éŒ„
                        dir_name = os.path.basename(output_dir)
                        
                        # éæ­¸æ·»åŠ ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
                        for root, dirs, files in os.walk(output_dir):
                            for file in files:
                                file_path = os.path.join(root, file)
                                # è¨ˆç®—åœ¨ZIPä¸­çš„ç›¸å°è·¯å¾‘
                                arcname = os.path.relpath(file_path, os.path.dirname(output_dir))
                                zipf.write(file_path, arcname)
                                total_files += 1
                                print(f"  æ·»åŠ æª”æ¡ˆï¼š{arcname}")
                
                if total_files == 0:
                    messages.warning(request, 'åˆ†æè¼¸å‡ºç›®éŒ„ä¸­æ²’æœ‰æª”æ¡ˆ')
                    os.unlink(temp_zip_path)
                    return redirect('liquefaction:results', pk=project.pk)
                
                print(f"ç¸½å…±æ‰“åŒ…äº† {total_files} å€‹æª”æ¡ˆ")
            
            # ç”Ÿæˆä¸‹è¼‰æª”å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"{project.name}_åˆ†æè¼¸å‡º_{timestamp}.zip"
            
            # è¿”å›æª”æ¡ˆéŸ¿æ‡‰
            response = FileResponse(
                open(temp_zip_path, 'rb'),
                as_attachment=True,
                filename=download_filename
            )
            response['Content-Type'] = 'application/zip'
            
            # è¨»å†Šæ¸…ç†å‡½æ•¸ï¼ˆç•¶éŸ¿æ‡‰å®Œæˆå¾Œåˆªé™¤è‡¨æ™‚æª”æ¡ˆï¼‰
            def cleanup_temp_file():
                try:
                    os.unlink(temp_zip_path)
                    print(f"å·²æ¸…ç†è‡¨æ™‚æª”æ¡ˆï¼š{temp_zip_path}")
                except:
                    pass
            
            # é€™è£¡æˆ‘å€‘ä¸èƒ½ç›´æ¥æ¸…ç†ï¼Œå› ç‚ºæª”æ¡ˆé‚„åœ¨ä½¿ç”¨ä¸­
            # å¯ä»¥è€ƒæ…®ä½¿ç”¨å¾Œå°ä»»å‹™ä¾†æ¸…ç†ï¼Œæˆ–è€…ä¾è³´ç³»çµ±çš„è‡¨æ™‚æª”æ¡ˆæ¸…ç†
            
            return response
            
        except Exception as e:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e
            
    except Exception as e:
        messages.error(request, f'ä¸‹è¼‰åˆ†æè¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)



def _find_project_output_directories(project):
    """ç›´æ¥æœå°‹å°ˆæ¡ˆç›¸é—œæª”æ¡ˆ - ç°¡åŒ–ç‰ˆæœ¬"""
    import glob
    from django.conf import settings
    
    output_dirs = []
    found_files = []
    
    try:
        analysis_output_root = getattr(settings, 'ANALYSIS_OUTPUT_ROOT', 
                                      os.path.join(settings.MEDIA_ROOT, 'analysis_outputs'))
        
        print(f"ğŸ” ç›´æ¥æœå°‹æª”æ¡ˆï¼Œæ ¹è·¯å¾‘ï¼š{analysis_output_root}")
        
        if not os.path.exists(analysis_output_root):
            print(f"âŒ åˆ†æè¼¸å‡ºæ ¹ç›®éŒ„ä¸å­˜åœ¨ï¼š{analysis_output_root}")
            return []
        
        # å–å¾—å°ˆæ¡ˆIDçš„å‰8ä½å­—ç¬¦ç”¨æ–¼åŒ¹é…
        project_id_short = str(project.id)[:8]
        
        print(f"ğŸ” æœå°‹å°ˆæ¡ˆIDé–‹é ­ï¼š{project_id_short}")
        
        # ç›´æ¥éæ­¸æœå°‹æ‰€æœ‰ç›¸é—œæª”æ¡ˆ
        search_patterns = [
            f"**/*{project_id_short}*",  # åŒ…å«å°ˆæ¡ˆIDçš„ä»»ä½•æª”æ¡ˆ
            f"**/*HBF*.csv",            # HBFç›¸é—œCSVæª”æ¡ˆ  
            f"**/*LPI*.csv",            # LPIç›¸é—œCSVæª”æ¡ˆ
            f"**/*{project.name}*",     # åŒ…å«å°ˆæ¡ˆåç¨±çš„æª”æ¡ˆ
        ]
        
        for pattern in search_patterns:
            search_path = os.path.join(analysis_output_root, pattern)
            matching_files = glob.glob(search_path, recursive=True)
            
            for file_path in matching_files:
                if os.path.isfile(file_path):
                    # æª¢æŸ¥æª”æ¡ˆåæ˜¯å¦çœŸçš„èˆ‡å°ˆæ¡ˆç›¸é—œ
                    file_name = os.path.basename(file_path)
                    
                    # æ›´å¯¬é¬†çš„åŒ¹é…æ¢ä»¶
                    is_relevant = any([
                        project_id_short in file_name,
                        project.name in file_name,
                        any(keyword in file_name.lower() for keyword in ['hbf', 'lpi', 'design', 'mideq', 'maxeq'])
                    ])
                    
                    if is_relevant:
                        found_files.append(file_path)
                        parent_dir = os.path.dirname(file_path)
                        
                        if parent_dir not in output_dirs:
                            output_dirs.append(parent_dir)
                            print(f"âœ… æ‰¾åˆ°ç›¸é—œæª”æ¡ˆï¼š{file_name}")
                            print(f"   æ‰€åœ¨ç›®éŒ„ï¼š{parent_dir}")
        
        # å»é‡ä¸¦æ’åº
        output_dirs = list(set(output_dirs))
        
        print(f"ğŸ¯ ç¸½å…±æ‰¾åˆ° {len(found_files)} å€‹ç›¸é—œæª”æ¡ˆ")
        print(f"ğŸ¯ æ¶‰åŠ {len(output_dirs)} å€‹ç›®éŒ„")
        
        # å¦‚æœæ²’æ‰¾åˆ°ä»»ä½•ç›®éŒ„ä½†æœ‰æª”æ¡ˆï¼Œè‡³å°‘è¿”å›æ ¹ç›®éŒ„
        if not output_dirs and found_files:
            output_dirs = [analysis_output_root]
        
        return output_dirs
        
    except Exception as e:
        print(f"âŒ æœå°‹æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        print(traceback.format_exc())
        return []

# åŒæ™‚ç°¡åŒ– get_analysis_outputs_info å‡½æ•¸

@login_required 
def get_analysis_outputs_info(request, pk):
    """å–å¾—åˆ†æè¼¸å‡ºè³‡è¨Š - ç›´æ¥æª”æ¡ˆæœå°‹ç‰ˆæœ¬"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        print(f"ğŸ” é–‹å§‹ç›´æ¥æœå°‹å°ˆæ¡ˆæª”æ¡ˆï¼š{project.name} (IDå‰8ä½: {str(project.id)[:8]})")
        
        from django.conf import settings
        import glob
        
        analysis_output_root = getattr(settings, 'ANALYSIS_OUTPUT_ROOT', 
                                      os.path.join(settings.MEDIA_ROOT, 'analysis_outputs'))
        
        project_id_short = str(project.id)[:8]
        all_found_files = []
        
        # ç›´æ¥æœå°‹ç›¸é—œæª”æ¡ˆ
        search_patterns = [
            f"**/*{project_id_short}*",
            f"**/*HBF*{datetime.now().strftime('%m%d')}*.csv",  # ä»Šå¤©ç”¢ç”Ÿçš„HBFæª”æ¡ˆ
            f"**/*LPI*{datetime.now().strftime('%m%d')}*.csv",  # ä»Šå¤©ç”¢ç”Ÿçš„LPIæª”æ¡ˆ
        ]
        
        for pattern in search_patterns:
            search_path = os.path.join(analysis_output_root, pattern)
            matching_files = glob.glob(search_path, recursive=True)
            
            for file_path in matching_files:
                if os.path.isfile(file_path):
                    file_name = os.path.basename(file_path)
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºç›¸é—œæª”æ¡ˆ
                    is_relevant = any([
                        project_id_short in file_name,
                        any(keyword in file_name.lower() for keyword in ['hbf', 'lpi', 'design', 'mideq', 'maxeq'])
                    ])
                    
                    if is_relevant and file_path not in all_found_files:
                        all_found_files.append(file_path)
                        print(f"ğŸ“„ æ‰¾åˆ°æª”æ¡ˆï¼š{file_name}")
        
        output_info = {
            'has_outputs': len(all_found_files) > 0,
            'directories': [],
            'total_files': len(all_found_files),
            'total_size': 0,
            'debug_info': {
                'project_id': str(project.id),
                'project_id_short': project_id_short,
                'project_name': project.name,
                'found_files_count': len(all_found_files),
                'analysis_output_root': analysis_output_root
            }
        }
        
        if all_found_files:
            # æŒ‰ç›®éŒ„åˆ†çµ„æª”æ¡ˆ
            dirs_dict = {}
            
            for file_path in all_found_files:
                dir_path = os.path.dirname(file_path)
                dir_name = os.path.basename(dir_path) if dir_path != analysis_output_root else "æ ¹ç›®éŒ„"
                
                if dir_name not in dirs_dict:
                    dirs_dict[dir_name] = {
                        'path': dir_path,
                        'name': dir_name,
                        'files': [],
                        'file_count': 0,
                        'size': 0
                    }
                
                try:
                    file_size = os.path.getsize(file_path)
                    file_modified = os.path.getmtime(file_path)
                    
                    dirs_dict[dir_name]['files'].append({
                        'name': os.path.basename(file_path),
                        'path': os.path.relpath(file_path, dir_path),
                        'size': file_size,
                        'modified': datetime.fromtimestamp(file_modified).strftime('%Y-%m-%d %H:%M:%S')
                    })
                    
                    dirs_dict[dir_name]['size'] += file_size
                    dirs_dict[dir_name]['file_count'] += 1
                    output_info['total_size'] += file_size
                    
                except OSError as e:
                    print(f"âš ï¸ ç„¡æ³•è®€å–æª”æ¡ˆ {file_path}: {e}")
                    continue
            
            output_info['directories'] = list(dirs_dict.values())
        
        print(f"ğŸ¯ APIå›æ‡‰ï¼šæ‰¾åˆ° {output_info['total_files']} å€‹æª”æ¡ˆ")
        
        return JsonResponse(output_info)
        
    except Exception as e:
        print(f"âŒ å–å¾—è¼¸å‡ºè³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        print(traceback.format_exc())
        
        return JsonResponse({
            'error': str(e),
            'has_outputs': False,
            'debug_info': {
                'project_id': str(project.id),
                'project_name': project.name,
                'error_details': str(e)
            }
        })
# åŒæ™‚ä¿®æ”¹ get_analysis_outputs_info å‡½æ•¸ï¼Œå¢åŠ æ›´è©³ç´°çš„åµéŒ¯è³‡è¨Š

@login_required 
def get_analysis_outputs_info(request, pk):
    """å–å¾—åˆ†æè¼¸å‡ºè³‡è¨Šçš„APIç«¯é» - å¢å¼·ç‰ˆæœ¬"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        print(f"ğŸ” é–‹å§‹æŸ¥æ‰¾å°ˆæ¡ˆè¼¸å‡ºæª”æ¡ˆï¼š{project.name} (ID: {project.id})")
        
        output_dirs = _find_project_output_directories(project)
        
        output_info = {
            'has_outputs': len(output_dirs) > 0,
            'directories': [],
            'total_files': 0,
            'total_size': 0,
            'debug_info': {
                'project_id': str(project.id),
                'project_name': project.name,
                'searched_dirs': len(output_dirs),
                'analysis_output_root': getattr(settings, 'ANALYSIS_OUTPUT_ROOT', 'Not set')
            }
        }
        
        for output_dir in output_dirs:
            if os.path.exists(output_dir):
                print(f"ğŸ“ è™•ç†ç›®éŒ„ï¼š{output_dir}")
                
                dir_info = {
                    'path': output_dir,
                    'name': os.path.basename(output_dir),
                    'files': [],
                    'file_count': 0,
                    'size': 0
                }
                
                # åˆ—å‡ºç›®éŒ„ä¸­çš„æª”æ¡ˆ
                for root, dirs, files in os.walk(output_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        relative_path = os.path.relpath(file_path, output_dir)
                        
                        try:
                            file_size = os.path.getsize(file_path)
                            file_modified = os.path.getmtime(file_path)
                            
                            dir_info['files'].append({
                                'name': file,
                                'path': relative_path,
                                'size': file_size,
                                'modified': datetime.fromtimestamp(file_modified).strftime('%Y-%m-%d %H:%M:%S')
                            })
                            
                            dir_info['size'] += file_size
                            dir_info['file_count'] += 1
                            print(f"ğŸ“„ æ‰¾åˆ°æª”æ¡ˆï¼š{file} ({file_size} bytes)")
                            
                        except OSError as e:
                            print(f"âš ï¸ ç„¡æ³•è®€å–æª”æ¡ˆ {file}: {e}")
                            continue
                
                if dir_info['file_count'] > 0:
                    output_info['directories'].append(dir_info)
                    output_info['total_files'] += dir_info['file_count']
                    output_info['total_size'] += dir_info['size']
                    print(f"âœ… ç›®éŒ„ {output_dir} åŒ…å« {dir_info['file_count']} å€‹æª”æ¡ˆ")
                else:
                    print(f"âš ï¸ ç›®éŒ„ {output_dir} æ²’æœ‰æª”æ¡ˆ")
        
        print(f"ğŸ¯ ç¸½çµæœï¼š{output_info['total_files']} å€‹æª”æ¡ˆï¼Œç¸½å¤§å° {output_info['total_size']} bytes")
        
        return JsonResponse(output_info)
        
    except Exception as e:
        print(f"âŒ å–å¾—è¼¸å‡ºè³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        print(traceback.format_exc())
        
        return JsonResponse({
            'error': str(e),
            'has_outputs': False,
            'debug_info': {
                'project_id': str(project.id),
                'project_name': project.name,
                'error_details': traceback.format_exc()
            }
        })

# ä¹Ÿä¿®æ”¹ download_analysis_outputs å‡½æ•¸ï¼Œå¢åŠ æ›´å¥½çš„éŒ¯èª¤è™•ç†

@login_required
def download_analysis_outputs(request, pk):
    """ä¸‹è¼‰å°ˆæ¡ˆçš„åˆ†æè¼¸å‡ºè³‡æ–™å¤¾ - æ”¹é€²ç‰ˆæœ¬"""
    project = get_object_or_404(AnalysisProject, pk=pk, user=request.user)
    
    try:
        import tempfile
        import zipfile
        from datetime import datetime
        from django.http import FileResponse
        
        print(f"ğŸ” é–‹å§‹æº–å‚™ä¸‹è¼‰å°ˆæ¡ˆè¼¸å‡ºï¼š{project.name}")
        
        # å°‹æ‰¾å°ˆæ¡ˆçš„è¼¸å‡ºç›®éŒ„
        output_dirs = _find_project_output_directories(project)
        
        if not output_dirs:
            messages.error(request, 'æ‰¾ä¸åˆ°åˆ†æè¼¸å‡ºæª”æ¡ˆã€‚è«‹æª¢æŸ¥åˆ†ææ˜¯å¦å·²å®Œæˆï¼Œæˆ–æª”æ¡ˆæ˜¯å¦å·²è¢«æ¸…ç†ã€‚')
            return redirect('liquefaction:results', pk=project.pk)
        
        # å‰µå»ºè‡¨æ™‚ZIPæª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as temp_zip:
            temp_zip_path = temp_zip.name
        
        try:
            total_files = 0
            
            with zipfile.ZipFile(temp_zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for output_dir in output_dirs:
                    if os.path.exists(output_dir):
                        print(f"ğŸ“ æ­£åœ¨æ‰“åŒ…ç›®éŒ„ï¼š{output_dir}")
                        
                        # å–å¾—ç›®éŒ„åç¨±ä½œç‚ºZIPå…§çš„æ ¹ç›®éŒ„
                        dir_name = os.path.basename(output_dir) if output_dir != os.path.dirname(output_dir) else "analysis_outputs"
                        
                        # éæ­¸æ·»åŠ ç›®éŒ„ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
                        for root, dirs, files in os.walk(output_dir):
                            for file in files:
                                file_path = os.path.join(root, file)
                                
                                # è¨ˆç®—åœ¨ZIPä¸­çš„ç›¸å°è·¯å¾‘
                                if root == output_dir:
                                    # æª”æ¡ˆåœ¨æ ¹ç›®éŒ„
                                    arcname = os.path.join(dir_name, file)
                                else:
                                    # æª”æ¡ˆåœ¨å­ç›®éŒ„
                                    rel_path = os.path.relpath(file_path, output_dir)
                                    arcname = os.path.join(dir_name, rel_path)
                                
                                zipf.write(file_path, arcname)
                                total_files += 1
                                print(f"ğŸ“„ æ·»åŠ æª”æ¡ˆï¼š{arcname}")
            
            if total_files == 0:
                messages.warning(request, 'åˆ†æè¼¸å‡ºç›®éŒ„ä¸­æ²’æœ‰æª”æ¡ˆ')
                os.unlink(temp_zip_path)
                return redirect('liquefaction:results', pk=project.pk)
            
            print(f"âœ… ç¸½å…±æ‰“åŒ…äº† {total_files} å€‹æª”æ¡ˆ")
            
            # ç”Ÿæˆä¸‹è¼‰æª”å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            download_filename = f"{project.name}_åˆ†æè¼¸å‡º_{timestamp}.zip"
            
            # è¿”å›æª”æ¡ˆéŸ¿æ‡‰
            response = FileResponse(
                open(temp_zip_path, 'rb'),
                as_attachment=True,
                filename=download_filename
            )
            response['Content-Type'] = 'application/zip'
            
            print(f"ğŸ¯ é–‹å§‹ä¸‹è¼‰ï¼š{download_filename}")
            return response
            
        except Exception as e:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_zip_path):
                os.unlink(temp_zip_path)
            raise e
            
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰åˆ†æè¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        import traceback
        print(traceback.format_exc())
        
        messages.error(request, f'ä¸‹è¼‰åˆ†æè¼¸å‡ºæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}')
        return redirect('liquefaction:results', pk=project.pk)

def _format_file_size(size_bytes):
    """æ ¼å¼åŒ–æª”æ¡ˆå¤§å°"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"
