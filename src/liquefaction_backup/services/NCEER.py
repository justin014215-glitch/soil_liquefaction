import numpy as np
import pandas as pd
import logging
import geopandas as gpd
import tkinter as tk
import time
import json
import os
import sys
from pathlib import Path
import traceback
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from enum import Enum
from shapely.geometry import Point
from typing import Dict, Optional, Tuple, Any
from dataclasses import dataclass
from tkinter import filedialog
from pyproj import Transformer
from geopy.geocoders import Nominatim
from geopy.distance import geodesic
from decimal import Decimal, ROUND_HALF_UP
from report import generate_all_wells_excel_reports, generate_all_wells_charts
import tkinter as tk
from tkinter import filedialog
from datetime import datetime

'''
å„åƒæ•¸å–®ä½ï¼š
    çµ±é«”å–®ä½é‡ : (t/m^3)
    SPTä¸Šä¸‹é™æ·±åº¦ : (m) 
    FC : (%)
    PI : (%)
    åœŸå±¤æ·±åº¦ã€åœŸå±¤åšåº¦ã€åœŸå±¤ä¸­é»ã€åˆ†æé» : (m)
    sigma_v : (t/m^2)

'''


def setup_django_paths():
    """è¨­å®š Django è·¯å¾‘ - ç°¡åŒ–ç‰ˆæœ¬"""
    try:
        from django.conf import settings
        # åœ¨ Django ç’°å¢ƒä¸­ï¼Œä¸éœ€è¦ç‰¹åˆ¥è¨­å®šè·¯å¾‘
        pass
    except ImportError:
        # é Django ç’°å¢ƒçš„è™•ç†
        pass
# åœ¨æª”æ¡ˆé–‹é ­å‘¼å«
setup_django_paths()

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # è§£æ±ºä¸­æ–‡é¡¯ç¤ºå•é¡Œ

# å¸¸æ•¸è¨­å®š
g = 9.81  # é‡åŠ›åŠ é€Ÿåº¦ (m/sÂ²)

#è®€å–æª”æ¡ˆ
def get_input_file(input_file_path=None, show_gui=True):
    if input_file_path is None and show_gui:
        try:
            import tkinter as tk
            from tkinter import filedialog
            root = tk.Tk()
            root.withdraw()
            file_path = filedialog.askopenfilename(
                title="è«‹é¸æ“‡è¼¸å…¥çš„ CSV æª”æ¡ˆ",
                filetypes=[("CSV æª”æ¡ˆ", "*.csv")]
            )
            root.destroy()
            print("æ­£åœ¨è®€å–è³‡æ–™...")
        except ImportError:
            # Django ç’°å¢ƒä¸­ä¸ä½¿ç”¨ GUI
            raise ValueError("åœ¨ç¶²é ç’°å¢ƒä¸­å¿…é ˆæä¾› input_file_path")

        if not file_path:
            print("æœªé¸æ“‡æª”æ¡ˆï¼Œç¨‹å¼çµæŸã€‚")
            return None
    elif input_file_path is not None:
        file_path = input_file_path
        if not file_path:
            print("æª”æ¡ˆè®€å–å¤±æ•—")
            return None
    else:
        raise ValueError("å¿…é ˆæä¾› input_file_path æˆ–è¨­å®š show_gui=True")

    return file_path

# æ–°å¢ï¼šå–å¾—çµ±é«”å–®ä½é‡å–®ä½é¸æ“‡
def get_unit_weight_unit():
    """å–å¾—ä½¿ç”¨è€…é¸æ“‡çš„çµ±é«”å–®ä½é‡å–®ä½"""
    print("\n=== çµ±é«”å–®ä½é‡å–®ä½è¨­å®š ===")
    print("è«‹é¸æ“‡æ‚¨çš„è³‡æ–™ä¸­çµ±é«”å–®ä½é‡/çµ±é«”å¯†åº¦çš„å–®ä½ï¼š")
    print("1. t/mÂ³ (å…¬å™¸/ç«‹æ–¹å…¬å°º)")
    print("2. kN/mÂ³ (åƒç‰›é “/ç«‹æ–¹å…¬å°º)")
    
    while True:
        try:
            choice = input("è«‹è¼¸å…¥é¸é … (1 æˆ– 2ï¼Œé è¨­ç‚º 1): ").strip()
            
            if choice == "" or choice == "1":
                print("âœ… é¸æ“‡ï¼št/mÂ³ (ç„¡éœ€è½‰æ›)")
                return "t/m3", 1.0
            elif choice == "2":
                print("âœ… é¸æ“‡ï¼škN/mÂ³ (å°‡é™¤ä»¥ 9.81 è½‰æ›ç‚º t/mÂ³)")
                return "kN/m3", 1.0/9.81
            else:
                print("âŒ è«‹è¼¸å…¥æœ‰æ•ˆé¸é … (1 æˆ– 2)")
                continue
                
        except Exception as e:
            print(f"âŒ è¼¸å…¥éŒ¯èª¤ï¼š{e}")
            continue

# æ”¯æ´çš„åº§æ¨™ç³»çµ±æ¸…å–®
AVAILABLE_CRS = {
    "1": {"name": "TWD97 å°ç£æœ¬å³¶", "epsg": "EPSG:3826"},
    "2": {"name": "TWD97 æ¾æ¹–", "epsg": "EPSG:3825"},
    "3": {"name": "WGS84 ç¶“ç·¯åº¦", "epsg": "EPSG:4326"}
}

#è®€å–.json
def load_json_file(file_path: str) -> Optional[Dict[str, Any]]:
    """å®‰å…¨è¼‰å…¥JSONæª”æ¡ˆ"""
    if not os.path.exists(file_path):
        logger.warning(f"æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{file_path}")
        return None
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            logger.info(f"æˆåŠŸè¼‰å…¥æª”æ¡ˆï¼š{file_path}")
            return data
    except Exception as e:
        logger.error(f"è¼‰å…¥æª”æ¡ˆå¤±æ•— {file_path}: {e}")
        return None

def get_parameter_file_path(filename):
    """å–å¾—åƒæ•¸æª”æ¡ˆçš„çµ•å°è·¯å¾‘"""
    try:
        from django.conf import settings
        return settings.BASE_DIR.parent / "åƒæ•¸" / filename
    except ImportError:
        # é Django ç’°å¢ƒ
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent.parent
        return project_root / "åƒæ•¸" / filename

taiwan_seismic_data = load_json_file(str(get_parameter_file_path("taiwan_seismic_data.json"))) or {}
general_zone_seismic_coefficients = load_json_file(str(get_parameter_file_path("general_zone_seismic_coefficient.json"))) or {}
taipei_basin_zones = load_json_file(str(get_parameter_file_path("taipei_basin_zone.json"))) or {}
fault_distance_parameters = load_json_file(str(get_parameter_file_path("æ–·å±¤åƒæ•¸.json"))) or {}

# å°åŒ—ç›†åœ°å¾®åˆ†å€ä¿‚æ•¸
taipei_basin_seismic_coefficients = {
    'è‡ºåŒ—ä¸€å€': {
        'SD_S': 0.6,
        'SM_S': 0.8,
        'T0_D': 1.60,
        'T0_M': 1.60
    },
    'è‡ºåŒ—äºŒå€': {
        'SD_S': 0.6,
        'SM_S': 0.8,
        'T0_D': 1.30,
        'T0_M': 1.30
    },
    'è‡ºåŒ—ä¸‰å€': {
        'SD_S': 0.6,
        'SM_S': 0.8,
        'T0_D': 1.05,
        'T0_M': 1.05
    }
}

# åŸå¸‚èˆ‡åœ°éœ‡è¦æ¨¡ Mw å°ç…§è¡¨
city_mw_mapping = {
    "åŸºéš†å¸‚": 7.3, "æ–°åŒ—å¸‚": 7.3, "è‡ºåŒ—å¸‚": 7.3, "å®œè˜­ç¸£": 7.3, "èŠ±è“®ç¸£": 7.3, "å°æ±ç¸£": 7.3,
    "æ¡ƒåœ’å¸‚": 7.1, "å°ä¸­å¸‚": 7.1, "å½°åŒ–ç¸£": 7.1, "å—æŠ•ç¸£": 7.1, "é›²æ—ç¸£": 7.1,
    "å˜‰ç¾©ç¸£": 7.1, "å°å—å¸‚": 7.1, "é«˜é›„å¸‚": 7.1,
    "æ–°ç«¹ç¸£": 6.9, "è‹—æ —ç¸£": 6.9, "å±æ±ç¸£": 6.9,
    "æ¾æ¹–ç¸£": 6.7, "é‡‘é–€ç¸£": 6.7, "é¦¬ç¥–ç¸£": 6.7
}

#åœ°éœ‡è¦æ¨¡ä¿®æ­£
earthquake_mw_adjustments = {
    "Design": 0.0,     # è¨­è¨ˆåœ°éœ‡ï¼šä½¿ç”¨åŸºæº–Mwï¼Œä¸èª¿æ•´
    "MidEq": -0.2,     # ä¸­å°åœ°éœ‡ï¼šåŸºæº–Mw - 0.2
    "MaxEq": +0.2      # æœ€å¤§åœ°éœ‡ï¼šåŸºæº–Mw + 0.2
}

#æ ¼å¼åŒ–çµæœåˆ°æŒ‡å®šå°æ•¸ä½æ•¸ï¼ˆä¿®æ­£æµ®é»èª¤å·®)
def format_result(value, decimal_places=3):
    """æ ¼å¼åŒ–çµæœåˆ°æŒ‡å®šå°æ•¸ä½æ•¸ï¼ˆä¿®æ­£æµ®é»èª¤å·®ï¼‰"""
    if pd.isna(value) or value == "-" or value == np.nan:
        return "-"
    try:
        if isinstance(value, float):
            value_dec = Decimal.from_float(value)
        else:
            value_dec = Decimal(str(value))

        quantize_str = "1." + "0" * decimal_places
        return float(value_dec.quantize(Decimal(quantize_str), rounding=ROUND_HALF_UP))
    except (ValueError, TypeError, ArithmeticError):
        return "-"

# å°‡ TW97 åæ¨™è½‰æ›ç‚º WGS84ï¼ˆç¶“ç·¯åº¦ï¼‰
def tw97_to_wgs84(x, y):
    transformer = Transformer.from_crs("EPSG:3826", "EPSG:4326", always_xy=True)
    lon, lat = transformer.transform(x, y)
    return lat, lon

# æ ¹æ“šç¶“ç·¯åº¦å–å¾—åŸå¸‚åç¨±
def get_city_from_coordinates(lat, lon):
    try:
        geolocator = Nominatim(user_agent="tw97_geoapi")
        location = geolocator.reverse((lat, lon), language='zh-TW')
        if location and location.raw.get('address'):
            address = location.raw['address']
            return address.get('city') or address.get('county') or address.get('town')
        return None
    except Exception as e:
        print(f"åœ°ç†ç·¨ç¢¼éŒ¯èª¤ï¼š{e}")
        return None

# æ ¹æ“šåº§æ¨™å–å¾—åŸå¸‚åç¨±èˆ‡åœ°éœ‡è¦æ¨¡ Mw
def generate_earthquake_parameters_from_tw97(x_tw97, y_tw97):
    lat, lon = tw97_to_wgs84(x_tw97, y_tw97)
    city = get_city_from_coordinates(lat, lon)
    
    print("ğŸ”´ WARNING: generate_earthquake_parameters_from_tw97 è¢«å‘¼å«äº†ï¼")
    print("ğŸ”´ å‘¼å«å †ç–Šï¼š")
    traceback.print_stack()

    if city is None:
        print(f"åº§æ¨™ ({x_tw97}, {y_tw97}) æŸ¥ç„¡åŸå¸‚")
        return "æœªçŸ¥åŸå¸‚", 0  

    mw = city_mw_mapping.get(city)
    if mw is None:
        print(f"åŸå¸‚ï¼š{city}ï¼Œä½†æŸ¥è¡¨ç„¡å°æ‡‰ Mw")
        return city, 0

    print(f"åº§æ¨™ ({x_tw97}, {y_tw97}) åŸå¸‚ï¼š{city}ï¼Œæ¨ä¼°åœ°éœ‡è¦æ¨¡ Mw = {mw}")
    return city, mw

# è¨ˆç®—ä¸åŒåœ°éœ‡æƒ…å¢ƒçš„Mwå€¼
def get_scenario_mw(base_mw, scenario):
    """æ ¹æ“šåœ°éœ‡æƒ…å¢ƒèª¿æ•´Mwå€¼ - ä½¿ç”¨åŠ æ¸›æ³•"""
    adjustment = earthquake_mw_adjustments.get(scenario, 0.0)
    adjusted_mw = base_mw + adjustment
    
    # ç¢ºä¿Mwåœ¨åˆç†ç¯„åœå…§ (5.0 ~ 8.5)
    adjusted_mw = max(5.0, min(8.5, adjusted_mw))
    # ä¿®æ­£æµ®é»æ•¸ç²¾åº¦å•é¡Œ
    adjusted_mw = round(adjusted_mw, 1)

    return adjusted_mw



# åˆ¤å®šç¬¦è™Ÿ
def parse_numeric_value(value):
    """è§£ææ•¸å€¼ï¼Œè™•ç† > ç¬¦è™Ÿå’Œç©ºç™½"""
    if pd.isna(value) or value == '' or value is None:
        return None
    
    value_str = str(value).strip()
    
    if value_str == '':
        return None
    
    # è™•ç† > ç¬¦è™Ÿ
    if value_str.startswith('>'):
        try:
            return float(value_str[1:].strip())
        except (ValueError, TypeError):
            return None
    
    # ç›´æ¥è½‰æ›æ•¸å­—
    try:
        return float(value_str)
    except (ValueError, TypeError):
        return None

#æ¨™æº–åŒ–åœ°å€åç¨±ï¼Œç§»é™¤å¸¸è¦‹çš„åœ°å€è®Šé«”
def normalize_address_name(name: str) -> str:
    """æ¨™æº–åŒ–åœ°å€åç¨±ï¼Œç§»é™¤å¸¸è¦‹çš„åœ°å€è®Šé«”"""
    if not name:
        return ""
    
    # ç§»é™¤å¸¸è¦‹çš„åœ°å€å¾Œç¶´å’Œè®Šé«”
    name = name.strip()
    
    # è™•ç†ç¸£å¸‚åç¨±
    city_variants = {
        'å°åŒ—å¸‚': 'è‡ºåŒ—å¸‚',
        'å°ä¸­å¸‚': 'è‡ºä¸­å¸‚',
        'å°å—å¸‚': 'è‡ºå—å¸‚',
        'å°æ±ç¸£': 'è‡ºæ±ç¸£',
    }
    
    for variant, standard in city_variants.items():
        if variant in name:
            name = name.replace(variant, standard)
    
    return name

#å°åŒ—å¾®åˆ†å€æœå°‹ç³»çµ±
def find_taipei_basin_zone(city: str, district: str, village: str = None) -> Optional[str]:
    """å°‹æ‰¾å°åŒ—ç›†åœ°å¾®åˆ†å€ - ä¿®æ­£ç‰ˆæœ¬"""
    logger.info(f"å°‹æ‰¾å°åŒ—ç›†åœ°å¾®åˆ†å€ï¼š{city}-{district}-{village}")
    
    # æ¨™æº–åŒ–åœ°å€åç¨±
    city = normalize_address_name(city)
    district = normalize_address_name(district)
    if village:
        village = normalize_address_name(village)
    
    # åªè™•ç†å°åŒ—å¸‚å’Œæ–°åŒ—å¸‚
    if city not in ['è‡ºåŒ—å¸‚', 'æ–°åŒ—å¸‚']:
        logger.info(f"{city} ä¸åœ¨å°åŒ—ç›†åœ°ç¯„åœå…§")
        return None
    
    # æª¢æŸ¥è©²ç¸£å¸‚æ˜¯å¦åœ¨å°åŒ—ç›†åœ°è³‡æ–™ä¸­
    if city not in taipei_basin_zones:
        logger.warning(f"åœ¨å°åŒ—ç›†åœ°è³‡æ–™ä¸­æ‰¾ä¸åˆ° {city}")
        logger.info(f"å¯ç”¨çš„ç¸£å¸‚åç¨±ï¼š{list(taipei_basin_zones.keys())}")
        return None
    
    # å–å¾—è©²ç¸£å¸‚çš„è³‡æ–™
    city_data = taipei_basin_zones[city]
    logger.info(f"è©²ç¸£å¸‚çš„å¯ç”¨å€åŸŸï¼š{list(city_data.keys())}")
    
    # ç§»é™¤ã€Œå€ã€å­—å¾Œç¶´é€²è¡Œæ¯”å°
    district_key = district.replace('å€', '') if district.endswith('å€') else district
    
    # åœ¨è©²ç¸£å¸‚çš„è¡Œæ”¿å€ä¸­å°‹æ‰¾åŒ¹é… - æ›´éˆæ´»çš„åŒ¹é…æ–¹å¼
    matching_districts = []
    for dist_key in city_data.keys():
        # å˜—è©¦å¤šç¨®åŒ¹é…æ–¹å¼
        if (district_key in dist_key or 
            dist_key in district_key or
            district in dist_key or
            dist_key in district or
            district_key == dist_key.replace('å€', '') or
            dist_key == district_key.replace('å€', '')):
            matching_districts.append(dist_key)
    
    if not matching_districts:
        logger.warning(f"åœ¨å°åŒ—ç›†åœ°è³‡æ–™ä¸­æ‰¾ä¸åˆ° {city} çš„ {district}")
        logger.info(f"å¯ç”¨çš„å€åŸŸåç¨±ï¼š{list(city_data.keys())}")
        return None
    
    # ä½¿ç”¨æœ€åŒ¹é…çš„å€
    best_match_district = min(matching_districts, key=lambda x: abs(len(x) - len(district_key)))
    district_zones = city_data[best_match_district]
    
    logger.info(f"æ‰¾åˆ°åŒ¹é…çš„å€åŸŸï¼š{city}-{best_match_district}ï¼Œå¯ç”¨å¾®åˆ†å€ï¼š{list(district_zones.keys())}")
    
    # å¦‚æœæœ‰é‡Œçš„è³‡è¨Šï¼Œå˜—è©¦æ‰¾åˆ°å°æ‡‰çš„å¾®åˆ†å€
    if village:
        for zone_name, village_list in district_zones.items():
            # æª¢æŸ¥é‡Œåæ˜¯å¦åœ¨æ‘é‡Œæ¸…å–®ä¸­
            if village in village_list:
                logger.info(f"æ‰¾åˆ°ç²¾ç¢ºåŒ¹é…çš„å¾®åˆ†å€ï¼š{zone_name}")
                return zone_name
            
            # ä¹Ÿå˜—è©¦ç§»é™¤ã€Œé‡Œã€å­—çš„åŒ¹é…
            village_without_suffix = village.replace('é‡Œ', '') if village.endswith('é‡Œ') else village
            for v in village_list:
                v_without_suffix = v.replace('é‡Œ', '') if v.endswith('é‡Œ') else v
                if village_without_suffix == v_without_suffix:
                    logger.info(f"æ‰¾åˆ°åŒ¹é…çš„å¾®åˆ†å€ï¼ˆç§»é™¤é‡Œå­—å¾Œï¼‰ï¼š{zone_name}")
                    return zone_name
        
        logger.warning(f"åœ¨ {city}-{best_match_district} çš„å¾®åˆ†å€ä¸­æ‰¾ä¸åˆ°é‡Œ {village}")
        # åˆ—å‡ºè©²å€æ‰€æœ‰å¾®åˆ†å€å’Œé‡Œä¾›åƒè€ƒ
        for zone_name, village_list in district_zones.items():
            logger.info(f"  {zone_name}: {len(village_list)}å€‹é‡Œ - {village_list[:5]}...")
    
    # å¦‚æœæ²’æœ‰é‡Œçš„è³‡è¨Šæˆ–æ‰¾ä¸åˆ°ç²¾ç¢ºåŒ¹é…ï¼Œå›å‚³ç¬¬ä¸€å€‹å¾®åˆ†å€
    default_zone = list(district_zones.keys())[0]
    logger.info(f"ä½¿ç”¨é è¨­å¾®åˆ†å€ï¼š{default_zone}")
    return default_zone

#åˆ©ç”¨é€†åœ°ç†ç·¨ç¢¼æœå°‹åœ°å€
def enhanced_geocoding(lat: float, lon: float) -> Dict[str, str]:
    """å¢å¼·çš„é€†åœ°ç†ç·¨ç¢¼ï¼Œå˜—è©¦å¤šç¨®æ–¹å¼è§£æåœ°å€"""
    geolocator = Nominatim(user_agent="tw-seismic-query", timeout=10)
    
    try:
        # ç¬¬ä¸€æ¬¡å˜—è©¦ï¼šæ¨™æº–é€†åœ°ç†ç·¨ç¢¼
        location = geolocator.reverse((lat, lon), language="zh-TW", exactly_one=True)
        time.sleep(1)  # é¿å… API é™åˆ¶
        
        if not location:
            raise Exception("ç„¡æ³•å–å¾—åœ°ç†ä½ç½®è³‡è¨Š")
        
        logger.info(f"åœ°ç†æŸ¥è©¢çµæœï¼š{location.address}")
        
        # è§£æåœ°å€
        addr = location.raw.get("address", {})
        full_address = location.address
        
        # å…ˆå–å¾—ç¸£å¸‚è³‡è¨Š
        city = None
        for field in ["state", "county", "province", "city"]:
            if addr.get(field):
                city = normalize_address_name(addr[field])
                break
        
        # ç‰¹åˆ¥è™•ç†æ¡ƒåœ’å¸‚å’Œè‡ºå—å¸‚
        if city in ["æ¡ƒåœ’å¸‚", "è‡ºå—å¸‚"]:
            return parse_taoyuan_tainan_address(full_address, addr, city)
        
        # å…¶ä»–ç¸£å¸‚çš„åŸæœ‰è™•ç†é‚è¼¯
        # å˜—è©¦å¤šç¨®æ¬„ä½ä¾†å–å¾—å€é„‰é®è³‡è¨Š
        district = None
        for field in ["suburb", "town", "city_district", "municipality", "neighbourhood"]:
            if addr.get(field):
                district = normalize_address_name(addr[field])
                break
        
        # å–å¾—é‡Œçš„è³‡è¨Š
        village = None
        for field in ["neighbourhood", "hamlet", "quarter"]:
            if addr.get(field):
                village = normalize_address_name(addr[field])
                break
        
        return {
            "city": city,
            "district": district,
            "village": village,
            "full_address": full_address
        }
    
    except Exception as e:
        logger.error(f"åœ°ç†æŸ¥è©¢å¤±æ•—ï¼š{e}")
        raise Exception(f"åœ°ç†æŸ¥è©¢æœå‹™éŒ¯èª¤ï¼š{e}")

#å„ªåŒ–å°å—å’Œæ¡ƒåœ’æœå°‹å•é¡Œ
def parse_taoyuan_tainan_address(full_address: str, addr: dict, city: str) -> Dict[str, str]:
    """å°ˆé–€è§£ææ¡ƒåœ’å¸‚å’Œè‡ºå—å¸‚çš„åœ°å€"""
    logger.info(f"ä½¿ç”¨å°ˆé–€è§£æå™¨è™•ç† {city} åœ°å€")
    
    # æ–¹æ³•1ï¼šå¾å®Œæ•´åœ°å€å­—ä¸²è§£æ
    district, village = parse_address_string(full_address, city)
    
    if district:
        logger.info(f"å¾åœ°å€å­—ä¸²è§£ææˆåŠŸï¼š{city} -> {district} -> {village}")
        return {
            "city": city,
            "district": district,
            "village": village,
            "full_address": full_address
        }
    
    # æ–¹æ³•2ï¼šå¾APIå›å‚³çš„çµæ§‹åŒ–è³‡æ–™è§£æ
    district, village = parse_structured_address(addr, city)
    
    logger.info(f"å¾çµæ§‹åŒ–è³‡æ–™è§£æï¼š{city} -> {district} -> {village}")
    return {
        "city": city,
        "district": district,
        "village": village,
        "full_address": full_address
    }

#å¾å®Œæ•´åœ°å€å­—ä¸²è§£æå€å’Œé‡Œ
def parse_address_string(full_address: str, city: str) -> Tuple[Optional[str], Optional[str]]:
    """å¾å®Œæ•´åœ°å€å­—ä¸²è§£æå€å’Œé‡Œ"""
    import re
    
    try:
        # ç§»é™¤ç¸£å¸‚åç¨±ï¼Œå°ˆæ³¨æ–¼å¾Œé¢çš„éƒ¨åˆ†
        address_parts = full_address.replace(city, "").strip()
        
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æ‰¾å‡ºå€å’Œé‡Œ
        # æ¨¡å¼ï¼šå°‹æ‰¾ã€ŒæŸæŸå€ã€å’Œã€ŒæŸæŸé‡Œã€
        district_pattern = r'([^,ï¼Œ\s]+å€)'
        village_pattern = r'([^,ï¼Œ\s]+é‡Œ)'
        
        district_matches = re.findall(district_pattern, address_parts)
        village_matches = re.findall(village_pattern, address_parts)
        
        district = district_matches[0] if district_matches else None
        village = village_matches[0] if village_matches else None
        
        logger.info(f"åœ°å€å­—ä¸²è§£æçµæœï¼šå€={district}, é‡Œ={village}")
        
        # é©—è­‰çµæœçš„åˆç†æ€§
        if district and village:
            # ç¢ºä¿å€åä¸æ˜¯é‡Œå
            if not district.endswith('é‡Œ'):
                return district, village
        
        return None, None
        
    except Exception as e:
        logger.warning(f"åœ°å€å­—ä¸²è§£æå¤±æ•—ï¼š{e}")
        return None, None

#é‡å°å°å—å’Œæ¡ƒåœ’å•é¡Œè§£æ±º
def parse_structured_address(addr: dict, city: str) -> Tuple[Optional[str], Optional[str]]:
    """å¾çµæ§‹åŒ–åœ°å€è³‡æ–™è§£æå€å’Œé‡Œ"""
    district = None
    village = None
    
    # å„ªå…ˆé †åºèª¿æ•´ï¼šå…ˆæ‰¾å€ç´šè¡Œæ”¿å–®ä½
    # æ¡ƒåœ’å¸‚å’Œè‡ºå—å¸‚éƒ½æ˜¯ç›´è½„å¸‚ï¼Œä¸‹è½„å€
    district_fields = ["suburb", "city_district", "town", "municipality"]
    village_fields = ["neighbourhood", "hamlet", "quarter"]
    
    # æ‰¾å€
    for field in district_fields:
        if addr.get(field):
            candidate = normalize_address_name(addr[field])
            # ç¢ºä¿æ˜¯å€è€Œä¸æ˜¯é‡Œ
            if candidate.endswith('å€') and not candidate.endswith('é‡Œ'):
                district = candidate
                logger.info(f"å¾ {field} æ¬„ä½æ‰¾åˆ°å€ï¼š{district}")
                break
    
    # æ‰¾é‡Œ
    for field in village_fields:
        if addr.get(field):
            candidate = normalize_address_name(addr[field])
            # ç¢ºä¿æ˜¯é‡Œè€Œä¸æ˜¯å€ï¼Œä¸”ä¸æ˜¯å·²ç¶“è¢«è­˜åˆ¥ç‚ºå€çš„åç¨±
            if candidate.endswith('é‡Œ') and candidate != district:
                village = candidate
                logger.info(f"å¾ {field} æ¬„ä½æ‰¾åˆ°é‡Œï¼š{village}")
                break
    
    # å¦‚æœä»ç„¶æ²’æ‰¾åˆ°å€ï¼Œå˜—è©¦å¾æ‰€æœ‰æ¬„ä½ä¸­æ‰¾å°‹
    if not district:
        logger.warning(f"æœªåœ¨æ¨™æº–æ¬„ä½æ‰¾åˆ°å€ï¼Œå˜—è©¦æ‰€æœ‰æ¬„ä½")
        for field, value in addr.items():
            if value and isinstance(value, str):
                candidate = normalize_address_name(value)
                if candidate.endswith('å€') and not candidate.endswith('é‡Œ'):
                    district = candidate
                    logger.info(f"å¾ {field} æ¬„ä½æ‰¾åˆ°å€ï¼š{district}")
                    break
    
    # å¦‚æœä»ç„¶æ²’æ‰¾åˆ°é‡Œï¼Œå˜—è©¦å¾æ‰€æœ‰æ¬„ä½ä¸­æ‰¾å°‹
    if not village:
        logger.warning(f"æœªåœ¨æ¨™æº–æ¬„ä½æ‰¾åˆ°é‡Œï¼Œå˜—è©¦æ‰€æœ‰æ¬„ä½")
        for field, value in addr.items():
            if value and isinstance(value, str):
                candidate = normalize_address_name(value)
                if candidate.endswith('é‡Œ') and candidate != district:
                    village = candidate
                    logger.info(f"å¾ {field} æ¬„ä½æ‰¾åˆ°é‡Œï¼š{village}")
                    break
    
    logger.info(f"çµæ§‹åŒ–è³‡æ–™è§£æçµæœï¼šå€={district}, é‡Œ={village}")
    
    # æœ€å¾Œé©—è­‰ï¼šç¢ºä¿å€å’Œé‡Œä¸ç›¸åŒ
    if district == village:
        logger.warning(f"å€å’Œé‡Œç›¸åŒ({district})ï¼Œæ¸…é™¤é‡Œçš„è³‡è¨Š")
        village = None
    
    return district, village


###æ–·å±¤æŸ¥è©¢    
def get_fault_based_parameters(fault_name: str, distance_km: float, city: str, district: str) -> Optional[Dict[str, Any]]:
    """
    æ ¹æ“šæ–·å±¤è·é›¢å–å¾—åœ°éœ‡åƒæ•¸ - åŠ å…¥å…§æ’åŠŸèƒ½
    
    Args:
        fault_name: æ–·å±¤åç¨±
        distance_km: è·é›¢æ–·å±¤çš„è·é›¢(å…¬é‡Œ)
        city: ç¸£å¸‚åç¨±
        district: é„‰é®å€åç¨±
    
    Returns:
        æ–·å±¤ç›¸é—œçš„åœ°éœ‡åƒæ•¸ï¼Œå¦‚æœ r>14 æˆ–æ‰¾ä¸åˆ°å‰‡å›å‚³ None
    """
    # æ¢ä»¶ï¼šè‹¥ r>14 å‰‡ä¸éœ€è¦æŸ¥è©¢èˆ‡æ–·å±¤ç›¸é—œçš„åƒæ•¸
    if distance_km > 14:
        logger.info(f"è·é›¢ {distance_km:.2f} km > 14 kmï¼Œè·³éæ–·å±¤åƒæ•¸æŸ¥è©¢")
        return None
    
    # å°‹æ‰¾åŒ¹é…çš„æ–·å±¤è¨˜éŒ„
    matching_records = []
    for record in fault_distance_parameters:
        record_fault_name = record["æ–·å±¤åç¨±"]
        
        # æ¨¡ç³ŠåŒ¹é…æ–·å±¤åç¨±
        if (fault_name in record_fault_name or 
            record_fault_name in fault_name or
            fault_name.replace('æ–·å±¤', '') in record_fault_name or
            record_fault_name.replace('æ–·å±¤', '') in fault_name):
            
            # æª¢æŸ¥å°æ‡‰é„‰é®æ˜¯å¦åŒ¹é…
            target_areas = record["å°æ‡‰é„‰é®"]
            if city in target_areas and district in target_areas:
                matching_records.append(record)
    
    if not matching_records:
        logger.warning(f"åœ¨æ–·å±¤åƒæ•¸ä¸­æ‰¾ä¸åˆ° {fault_name} å°æ‡‰ {city}-{district} çš„è¨˜éŒ„")
        return None
    
    # å°‡è·é›¢ç¯„åœè½‰æ›ç‚ºæ•¸å€¼é€²è¡Œå…§æ’
    distance_ranges = {
        "<=1": 1.0,     # ä¿®æ”¹ï¼šä½¿ç”¨ 1.0 ä½œç‚º <=1 çš„ä»£è¡¨å€¼
        "3": 3.0,
        "5": 5.0,
        "7": 7.0,
        "9": 9.0,
        "11": 11.0,
        "13": 13.0,
        ">=14": 14.0    # ä½¿ç”¨ 14.0 ä½œç‚º >=14 çš„ä»£è¡¨å€¼
    }
    
    # å»ºç«‹è·é›¢-åƒæ•¸å°æ‡‰è¡¨
    distance_params = {}
    for record in matching_records:
        r_range = record["r"]
        if r_range in distance_ranges:
            dist_key = distance_ranges[r_range]
            distance_params[dist_key] = {
                "SDS": float(record["SDS"]),
                "SD1": float(record["SD1"]),
                "SMS": float(record["SMS"]),
                "SM1": float(record["SM1"]),
                "åŸå§‹ç¯„åœ": r_range
            }
    
    if not distance_params:
        logger.warning(f"æ²’æœ‰å¯ç”¨çš„è·é›¢åƒæ•¸é€²è¡Œå…§æ’")
        return None
    
    # æ’åºè·é›¢é»
    sorted_distances = sorted(distance_params.keys())
    
    # å¦‚æœå¯¦éš›è·é›¢å°æ–¼ç­‰æ–¼æœ€å°è·é›¢ï¼Œä½¿ç”¨æœ€å°è·é›¢çš„åƒæ•¸
    if distance_km <= sorted_distances[0]:
        closest_dist = sorted_distances[0]
        params = distance_params[closest_dist]
        logger.info(f"ä½¿ç”¨æœ€å°è·é›¢åƒæ•¸: r={params['åŸå§‹ç¯„åœ']}")
        
        return {
            "æ–·å±¤åç¨±": fault_name,
            "r": params['åŸå§‹ç¯„åœ'],
            "å°æ‡‰é„‰é®": f"[{city}] {district}",
            "SDS": params["SDS"],
            "SD1": params["SD1"],
            "SMS": params["SMS"],
            "SM1": params["SM1"],
            "å…§æ’æ–¹æ³•": "ä½¿ç”¨æœ€å°è·é›¢"
        }
    
    # å¦‚æœå¯¦éš›è·é›¢å¤§æ–¼ç­‰æ–¼æœ€å¤§è·é›¢ï¼Œä½¿ç”¨æœ€å¤§è·é›¢çš„åƒæ•¸
    if distance_km >= sorted_distances[-1]:
        closest_dist = sorted_distances[-1]
        params = distance_params[closest_dist]
        logger.info(f"ä½¿ç”¨æœ€å¤§è·é›¢åƒæ•¸: r={params['åŸå§‹ç¯„åœ']}")
        
        return {
            "æ–·å±¤åç¨±": fault_name,
            "r": params['åŸå§‹ç¯„åœ'],
            "å°æ‡‰é„‰é®": f"[{city}] {district}",
            "SDS": params["SDS"],
            "SD1": params["SD1"],
            "SMS": params["SMS"],
            "SM1": params["SM1"],
            "å…§æ’æ–¹æ³•": "ä½¿ç”¨æœ€å¤§è·é›¢"
        }
    
    # æ‰¾åˆ°å¯¦éš›è·é›¢æ‰€åœ¨çš„å€é–“é€²è¡Œç·šæ€§å…§æ’
    for i in range(len(sorted_distances) - 1):
        lower_dist = sorted_distances[i]
        upper_dist = sorted_distances[i + 1]
        
        if lower_dist <= distance_km <= upper_dist:
            lower_params = distance_params[lower_dist]
            upper_params = distance_params[upper_dist]
            
            # è¨ˆç®—å…§æ’æ¬Šé‡
            if upper_dist == lower_dist:
                # é¿å…é™¤é›¶éŒ¯èª¤
                weight = 0.5
            else:
                weight = (distance_km - lower_dist) / (upper_dist - lower_dist)
            
            # ç·šæ€§å…§æ’å„åƒæ•¸
            interpolated_params = {}
            for param in ["SDS", "SD1", "SMS", "SM1"]:
                lower_val = lower_params[param]
                upper_val = upper_params[param]
                interpolated_val = lower_val + weight * (upper_val - lower_val)
                interpolated_params[param] = round(interpolated_val, 3)
            
            logger.info(f"ç·šæ€§å…§æ’: {lower_params['åŸå§‹ç¯„åœ']} ({lower_dist}) â† {distance_km:.2f} â†’ {upper_params['åŸå§‹ç¯„åœ']} ({upper_dist}), æ¬Šé‡={weight:.3f}")
            
            return {
                "æ–·å±¤åç¨±": fault_name,
                "r": f"{lower_params['åŸå§‹ç¯„åœ']}~{upper_params['åŸå§‹ç¯„åœ']}",
                "å°æ‡‰é„‰é®": f"[{city}] {district}",
                "SDS": interpolated_params["SDS"],
                "SD1": interpolated_params["SD1"],
                "SMS": interpolated_params["SMS"],
                "SM1": interpolated_params["SM1"],
                "å…§æ’æ–¹æ³•": f"ç·šæ€§å…§æ’ (æ¬Šé‡={weight:.3f})",
                "å…§æ’ç¯„åœ": f"{lower_params['åŸå§‹ç¯„åœ']} â† {distance_km:.2f}km â†’ {upper_params['åŸå§‹ç¯„åœ']}",
                "ä¸‹ç•Œåƒæ•¸": f"SDS={lower_params['SDS']}, SD1={lower_params['SD1']}, SMS={lower_params['SMS']}, SM1={lower_params['SM1']}",
                "ä¸Šç•Œåƒæ•¸": f"SDS={upper_params['SDS']}, SD1={upper_params['SD1']}, SMS={upper_params['SMS']}, SM1={upper_params['SM1']}"
            }
    
    logger.warning(f"æ‰¾ä¸åˆ°è·é›¢ {distance_km:.2f} km å°æ‡‰çš„åƒæ•¸ç¯„åœ")
    return None


def compute_distances_to_faults(x: float, y: float, source_epsg: str, faults_gdf: gpd.GeoDataFrame) -> dict:
    """
    è¨ˆç®—é»åˆ°å„æ–·å±¤ç·šçš„æœ€è¿‘è·é›¢
    é‡å°åœ°èª¿æ‰€æ–·å±¤è³‡æ–™æ ¼å¼å„ªåŒ–
    """
    # çµ±ä¸€ä½¿ç”¨ TWD97 æŠ•å½±åº§æ¨™ç³»çµ±é€²è¡Œç²¾ç¢ºè¨ˆç®—
    target_epsg = "EPSG:3826"
    
    # æ­¥é©Ÿ1: å°‡è¼¸å…¥åº§æ¨™è½‰æ›ç‚º TWD97
    if source_epsg != target_epsg:
        transformer = Transformer.from_crs(source_epsg, target_epsg, always_xy=True)
        x_proj, y_proj = transformer.transform(x, y)
    else:
        x_proj, y_proj = x, y
    
    # æ­¥é©Ÿ2: ç¢ºä¿æ–·å±¤è³‡æ–™ä¹Ÿæ˜¯ TWD97
    if faults_gdf.crs is None:
        logger.warning("æ–·å±¤è³‡æ–™æ²’æœ‰åº§æ¨™ç³»çµ±è³‡è¨Šï¼Œå‡è¨­ç‚º TWD97")
        faults_proj = faults_gdf.copy()
    elif faults_gdf.crs.to_epsg() != 3826:
        logger.info(f"å°‡æ–·å±¤è³‡æ–™å¾ {faults_gdf.crs} è½‰æ›ç‚º TWD97")
        faults_proj = faults_gdf.to_crs(target_epsg)
    else:
        faults_proj = faults_gdf.copy()
    
    # æ­¥é©Ÿ3: å»ºç«‹æŸ¥è©¢é»
    point = Point(x_proj, y_proj)
    
    # æ­¥é©Ÿ4: æ ¹æ“šåœ°èª¿æ‰€è³‡æ–™æ ¼å¼é¸æ“‡æ­£ç¢ºçš„æ–·å±¤åç¨±æ¬„ä½
    name_col = None
    if 'FAULT_NAME' in faults_proj.columns:
        name_col = 'FAULT_NAME'
        logger.info("ä½¿ç”¨ FAULT_NAME æ¬„ä½ä½œç‚ºæ–·å±¤åç¨±")
    elif 'E_NAME' in faults_proj.columns:
        name_col = 'E_NAME'
        logger.info("ä½¿ç”¨ E_NAME æ¬„ä½ä½œç‚ºæ–·å±¤åç¨±")
    elif 'Fault_No_3' in faults_proj.columns:
        name_col = 'Fault_No_3'
        logger.info("ä½¿ç”¨ Fault_No_3 æ¬„ä½ä½œç‚ºæ–·å±¤åç¨±")
    else:
        logger.warning("æœªæ‰¾åˆ°é©ç•¶çš„æ–·å±¤åç¨±æ¬„ä½")
        return {}
    
    # æ­¥é©Ÿ5: è¨ˆç®—è·é›¢ä¸¦æŒ‰æ–·å±¤åç¨±åˆ†çµ„
    fault_distances = {}
    
    for idx, row in faults_proj.iterrows():
        fault_geom = row.geometry
        
        # è¨ˆç®—é»åˆ°ç·šçš„æœ€çŸ­è·é›¢ï¼ˆå–®ä½ï¼šå…¬å°ºï¼‰
        distance_m = fault_geom.distance(point)
        distance_km = distance_m / 1000.0
        
        # å–å¾—æ–·å±¤åç¨±
        if name_col and pd.notna(row[name_col]):
            fault_name = str(row[name_col]).strip()
        else:
            fault_name = f"æ–·å±¤_{idx+1}"
        
        # å¦‚æœè©²æ–·å±¤å·²å­˜åœ¨ï¼Œä¿ç•™è¼ƒè¿‘çš„è·é›¢ï¼ˆå› ç‚ºæ–·å±¤å¯èƒ½æœ‰å¤šå€‹ç·šæ®µï¼‰
        if fault_name in fault_distances:
            fault_distances[fault_name] = min(fault_distances[fault_name], distance_km)
        else:
            fault_distances[fault_name] = distance_km
    
    return fault_distances

#å¾æª”æ¡ˆä¸­çš„é‘½å­”åº§æ¨™ç²å–åœ°éœ‡åƒæ•¸
def coordinate_search_from_file(x_tw97: float, y_tw97: float, use_fault_data: bool = False, fault_gdf=None) -> Optional[Dict[str, Any]]:
    """ä½¿ç”¨æª”æ¡ˆä¸­çš„TWD97åº§æ¨™é€²è¡Œåº§æ¨™æœå°‹"""
    try:
        print(f"æ­£åœ¨æŸ¥è©¢åº§æ¨™ ({x_tw97}, {y_tw97}) çš„åœ°éœ‡åƒæ•¸...")
        
        # æ­¥é©Ÿ1: å°‡ TWD97 åº§æ¨™è½‰æ›ç‚º WGS84
        lat, lon = tw97_to_wgs84(x_tw97, y_tw97)
        print(f"  è½‰æ›ç‚º WGS84: ({lat:.6f}, {lon:.6f})")
        
        # æ­¥é©Ÿ2: ä½¿ç”¨å¢å¼·åœ°ç†ç·¨ç¢¼ç²å–åœ°å€è³‡è¨Š
        try:
            geo_info = enhanced_geocoding(lat, lon)  # ä½¿ç”¨åŸæœ‰çš„å‡½æ•¸
            city = geo_info.get('city')
            district = geo_info.get('district') 
            village = geo_info.get('village')
            
            print(f"  åœ°ç†ç·¨ç¢¼çµæœ: {city} - {district} - {village}")
            
            if not city:
                print(f"  ç„¡æ³•ç²å–åŸå¸‚è³‡è¨Š")
                return None
                
        except Exception as e:
            print(f"  åœ°ç†ç·¨ç¢¼å¤±æ•—: {e}")
            return None
        
        # æ­¥é©Ÿ3: æ–°å¢æ–·å±¤è·é›¢åƒæ•¸æŸ¥è©¢ (æœ€é«˜å„ªå…ˆé †åº)
        result = None
        
        if use_fault_data and fault_gdf is not None:
            try:
                print(f"  æ­£åœ¨è¨ˆç®—æ–·å±¤è·é›¢...")
                # ä¿®æ”¹ï¼šä½¿ç”¨æ­£ç¢ºçš„å‡½æ•¸å‘¼å«æ–¹å¼
                distances = compute_distances_to_faults(x_tw97, y_tw97, "EPSG:3826", fault_gdf)
                
                if distances:
                    nearest_fault, min_distance = min(distances.items(), key=lambda item: item[1])
                    print(f"  æœ€è¿‘æ–·å±¤: {nearest_fault} ({min_distance:.2f} km)")
                    
                    # å¦‚æœè·é›¢â‰¤14kmï¼ŒæŸ¥è©¢æ–·å±¤è·é›¢åƒæ•¸
                    if min_distance <= 14:
                        print(f"  æŸ¥è©¢æ–·å±¤è·é›¢åƒæ•¸...")
                        fault_params = get_fault_based_parameters(nearest_fault, min_distance, city, district)
                        if fault_params:
                            result = {
                                'ç¸£å¸‚': city,
                                'é„‰é®/å€': district,
                                'é‡Œ': village or "",
                                'å¾®åˆ†å€': "",
                                'SDS': fault_params.get('SDS'),
                                'SMS': fault_params.get('SMS'),
                                'SD1': fault_params.get('SD1'),
                                'SM1': fault_params.get('SM1'),
                                'é„°è¿‘ä¹‹æ–·å±¤': f"{nearest_fault} ({min_distance:.2f} km)",
                                'è³‡æ–™ä¾†æº': f'æ–·å±¤è·é›¢åƒæ•¸ (r={fault_params.get("r", "")})'
                            }
                            print(f"  âœ… ä½¿ç”¨æ–·å±¤è·é›¢åƒæ•¸: r={fault_params.get('r')}")
                            return result
                        else:
                            print(f"  æœªæ‰¾åˆ°å°æ‡‰çš„æ–·å±¤è·é›¢åƒæ•¸")
                    else:
                        print(f"  è·é›¢ {min_distance:.2f}km > 14kmï¼Œä¸ä½¿ç”¨æ–·å±¤è·é›¢åƒæ•¸")
                else:
                    print(f"  æœªè¨ˆç®—å‡ºæ–·å±¤è·é›¢")
                        
            except Exception as e:
                print(f"  æ–·å±¤è·é›¢åƒæ•¸æŸ¥è©¢å¤±æ•—: {e}")
        
        # æ­¥é©Ÿ4: å„ªå…ˆæŸ¥è©¢å°åŒ—ç›†åœ°å¾®åˆ†å€
        if not result and city in ['è‡ºåŒ—å¸‚', 'æ–°åŒ—å¸‚'] and district:
            taipei_zone = find_taipei_basin_zone(city, district, village)
            if taipei_zone:
                print(f"  æ‰¾åˆ°å°åŒ—ç›†åœ°å¾®åˆ†å€: {taipei_zone}")
                coefficients = taipei_basin_seismic_coefficients.get(taipei_zone, {})
                result = {
                    'ç¸£å¸‚': city,
                    'é„‰é®/å€': district,
                    'é‡Œ': village or "",
                    'å¾®åˆ†å€': taipei_zone,
                    'SDS': coefficients.get('SD_S'),  # å°åŒ—ç›†åœ°ä½¿ç”¨SD_S
                    'SMS': coefficients.get('SM_S'),  # å°åŒ—ç›†åœ°ä½¿ç”¨SM_S
                    'SD1': coefficients.get('SD1', None),
                    'SM1': coefficients.get('SM1', None),
                    'é„°è¿‘ä¹‹æ–·å±¤': "",
                    'è³‡æ–™ä¾†æº': 'å°åŒ—ç›†åœ°å¾®åˆ†å€'
                }
        
        # æ­¥é©Ÿ5: å¦‚æœæ²’æœ‰æ‰¾åˆ°å°åŒ—ç›†åœ°è³‡æ–™ï¼ŒæŸ¥è©¢ä¸€èˆ¬éœ‡å€è³‡æ–™
        if not result:
            print(f"  æŸ¥è©¢ä¸€èˆ¬éœ‡å€è³‡æ–™...")
            # æŸ¥è©¢ä¸€èˆ¬éœ‡å€ä¿‚æ•¸
            city_data = general_zone_seismic_coefficients.get(city, {})
            if city_data and district:
                district_data = city_data.get(district, {})
                if district_data and village:
                    village_data = district_data.get(village, {})
                    if village_data:
                        result = {
                            'ç¸£å¸‚': city,
                            'é„‰é®/å€': district,
                            'é‡Œ': village,
                            'å¾®åˆ†å€': "",
                            'SDS': village_data.get('SDS'),
                            'SMS': village_data.get('SMS'),
                            'SD1': village_data.get('SD1'),
                            'SM1': village_data.get('SM1'),
                            'é„°è¿‘ä¹‹æ–·å±¤': village_data.get('é„°è¿‘ä¹‹æ–·å±¤', ""),
                            'è³‡æ–™ä¾†æº': 'ä¸€èˆ¬éœ‡å€è³‡æ–™'
                        }
        
        # æ­¥é©Ÿ6: å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é è¨­å€¼
        if not result:
            print(f"  ä½¿ç”¨é è¨­åœ°éœ‡åƒæ•¸")
            result = {
                'ç¸£å¸‚': city,
                'é„‰é®/å€': district or "",
                'é‡Œ': village or "",
                'å¾®åˆ†å€': "",
                'SDS': 0.8,  # é è¨­å€¼
                'SMS': 1.0,  # é è¨­å€¼
                'SD1': None,
                'SM1': None,
                'é„°è¿‘ä¹‹æ–·å±¤': "",
                'è³‡æ–™ä¾†æº': 'é è¨­å€¼'
            }
        
        # æ­¥é©Ÿ7: æ·»åŠ æ–·å±¤è·é›¢è³‡è¨Š (ä¸å½±éŸ¿ä¸»è¦åƒæ•¸é¸æ“‡)
        if use_fault_data and fault_gdf is not None and result:
            try:
                distances = compute_distances_to_faults(x_tw97, y_tw97, "EPSG:3826", fault_gdf)
                if distances:
                    nearest_fault, min_distance = min(distances.items(), key=lambda item: item[1])
                    original_fault = result.get("é„°è¿‘ä¹‹æ–·å±¤", "")
                    if original_fault and original_fault.strip():
                        result["é„°è¿‘ä¹‹æ–·å±¤"] = f"{original_fault} (æœ€è¿‘æ–·å±¤: {nearest_fault} {min_distance:.2f} km)"
                    else:
                        result["é„°è¿‘ä¹‹æ–·å±¤"] = f"{nearest_fault} ({min_distance:.2f} km)"
            except Exception as e:
                print(f"  è¨ˆç®—æ–·å±¤è·é›¢å¤±æ•—: {e}")
        
        if result:
            print(f"  æŸ¥è©¢æˆåŠŸï¼š{result['ç¸£å¸‚']} - {result['é„‰é®/å€']}")
            if 'SDS' in result and 'SMS' in result:
                print(f"  SDS: {result['SDS']}, SMS: {result['SMS']}")
            return result
        else:
            print(f"  åº§æ¨™ ({x_tw97}, {y_tw97}) æŸ¥è©¢å¤±æ•—")
            return None
            
    except Exception as e:
        logger.error(f"åº§æ¨™æœå°‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        print(f"åº§æ¨™æœå°‹éŒ¯èª¤ï¼š{e}")
        return None
def get_earthquake_parameters_from_wells(df: pd.DataFrame, use_fault_data: bool = False, fault_gdf=None) -> Dict[str, Dict[str, Any]]:
    """å¾æª”æ¡ˆä¸­çš„é‘½å­”åº§æ¨™ç²å–åœ°éœ‡åƒæ•¸"""
    well_params = {}
    unique_wells_data = df.groupby('é‘½å­”ç·¨è™Ÿ')[['TWD97_X', 'TWD97_Y']].first()
    well_ids = unique_wells_data.index.tolist()
    
    print(f"\n=== æ­£åœ¨ç²å– {len(well_ids)} å€‹é‘½å­”çš„åœ°éœ‡åƒæ•¸ ===")
    
    for i, well_id in enumerate(well_ids, 1):
        print(f"\né€²åº¦ [{i}/{len(well_ids)}] è™•ç†é‘½å­”ï¼š{well_id}")
        
        # å–å¾—è©²é‘½å­”çš„åº§æ¨™
        well_data = df[df['é‘½å­”ç·¨è™Ÿ'] == well_id].iloc[0]
        x_tw97 = well_data['TWD97_X']
        y_tw97 = well_data['TWD97_Y']
        
        print(f"  TWD97åº§æ¨™ï¼š({x_tw97}, {y_tw97})")
        
        # é€²è¡Œåº§æ¨™æœå°‹ï¼ˆå‚³å…¥å·²è¼‰å…¥çš„æ–·å±¤è³‡æ–™ï¼‰
        search_result = coordinate_search_from_file(x_tw97, y_tw97, use_fault_data, fault_gdf)
        
        if search_result:
            # å–å¾—åŸºæº–åœ°éœ‡è¦æ¨¡

            city = search_result.get('ç¸£å¸‚', 'æœªçŸ¥')
            base_mw_map = {
                "åŸºéš†å¸‚": 7.3, "æ–°åŒ—å¸‚": 7.3, "è‡ºåŒ—å¸‚": 7.3, "å®œè˜­ç¸£": 7.3, "èŠ±è“®ç¸£": 7.3, "å°æ±ç¸£": 7.3,
                "æ¡ƒåœ’å¸‚": 7.1, "å°ä¸­å¸‚": 7.1, "å½°åŒ–ç¸£": 7.1, "å—æŠ•ç¸£": 7.1, "é›²æ—ç¸£": 7.1,
                "å˜‰ç¾©ç¸£": 7.1, "å°å—å¸‚": 7.1, "é«˜é›„å¸‚": 7.1,
                "æ–°ç«¹ç¸£": 6.9, "è‹—æ —ç¸£": 6.9, "å±æ±ç¸£": 6.9,
                "æ¾æ¹–ç¸£": 6.7, "é‡‘é–€ç¸£": 6.7, "é¦¬ç¥–ç¸£": 6.7
            }
            base_mw = base_mw_map.get(city, 7.0)
            
            well_params[well_id] = {
                'city': city,
                'base_mw': base_mw,
                'x': x_tw97,
                'y': y_tw97,
                'SDS': search_result.get('SDS'),
                'SMS': search_result.get('SMS'),
                'SD1': search_result.get('SD1', None),
                'SM1': search_result.get('SM1', None),
                'search_result': search_result
            }
            
            print(f"  âœ… æˆåŠŸï¼š{city}, Mw={base_mw}, SDS={well_params[well_id]['SDS']}, SMS={well_params[well_id]['SMS']}")
        else:
            # ä½¿ç”¨é è¨­å€¼
            well_params[well_id] = {
                'city': 'æœªçŸ¥',
                'base_mw': 7.0,
                'x': x_tw97,
                'y': y_tw97,
                'SDS': 0.8,
                'SMS': 1.0,
                'SD1': None,
                'SM1': None,
                'search_result': None
            }
            print(f"  âš ï¸ æ²’æœ‰æœå°‹åˆ°åœ°éœ‡åƒæ•¸")
        
        # é¿å…éæ–¼é »ç¹çš„æŸ¥è©¢
        if i < len(well_ids):
            time.sleep(0.5)
    
    return well_params


# NCEERæ¶²åŒ–åˆ†æé¡åˆ¥
class NCEER:
    def __init__(self, default_em = 72):
        """åˆå§‹åŒ–NCEERåˆ†æå™¨"""
        self.g = 9.81  # é‡åŠ›åŠ é€Ÿåº¦ (m/sÂ²)
        self.Pa = 100  # å¤§æ°£å£“åŠ› (t/mÂ²)
        
        # Faä¿‚æ•¸æŸ¥è¡¨
        self.fa_table = {
            "ç¬¬ä¸€é¡åœ°ç›¤": {
                "SDS<=0.5": 1.0, "SDS=0.6": 1.0, "SDS=0.7": 1.0, "SDS=0.8": 1.0, "SDS>=0.9": 1.0,
                "SMS<=0.5": 1.0, "SMS=0.6": 1.0, "SMS=0.7": 1.0, "SMS=0.8": 1.0, "SMS>=0.9": 1.0
            },
            "ç¬¬äºŒé¡åœ°ç›¤": {
                "SDS<=0.5": 1.1, "SDS=0.6": 1.1, "SDS=0.7": 1.0, "SDS=0.8": 1.0, "SDS>=0.9": 1.0,
                "SMS<=0.5": 1.1, "SMS=0.6": 1.1, "SMS=0.7": 1.0, "SMS=0.8": 1.0, "SMS>=0.9": 1.0
            },
            "ç¬¬ä¸‰é¡åœ°ç›¤": {
                "SDS<=0.5": 1.2, "SDS=0.6": 1.2, "SDS=0.7": 1.1, "SDS=0.8": 1.0, "SDS>=0.9": 1.0,
                "SMS<=0.5": 1.2, "SMS=0.6": 1.2, "SMS=0.7": 1.1, "SMS=0.8": 1.0, "SMS>=0.9": 1.0
            }
        }



###    
    def validate_input_data(self, df):
        """é©—è­‰è¼¸å…¥æ•¸æ“šçš„å®Œæ•´æ€§"""
        required_columns = ['é‘½å­”ç·¨è™Ÿ', 'TWD97_X', 'TWD97_Y', 'ä¸Šé™æ·±åº¦(å…¬å°º)', 'ä¸‹é™æ·±åº¦(å…¬å°º)']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}")
        
        # æª¢æŸ¥æ•¸æ“šé¡å‹å’Œç¯„åœ
        for col in ['TWD97_X', 'TWD97_Y']:
            if not pd.api.types.is_numeric_dtype(df[col]):
                try:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                except:
                    raise ValueError(f"åº§æ¨™æ¬„ä½ {col} åŒ…å«ç„¡æ•ˆæ•¸æ“š")
        
        return df


    def get_user_em_value(self):
        """å–å¾—ä½¿ç”¨è€…è¼¸å…¥çš„ Em å€¼"""
        while True:
            try:
                user_input = input("è«‹è¼¸å…¥ SPT éŒ˜æ“Šèƒ½é‡æ•ˆç‡ Em (é è¨­ 72ï¼Œç›´æ¥æŒ‰ Enter ä½¿ç”¨é è¨­å€¼): ").strip()
                
                if user_input == "":
                    return 72  # é è¨­å€¼
                
                em_value = float(user_input)
                
                if em_value <= 0:
                    print("éŒ¯èª¤ï¼šEm å€¼å¿…é ˆå¤§æ–¼ 0ï¼Œè«‹é‡æ–°è¼¸å…¥")
                    continue
                elif em_value > 100:
                    print("è­¦å‘Šï¼šEm å€¼é€šå¸¸ä¸æœƒè¶…é 100%ï¼Œè«‹ç¢ºèªè¼¸å…¥æ˜¯å¦æ­£ç¢º")
                    confirm = input("æ˜¯å¦ç¹¼çºŒä½¿ç”¨æ­¤å€¼ï¼Ÿ(y/n): ").strip().lower()
                    if confirm in ['y', 'yes']:
                        return em_value
                    else:
                        continue
                else:
                    return em_value
                    
            except ValueError:
                print("éŒ¯èª¤ï¼šè«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å€¼")
                continue

    def compute_coefficient(self, group):
        """ç‚ºåŒä¸€é‘½å­”çš„æ‰€æœ‰åœŸå±¤è¨ˆç®—åœŸå±¤æ·±åº¦ã€åšåº¦ã€ä¸­é»æ·±åº¦ã€åˆ†æé»æ·±åº¦å’Œæ‡‰åŠ›"""
        group = group.copy()
        
        # è™•ç† N å€¼
        if 'N_value' in group.columns:
            group['N'] = group['N_value'].apply(lambda x: parse_numeric_value(x))
        else:
            group['N'] = np.nan
                    
        # çµ±ä¸€æ¬„ä½åç¨±
        if 'SPT_top_depth' in group.columns and 'ä¸Šé™æ·±åº¦(å…¬å°º)' not in group.columns:
            group = group.rename(columns={'SPT_top_depth': 'ä¸Šé™æ·±åº¦(å…¬å°º)'})
        if 'SPT_bottom_depth' in group.columns and 'ä¸‹é™æ·±åº¦(å…¬å°º)' not in group.columns:
            group = group.rename(columns={'SPT_bottom_depth': 'ä¸‹é™æ·±åº¦(å…¬å°º)'})
        group = group.sort_values('ä¸Šé™æ·±åº¦(å…¬å°º)').reset_index(drop=True)
        # çµ±ä¸€è™•ç†çµ±é«”å–®ä½é‡å’Œçµ±é«”å¯†åº¦æ¬„ä½ç‚º Density
        if 'çµ±é«”å¯†åº¦(t/m3)' in group.columns and 'çµ±é«”å–®ä½é‡(t/m3)' in group.columns:
            # å…©å€‹æ¬„ä½éƒ½å­˜åœ¨ï¼Œå„ªå…ˆä½¿ç”¨çµ±é«”å¯†åº¦ï¼Œå¦‚æœç‚ºç©ºå‰‡ä½¿ç”¨çµ±é«”å–®ä½é‡
            group['Density'] = group['çµ±é«”å¯†åº¦(t/m3)'].fillna(group['çµ±é«”å–®ä½é‡(t/m3)'])
        elif 'çµ±é«”å¯†åº¦(t/m3)' in group.columns:
            group['Density'] = group['çµ±é«”å¯†åº¦(t/m3)']
        elif 'çµ±é«”å–®ä½é‡(t/m3)' in group.columns:
            group['Density'] = group['çµ±é«”å–®ä½é‡(t/m3)']
        else:
            group['Density'] = 0.0  # å¦‚æœéƒ½æ²’æœ‰ï¼Œè¨­ç‚ºé è¨­å€¼
        # ã€é—œéµä¿®æ­£ã€‘è™•ç†çµ±é«”å–®ä½é‡ç¼ºå¤±å€¼
        print(f"    æª¢æŸ¥çµ±é«”å–®ä½é‡ç¼ºå¤±æƒ…æ³...")
        unit_weight_col = 'Density'
        
        # è™•ç† Density ç¼ºå¤±å€¼
        print(f"    æª¢æŸ¥ Density ç¼ºå¤±æƒ…æ³...")

        # æª¢æŸ¥ä¸¦è™•ç† Density ç¼ºå¤± - æ–°çš„è™•ç†é‚è¼¯
        missing_count = 0
        for i in range(len(group)):
            density = group.iloc[i][unit_weight_col]
            if pd.isna(density) or density == "" or density is None:
                missing_count += 1
                # ç›´æ¥è¨­ç‚º0ï¼Œä¸ä½¿ç”¨å‰ä¸€å±¤çš„å€¼æˆ–é è¨­å€¼
                group.iloc[i, group.columns.get_loc(unit_weight_col)] = 0.0
                print(f"      ç¬¬{i+1}å±¤ Density ç¼ºå¤±ï¼Œè¨­ç‚º0")

        if missing_count > 0:
            print(f"    å…±è™•ç† {missing_count} å€‹ Density ç¼ºå¤±å€¼ï¼Œå…¨éƒ¨è¨­ç‚º0")
        # è¨ˆç®—åœŸå±¤æ·±åº¦
        dirt_depths = []
        valid_indices = []
        
        for i in range(len(group)):
            current_row = group.iloc[i]
            lower_depth = current_row['ä¸‹é™æ·±åº¦(å…¬å°º)']
            
            # é©—è­‰æ·±åº¦æ•¸æ“š
            if pd.isna(lower_depth):
                print(f"    è­¦å‘Šï¼šç¬¬{i+1}å±¤ä¸‹é™æ·±åº¦ç¼ºå¤±ï¼Œè·³é")
                continue
            
            # å¦‚æœæœ‰ä¸‹ä¸€å±¤
            if i + 1 < len(group):
                next_row = group.iloc[i + 1]
                next_upper_depth = next_row['ä¸Šé™æ·±åº¦(å…¬å°º)']
                if not pd.isna(next_upper_depth):
                    dirt_depth = (lower_depth + next_upper_depth) / 2
                else:
                    dirt_depth = lower_depth
            else:
                # æœ€å¾Œä¸€å±¤
                dirt_depth = lower_depth
            
            # é™åˆ¶åœŸå±¤æ·±åº¦æœ€å¤§ç‚º30m
            if dirt_depth > 30:
                print(f"    è­¦å‘Šï¼šç¬¬{i+1}å±¤æ·±åº¦ {dirt_depth}m è¶…é30mé™åˆ¶ï¼Œè·³é")
                continue
            
            dirt_depths.append(dirt_depth)
            valid_indices.append(i)
        
        # åªä¿ç•™æœ‰æ•ˆçš„è³‡æ–™è¡Œ
        if len(valid_indices) < len(group):
            group = group.iloc[valid_indices].reset_index(drop=True)
            print(f"    éæ¿¾æ‰ {len(group) - len(valid_indices)} å±¤ç„¡æ•ˆåœŸå±¤")
        
        group['åœŸå±¤æ·±åº¦'] = dirt_depths

        # è¨ˆç®—åœŸå±¤åšåº¦
        dirt_thickness = []
        for i in range(len(group)):
            if i == 0:
                thickness = dirt_depths[i] if not pd.isna(dirt_depths[i]) else np.nan
            else:
                current_depth = dirt_depths[i]
                previous_depth = dirt_depths[i-1]
                if not pd.isna(current_depth) and not pd.isna(previous_depth):
                    thickness = current_depth - previous_depth
                else:
                    thickness = np.nan
            dirt_thickness.append(thickness)
        
        group['åœŸå±¤åšåº¦'] = dirt_thickness

        # è¨ˆç®—åœŸå±¤ä¸­é»æ·±åº¦
        dirt_mid_depth = []
        for i in range(len(group)):
            depth = dirt_depths[i]
            thickness = dirt_thickness[i]
            
            if not pd.isna(depth) and not pd.isna(thickness):
                mid_depth = depth - thickness / 2
            else:
                mid_depth = np.nan
            dirt_mid_depth.append(mid_depth)
        
        group['åœŸå±¤ä¸­é»æ·±åº¦'] = dirt_mid_depth
        
        # è¨ˆç®—åˆ†æé»æ·±åº¦ - ä¿®æ”¹ GWT_CSR è™•ç†é‚è¼¯
        analysis_depths = []
        
        
        # å¾ water_depth(m) å–å¾— GWT_CSRï¼Œå¦‚æœç‚ºç©ºå€¼å‰‡è¨­ç‚º 0
        if 'water_depth(m)' in group.columns:
            GWT_CSR = group['water_depth(m)'].iloc[0]
        else:
            GWT_CSR = 0
        
        # è™•ç† GWT_CSR ç©ºå€¼
        if pd.isna(GWT_CSR) or GWT_CSR == "" or GWT_CSR is None:
            GWT_CSR = 0
            print(f"    åœ°ä¸‹æ°´ä½æ·±åº¦ç‚ºç©ºå€¼ï¼Œè¨­ç‚º 0")
        
        # ç¢ºä¿ GWT_CSR ç‚ºæ•¸å€¼å‹æ…‹
        try:
            GWT_CSR = float(GWT_CSR)
        except (ValueError, TypeError):
            GWT_CSR = 0
            print(f"    åœ°ä¸‹æ°´ä½æ·±åº¦ç„¡æ³•è½‰æ›ç‚ºæ•¸å€¼ï¼Œè¨­ç‚º 0")

        group['GWT_CSR'] = GWT_CSR
        GWT_CRR = GWT_CSR
        

        for i in range(len(group)):
            if pd.isna(dirt_depths[i]) or dirt_depths[i] == "":
                analysis_depth = ""
            elif dirt_depths[i] > GWT_CSR:
                if not pd.isna(dirt_thickness[i]):
                    min_value = min((dirt_depths[i] - GWT_CSR) / 2, dirt_thickness[i] / 2)
                    analysis_depth = dirt_depths[i] - min_value
                else:
                    analysis_depth = dirt_depths[i] 
            else:
                analysis_depth = dirt_mid_depth[i] if not pd.isna(dirt_mid_depth[i]) else ""
            
            analysis_depths.append(analysis_depth)
        
        group['åˆ†æé»æ·±åº¦'] = analysis_depths
        
        # è¨ˆç®—FCå€¼ï¼ˆç´°æ–™å«é‡ï¼‰
        fc_values = []
        for i in range(len(group)):
            row = group.iloc[i]
            FC = row.get('ç´°æ–™(%)', np.nan)
            
            if pd.isna(FC) or FC == "":
                ç²‰åœŸ = row.get('ç²‰åœŸ(%)', 0)
                é»åœŸ = row.get('é»åœŸ(%)', 0)
                
                if pd.isna(ç²‰åœŸ):
                    ç²‰åœŸ = 0
                if pd.isna(é»åœŸ):
                    é»åœŸ = 0
                    
                try:
                    if isinstance(ç²‰åœŸ, str):
                        ç²‰åœŸ = float(ç²‰åœŸ) if ç²‰åœŸ.replace('.', '').isdigit() else 0
                    if isinstance(é»åœŸ, str):
                        é»åœŸ = float(é»åœŸ) if é»åœŸ.replace('.', '').isdigit() else 0
                except (ValueError, AttributeError):
                    ç²‰åœŸ = 0
                    é»åœŸ = 0
                    
                FC = ç²‰åœŸ + é»åœŸ
            
            fc_values.append(FC)
        
        group['FC'] = fc_values

        # ã€é—œéµä¿®æ­£ã€‘æ”¹å–„ sigmav ç´¯è¨ˆè¨ˆç®—
        cumulative_sigmav = []

        for i in range(len(group)):
            current_analysis_depth = analysis_depths[i]
            current_unit_weight = group.iloc[i][unit_weight_col]
            
        
            try:
                current_analysis_depth = float(current_analysis_depth)
                current_unit_weight = float(current_unit_weight)
            except (ValueError, TypeError):
                print(f"    è­¦å‘Šï¼šç¬¬{i+1}å±¤æ•¸æ“šç„¡æ³•è½‰æ›ç‚ºæ•¸å€¼")
                cumulative_sigmav.append(np.nan)
                continue
            
            if i == 0:
                # ç¬¬ä¸€å±¤ï¼šsigma_v = è©²å±¤åˆ†æé»æ·±åº¦ Ã— è©²å±¤å–®ä½é‡
                sigma_v = current_analysis_depth * current_unit_weight
                print(f"    ç¬¬1å±¤ sigma_v = {current_analysis_depth} Ã— {current_unit_weight} = {sigma_v}")
            else:
                # å…¶ä»–å±¤çš„è¨ˆç®—
                prev_soil_depth = dirt_depths[i-1]
                prev_analysis_depth = analysis_depths[i-1]
                prev_unit_weight = group.iloc[i-1][unit_weight_col]
                prev_sigma_v = cumulative_sigmav[i-1]
                
                # æª¢æŸ¥å‰ä¸€å±¤æ•¸æ“šæœ‰æ•ˆæ€§
                if (pd.isna(prev_soil_depth) or pd.isna(prev_analysis_depth) or 
                    pd.isna(prev_unit_weight) or pd.isna(prev_sigma_v) or 
                    prev_analysis_depth == ""):
                    print(f"    è­¦å‘Šï¼šç¬¬{i+1}å±¤è¨ˆç®—éœ€è¦çš„å‰ä¸€å±¤æ•¸æ“šä¸å®Œæ•´")
                    cumulative_sigmav.append(np.nan)
                    continue
                
                try:
                    prev_soil_depth = float(prev_soil_depth)
                    prev_analysis_depth = float(prev_analysis_depth)
                    prev_unit_weight = float(prev_unit_weight)
                    prev_sigma_v = float(prev_sigma_v)
                except (ValueError, TypeError):
                    print(f"    è­¦å‘Šï¼šç¬¬{i+1}å±¤å‰ä¸€å±¤æ•¸æ“šç„¡æ³•è½‰æ›ç‚ºæ•¸å€¼")
                    cumulative_sigmav.append(np.nan)
                    continue
                
                # è¨ˆç®—sigma_v
                part1 = (prev_soil_depth - prev_analysis_depth) * prev_unit_weight
                part2 = (current_analysis_depth - prev_soil_depth) * current_unit_weight
                sigma_v = part1 + part2 + prev_sigma_v
                
                print(f"    ç¬¬{i+1}å±¤ sigma_v = ({prev_soil_depth} - {prev_analysis_depth}) Ã— {prev_unit_weight} + ({current_analysis_depth} - {prev_soil_depth}) Ã— {current_unit_weight} + {prev_sigma_v} = {sigma_v}")
            
            cumulative_sigmav.append(sigma_v)
        
        group['ç´¯è¨ˆsigmav'] = cumulative_sigmav

        # è¨ˆç®— sigmav_CSR' (æœ‰æ•ˆæ‡‰åŠ›) 
        sigma_v_CSR_values = []
        for i in range(len(group)):
            if pd.isna(cumulative_sigmav[i]) or pd.isna(analysis_depths[i]) or analysis_depths[i] == "":
                sigma_v_CSR_values.append(np.nan)
                continue
            
            try:
                analysis_depth = float(analysis_depths[i])
                ç´¯è¨ˆsigmav = float(cumulative_sigmav[i])
            except (ValueError, TypeError):
                sigma_v_CSR_values.append(np.nan)
                continue
            
            if analysis_depth <= GWT_CSR:
                # åœ¨åœ°ä¸‹æ°´ä½ä»¥ä¸Šï¼Œä¸éœ€è¦æ‰£é™¤æµ®åŠ›
                sigma_v_CSR = ç´¯è¨ˆsigmav
            else:
                sigma_v_CSR = ç´¯è¨ˆsigmav - max(0, (analysis_depth - GWT_CSR) )
            
            sigma_v_CSR_values.append(sigma_v_CSR)
        
        group['sigma_v_CSR'] = sigma_v_CSR_values
        
        # è¨ˆç®— sigma_v_CRR (é¡ä¼¼è¨ˆç®—)
        sigma_v_CRR_values = []
        for i in range(len(group)):
            if pd.isna(cumulative_sigmav[i]) or pd.isna(analysis_depths[i]) or analysis_depths[i] == "":
                sigma_v_CRR_values.append(np.nan)
                continue
            
            try:
                analysis_depth = float(analysis_depths[i])
                ç´¯è¨ˆsigmav = float(cumulative_sigmav[i])
            except (ValueError, TypeError):
                sigma_v_CRR_values.append(np.nan)
                continue
            
            if analysis_depth <= GWT_CRR:
                sigma_v_CRR = ç´¯è¨ˆsigmav
            else:
                sigma_v_CRR = ç´¯è¨ˆsigmav - max(0, (analysis_depth - GWT_CRR) )

            
            sigma_v_CRR_values.append(sigma_v_CRR)
        
        group['sigma_v_CRR'] = sigma_v_CRR_values

        return group
    def compute_Vs(self, row):
        """è¨ˆç®—å‰ªåŠ›æ³¢é€Ÿ Vs"""
        soil_class = row.get('çµ±ä¸€åœŸå£¤åˆ†é¡', row.get('åœŸå£¤åˆ†é¡', ''))
        N_value = row.get('N', np.nan)
        
        if soil_class in ["GW", "GP", "SW", "SP", "GM", "GC", "SM", "SC"]:
            soil_type = "Granular"
        elif soil_class in ["ML", "CL", "OL", "MH", "CH", "OH"]:
            soil_type = "Cohesive"
        else:
            soil_type = "-"
            
        if N_value in [None, 0, ""] or pd.isna(N_value):
            return "NG"

        try:
            N_numeric = float(N_value)
        except (ValueError, TypeError):
            return "NG"

        if soil_type == "Granular":
            Vs = round(80 * (min(N_numeric, 50) ** (1/3)), 2)
        elif soil_type == "Cohesive":
            Vs = round(100 * (min(N_numeric, 25) ** (1/3)), 2)
        else:
            Vs = "NG"
        
        return Vs

    def compute_d_over_v(self, row):
        """è¨ˆç®— d/v å€¼"""
        thickness = row['åœŸå±¤åšåº¦']
        vs = row['Vs']
        
        if pd.isna(thickness) or pd.isna(vs) or thickness == 0 or vs == 0 or vs == "" or vs == "NG":
            return ""
        
        try:
            thickness_num = float(thickness)
            vs_num = float(vs)
            return round(thickness_num / vs_num, 3)
        except (ValueError, ZeroDivisionError, TypeError):
            return "NG"
    
    def compute_Vs30(self, group):
        """è¨ˆç®— Vs30"""
        # è¨ˆç®—æ¯å±¤çš„ d/v
        group['d/v'] = group.apply(self.compute_d_over_v, axis=1)
        
        valid_data = group[
            (pd.notna(group['åœŸå±¤åšåº¦'])) & 
            (group['d/v'] != "") & 
            (group['d/v'] != "NG") &
            (group['åœŸå±¤åšåº¦'] > 0)
        ].copy()

        if len(valid_data) == 0:
            return None
        else:
            sum_thickness = valid_data['åœŸå±¤åšåº¦'].sum()
            sum_d_over_v = valid_data['d/v'].sum()
            
            if sum_d_over_v > 0:
                vs30 = round(sum_thickness / sum_d_over_v, 2)
            else:
                vs30 = None

        return vs30

    def ground_class_from_vs30(self, vs30):
        """æ ¹æ“š Vs30 åˆ¤å®šåœ°ç›¤åˆ†é¡"""
        if vs30 is None or vs30 == "NG":
            return "ç¬¬äºŒé¡åœ°ç›¤"  # é è¨­å€¼
        
        if vs30 >= 270:
            return "ç¬¬ä¸€é¡åœ°ç›¤"
        elif 180 <= vs30 < 270:
            return "ç¬¬äºŒé¡åœ°ç›¤"
        else:
            return "ç¬¬ä¸‰é¡åœ°ç›¤"
        
    def compute_Fa(self, row, scenario='Design'):
        """è¨ˆç®—å ´å€ä¿‚æ•¸ Fa"""
        def get_range_key(value, prefix):
            if value <= 0.5:
                return f"{prefix}<=0.5"
            elif value <= 0.55:
                return f"{prefix}=0.6"
            elif value <= 0.65:
                return f"{prefix}=0.6"
            elif value <= 0.75:
                return f"{prefix}=0.7"
            elif value <= 0.85:
                return f"{prefix}=0.8"
            else:
                return f"{prefix}>=0.9"
        
        # å¾ row ä¸­å–å¾—åƒæ•¸
        SDS = row.get('SDS') or row.get('ä½¿ç”¨SDS')
        SMS = row.get('SMS') or row.get('ä½¿ç”¨SMS')
        
        # è¨ˆç®—åœ°ç›¤åˆ†é¡
        vs30 = getattr(row, '_vs30', None)  # å¦‚æœå·²ç¶“è¨ˆç®—éå°±ä½¿ç”¨
        if vs30 is None:
            # éœ€è¦æ•´å€‹groupä¾†è¨ˆç®—Vs30ï¼Œé€™è£¡ä½¿ç”¨é è¨­å€¼
            site_class = "ç¬¬äºŒé¡åœ°ç›¤"
        else:
            site_class = self.ground_class_from_vs30(vs30)
        
        # ç¢ºå®š SDS å’Œ SMS çš„ç¯„åœ
        SDS_range = get_range_key(SDS, "SDS")
        SMS_range = get_range_key(SMS, "SMS")
        
        # æŸ¥è©¢å°æ‡‰çš„ä¿‚æ•¸
        Fa_SDS = self.fa_table[site_class][SDS_range]
        Fa_SMS = self.fa_table[site_class][SMS_range]
        
        return Fa_SDS, Fa_SMS

    def compute_A_value(self, row, scenario):
        """è¨ˆç®—è¨­è¨ˆåœ°è¡¨åŠ é€Ÿåº¦ A_value - ä¿®æ”¹ç‰ˆ"""
        # æª¢æŸ¥æ˜¯å¦ç‚ºå°åŒ—ç›†åœ°å¾®åˆ†å€
        data_source = row.get('è³‡æ–™ä¾†æº', '')
        
        if 'å°åŒ—ç›†åœ°å¾®åˆ†å€' in data_source:
            # å°åŒ—ç›†åœ°å¾®åˆ†å€ï¼šç›´æ¥ä½¿ç”¨ SD_S, SM_S å€¼
            SD_S = row.get('SDS') or row.get('ä½¿ç”¨SDS')  # å°åŒ—ç›†åœ°çš„SDSå°±æ˜¯SD_S
            SM_S = row.get('SMS') or row.get('ä½¿ç”¨SMS')  # å°åŒ—ç›†åœ°çš„SMSå°±æ˜¯SM_S
            
            # æ ¹æ“šæƒ…å¢ƒè¨ˆç®— A_value
            if scenario == "Design": 
                A_value = 0.4 * SD_S / 3.5
            elif scenario == "MidEq": 
                A_value = 0.4 * SD_S / 4.2
            elif scenario == "MaxEq":
                A_value = 0.4 * SM_S
            else:
                A_value = 0.4 * SD_S
            
            return A_value, SD_S, SM_S
        else:
            # ä¸€èˆ¬æƒ…æ³ï¼šåŸæœ‰çš„å ´å€ä¿‚æ•¸è¨ˆç®—
            Fa_SDS, Fa_SMS = self.compute_Fa(row, scenario)
            
            SDS = row.get('SDS') or row.get('ä½¿ç”¨SDS')
            SMS = row.get('SMS') or row.get('ä½¿ç”¨SMS')
            
            SD_S = Fa_SDS * SDS
            SM_S = Fa_SMS * SMS
            
            if scenario == "Design":
                A_value = 0.4 * SD_S
            elif scenario == "MidEq": 
                A_value = 0.4 * SD_S / 4.2
            elif scenario == "MaxEq":
                A_value = 0.4 * SM_S
            else:
                A_value = 0.4 * SD_S
            
            return A_value, SD_S, SM_S

    def compute_N60(self, row):
        """è¨ˆç®— N60"""
        N_value = row['N_value'] if 'N_value' in row else row.get('N', np.nan)
        
        # å¾æª”æ¡ˆä¸­å°‹æ‰¾ Em æ¬„ä½ï¼Œæ²’æœ‰çš„è©±ä½¿ç”¨é¡åˆ¥ä¸­è¨­å®šçš„é è¨­å€¼
        if 'Em' in row and pd.notna(row['Em']) and row['Em'] != "":
            Em = row['Em']
        else:
            Em = self.default_em  # ä½¿ç”¨é¡åˆ¥ä¸­è¨­å®šçš„é è¨­å€¼
        
        N_value_parsed = parse_numeric_value(N_value)
        Em_parsed = parse_numeric_value(Em)
        
        if N_value_parsed is None or Em_parsed is None:
            return 0.00
        
        try:
            N60 = N_value_parsed * Em_parsed / 60
            return format_result(N60)
        except (ValueError, TypeError):
            return 0.00
        
    def compute_N1_60(self, row):
        """è¨ˆç®— N1_60"""
        N_value = row['N_value'] if 'N_value' in row else row.get('N', np.nan)
        sigma_v = row['ç´¯è¨ˆsigmav']
        sigma_v_CRR = row['sigma_v_CRR']
        N60 = self.compute_N60(row)  
        N_value_parsed = parse_numeric_value(N_value)
        
        if N_value_parsed is None or pd.isna(sigma_v) or sigma_v <= 0:
            return 0.00
        
        try:
            Cn = np.minimum(np.sqrt(self.Pa / sigma_v_CRR), 1.7)
            N1_60 = Cn * parse_numeric_value(N60)
            return format_result(N1_60)
        except (ValueError, TypeError):
            return 0.00
        
    def compute_N1_60cs(self, row):
        """è¨ˆç®— N1_60cs"""
        N1_60 = self.compute_N1_60(row)  # ä¿®æ­£ï¼šæ‡‰è©²æ˜¯å‡½æ•¸èª¿ç”¨
        FC = row['FC']  # ç´°æ–™å«é‡
        
        if N1_60 == "-" or pd.isna(N1_60):
            return "-"
        
        try:
            N1_60_parsed = parse_numeric_value(N1_60)
            if N1_60_parsed is None:
                return "-"
            
            if FC <= 5:
                a = 0.0  # æ˜ç¢ºæŒ‡å®šç‚ºæµ®é»æ•¸
                b = 1.0
            elif 5 < FC <= 35:    
                # ä¿®æ­£1: ä½¿ç”¨åœ“æ‹¬è™Ÿè€Œä¸æ˜¯æ–¹æ‹¬è™Ÿèª¿ç”¨ np.exp
                a = np.exp(1.76 - 190/(FC ** 2))
                # ä¿®æ­£2: ç§»é™¤æ–¹æ‹¬è™Ÿï¼Œç›´æ¥è¨ˆç®—æ•¸å€¼
                b = 0.99 + (FC ** 1.5) / 1000
            elif FC > 35:  # ä¿®æ­£3: ç°¡åŒ–æ¢ä»¶åˆ¤æ–·
                a = 5.0
                b = 1.2
            else:
                # é€™å€‹ else å¯¦éš›ä¸Šä¸æœƒè¢«åŸ·è¡Œï¼Œä½†ä¿ç•™ä½œç‚ºå®‰å…¨æªæ–½
                a = 5.0
                b = 1.2
            
            N1_60cs = a + (b * N1_60_parsed)
            return format_result(N1_60cs)
            
        except (ValueError, TypeError, ZeroDivisionError) as e:
            print(f"è¨ˆç®— N1_60cs æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}, FC = {FC}, N1_60 = {N1_60}")
            return "-"



    # è¨ˆç®— CRR_7.5
    def compute_CRR_7_5(self, row):
        
        
        
        
        """è¨ˆç®— CRR_7.5 - ä½¿ç”¨æŒ‡å®šå…¬å¼"""
        N1_60cs = self.compute_N1_60cs(row)
        
        if N1_60cs == "-" or pd.isna(N1_60cs) :
            return "-"
        
        try:

            if N1_60cs is None:
                return "-"
            CRR_7_5 = (1 / (34 - N1_60cs)) + (N1_60cs / 135) + (50 / ((10 * N1_60cs + 45) ** 2)) - (1/200)
        
            return format_result(CRR_7_5)
        except (ValueError, TypeError, ZeroDivisionError) as e:
            print(f"è¨ˆç®— CRR_7_5 æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}, N1_60cs = {N1_60cs}")
        return "-"

    def calculate_FS(self, row, scenario='Design'):
        """è¨ˆç®—æ¶²åŒ–å®‰å…¨ä¿‚æ•¸ (FS) åŠç›¸é—œåƒæ•¸"""
        
        # ç²å–åŸºæœ¬åƒæ•¸
        soil_class = row.get('çµ±ä¸€åœŸå£¤åˆ†é¡', '') 
        
        PI_raw = row.get('å¡‘æ€§æŒ‡æ•¸(%)', 0)
        is_np_or_empty = False  # æ¨™è¨˜æ˜¯å¦ç‚ºNPæˆ–ç©ºå€¼

        if pd.isna(PI_raw) or PI_raw == "" or PI_raw is None:
            PI = 0
            is_np_or_empty = True
        elif str(PI_raw).upper() == "NP":
            PI = 0
            is_np_or_empty = True
        else:
            try:
                PI = float(PI_raw)
                is_np_or_empty = False
            except (ValueError, TypeError):
                PI = 0
                is_np_or_empty = True
        
        dirt_depth = row['åˆ†æé»æ·±åº¦']
        GWT_CSR = row.get('GWT_CSR', 0)
        N1_60cs_value = parse_numeric_value(row['N1_60cs'])
        
        # ç²å–åœ°éœ‡è¦æ¨¡
        base_mw = row.get('åŸºæº–Mw', 7.0)
        mw_value = get_scenario_mw(base_mw, scenario)
        

        # æ–°å¢åˆ¤æ–·æ¢ä»¶1: æ·±åº¦ < 20m æˆ– æ·±åº¦åœ¨åœ°ä¸‹æ°´ä½ä»¥ä¸Š
        depth_condition = False
        if pd.notna(dirt_depth) and dirt_depth != "":
            if dirt_depth > 20 or dirt_depth <= GWT_CSR:
                depth_condition = True
                print(f"Debug - æ·±åº¦æ¢ä»¶è§¸ç™¼: depth={dirt_depth}, GWT={GWT_CSR}")
        
        # æ–°å¢åˆ¤æ–·æ¢ä»¶2: å¡‘æ€§æŒ‡æ•¸ > 7 (ç©ºå€¼å·²è½‰ç‚º0ï¼Œæ‰€ä»¥0ä¸æœƒè§¸ç™¼)
        pi_condition = False
        if PI > 7 and not is_np_or_empty :
            pi_condition = True
            print(f"Debug - PIæ¢ä»¶è§¸ç™¼: PI={PI} (åŸå€¼: {PI_raw}) > 7")
        
        # æ–°å¢åˆ¤æ–·æ¢ä»¶3: CRR_7_5 ç‚º "-"
        crr_condition = False
        CRR_7_5_value = self.compute_CRR_7_5(row)
        if CRR_7_5_value == "-":
            crr_condition = True
            print(f"Debug - CRRæ¢ä»¶è§¸ç™¼: CRR_7_5={CRR_7_5_value}")
        
        
        
        # æª¢æŸ¥æ˜¯å¦ç¬¦åˆä»»ä¸€ FS=3 çš„æ¢ä»¶
        should_set_fs_3 = crr_condition 
        if should_set_fs_3:
            
            # è¨ˆç®—å…¶ä»–åƒæ•¸ä½†è¨­å®š FS = 3
            try:
                # è¨ˆç®— A_value, SD_S, SM_S
                A_value, SD_S, SM_S = self.compute_A_value(row, scenario)
                
                # è¨ˆç®— MSF (è¦æ¨¡ä¿®æ­£å› å­)
                MSF = (mw_value / 7.5) ** (-2.56)
                
                # è¨ˆç®— rd (æ‡‰åŠ›æŠ˜æ¸›ä¿‚æ•¸)
                z = depth
                rd = (1 - 0.4113 * np.sqrt(z) + 0.04052 * z + 0.001753 * (z ** 1.5) ) / (1-0.4117 * np.sqrt(z) + 0.05729 * z - 0.006205 * (z ** 1.5) + 0.001210 * (z ** 2))
         
                # è¨ˆç®— CSR å’Œ CRR
                sigma_v_csr = row.get('sigma_v_CSR')
                sigma_v = row.get('ç´¯è¨ˆsigmav')
                
                if pd.notna(sigma_v_csr) and pd.notna(sigma_v) and rd != "-":
                    CSR = parse_numeric_value(0.65 * (A_value) * (sigma_v / sigma_v_csr) * rd )
                else:
                    CSR = "-"
                
                CRR_7_5_numeric = parse_numeric_value(CRR_7_5_value)
                if CRR_7_5_numeric is not None and MSF != "-":
                    CRR = CRR_7_5_numeric * MSF
                else:
                    CRR = "-"
                
            except Exception as e:
                print(f"Debug - è¨ˆç®—å…¶ä»–åƒæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                # å¦‚æœè¨ˆç®—å¤±æ•—ï¼Œè¨­å®šç‚ºé è¨­å€¼
                A_value = "-"
                SD_S = "-"
                SM_S = "-"
                MSF = "-"
                rd = "-"
                CSR = "-"
                CRR = "-"
            
            return {
                'Mw_used': format_result(mw_value),
                'A_value': format_result(A_value) if A_value != "-" else "-",
                'SD_S': format_result(SD_S) if SD_S != "-" else "-",
                'SM_S': format_result(SM_S) if SM_S != "-" else "-",
                'MSF': format_result(MSF) if MSF != "-" else "-",
                'rd': format_result(rd) if rd != "-" else "-",
                'CSR': format_result(CSR) if CSR != "-" else "-",
                'CRR': format_result(CRR) if CRR != "-" else "-",
                'FS': 3.0  # æ˜ç¢ºè¨­å®šç‚º 3.0
            }
        
        print(f"Debug - é€²è¡Œæ­£å¸¸ FS è¨ˆç®—")
        
        # å¦‚æœä¸ç¬¦åˆä¸Šè¿°æ¢ä»¶ï¼Œé€²è¡Œæ­£å¸¸è¨ˆç®—
        # å–å¾—å¿…è¦åƒæ•¸
        depth = row['åˆ†æé»æ·±åº¦']
        sigma_v_csr = row['sigma_v_CSR']
        CRR_7_5 = parse_numeric_value(CRR_7_5_value)
        sigma_v = row['ç´¯è¨ˆsigmav']
        
        # æª¢æŸ¥å¿…è¦æ•¸æ“šå®Œæ•´æ€§
        if pd.isna(depth) or pd.isna(sigma_v_csr) or CRR_7_5 is None or pd.isna(sigma_v):
            return {
                'Mw_used': format_result(mw_value),
                'A_value': "-",
                'SD_S': "-",
                'SM_S': "-",
                'MSF': "-",
                'rd': "-",
                'CSR': "-", 
                'CRR': "-",
                'FS': "-"
            }
        
        try:
            # 1. è¨ˆç®— A_value, SD_S, SM_S
            A_value, SD_S, SM_S = self.compute_A_value(row, scenario)
            
            # 2. è¨ˆç®— MSF (è¦æ¨¡ä¿®æ­£å› å­)
            MSF = (mw_value / 7.5) ** (-2.56)
            z = depth
            rd = (1 - 0.4113 * np.sqrt(z) + 0.04052 * z + 0.001753 * (z ** 1.5) ) / (1-0.4117 * np.sqrt(z) + 0.05729 * z - 0.006205 * (z ** 1.5) + 0.001210 * (z ** 2))
         

            
            # 4. è¨ˆç®— CSR (åè¦†å‰ªæ‡‰åŠ›æ¯”)
            CSR = parse_numeric_value(0.65 * (A_value) * (sigma_v / sigma_v_csr) * rd )
            
            # 5. è¨ˆç®—èª¿æ•´å¾Œçš„ CRR
            CRR = CRR_7_5 * MSF
            
            # 6. è¨ˆç®—å®‰å…¨ä¿‚æ•¸ FS
            if CSR > 0:
                FS = CRR / CSR
                FS = min(FS, 3)
            else:
                FS = 3  # è¨­å®šä¸€å€‹å¤§æ•¸å€¼è¡¨ç¤ºéå¸¸å®‰å…¨
            
            print(f"Debug - æ­£å¸¸è¨ˆç®—çµæœ: FS={FS}")
                
            return {
                'Mw_used': format_result(mw_value),
                'A_value': format_result(A_value),
                'SD_S': format_result(SD_S),
                'SM_S': format_result(SM_S),
                'MSF': format_result(MSF),
                'rd': format_result(rd),
                'CSR': format_result(CSR),
                'CRR': format_result(CRR),
                'FS': format_result(FS)
            }
            
        except Exception as e:
            print(f"è¨ˆç®—æ¶²åŒ–åƒæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {
                'Mw_used': format_result(mw_value),
                'A_value': "-",
                'SD_S': "-", 
                'SM_S': "-",
                'MSF': "-",
                'rd': "-",
                'CSR': "-",
                'CRR': "-", 
                'FS': "-"
            }

    def calculate_LPI_single_layer(self, row, scenario):
        """è¨ˆç®—å–®å±¤æ¶²åŒ–æ½›èƒ½æŒ‡æ•¸ LPI"""
        fs_col = f'FS_{scenario}'
        
        z = row['åˆ†æé»æ·±åº¦']
        thickness = row['åœŸå±¤åšåº¦']
        fs_value = row[fs_col]
        
        # æª¢æŸ¥å¿…è¦æ•¸æ“šæ˜¯å¦å®Œæ•´
        if pd.isna(z) or pd.isna(thickness) or fs_value == "-":
            return "-"
            
        # åªè¨ˆç®—æ·±åº¦ 20m ä»¥å…§çš„åœŸå±¤
        if z > 20:
            return 0.0
            
        # Wi = 10 - 0.5*z
        Wi = 10 - 0.5 * z
        if Wi <= 0:
            return 0.0
            
        # max(0, 1 - FS)
        fs_numeric = float(fs_value) if fs_value != "-" else 3.0
        lpi_value = max(0, 1 - fs_numeric) * Wi * thickness
        
        return format_result(lpi_value)
    def generate_simplified_report(self, final_df: pd.DataFrame, output_dir: str = None, 
                              scenario: str = "Design") -> str:
        """ç”Ÿæˆç°¡åŒ–çš„æ¶²åŒ–åˆ†æå ±è¡¨"""
        print(f"\næ­£åœ¨ç”Ÿæˆç°¡åŒ–å ±è¡¨ï¼ˆ{scenario} ï¼‰...")
        
        # é¸æ“‡éœ€è¦çš„æ¬„ä½ä¸¦é‡æ–°å‘½å
        column_mapping = {
            'é‘½å­”ç·¨è™Ÿ': 'HOLE ID',
            'TWD97_X': 'X', 
            'TWD97_Y': 'Y',
            'é‘½å­”åœ°è¡¨é«˜ç¨‹': 'Z',
            'ä¸Šé™æ·±åº¦(å…¬å°º)': 'from',
            'ä¸‹é™æ·±åº¦(å…¬å°º)': 'to',
            'çµ±ä¸€åœŸå£¤åˆ†é¡': 'USCS',
            'N': 'SPT-N',
            f'FS_{scenario}': 'FS',
            f'LPI_{scenario}': 'LPI'
        }
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        missing_columns = []
        available_columns = []
        
        for original_col, new_col in column_mapping.items():
            if original_col in final_df.columns:
                available_columns.append((original_col, new_col))
            else:
                missing_columns.append(original_col)
        
        if missing_columns:
            print(f"è­¦å‘Šï¼šä»¥ä¸‹æ¬„ä½åœ¨è³‡æ–™ä¸­æ‰¾ä¸åˆ°ï¼Œå°‡ä»¥ç©ºå€¼å¡«å……ï¼š{missing_columns}")
        
        # éæ¿¾æ·±åº¦æ¢ä»¶ï¼šä¿ç•™åˆ°ç¬¬ä¸€å€‹è¶…é20mçš„å±¤ï¼Œå…¶é¤˜åˆªé™¤
        print(f"  éæ¿¾å‰è³‡æ–™ç­†æ•¸ï¼š{len(final_df)}")
        
        # æª¢æŸ¥ä¸Šé™æ·±åº¦æ¬„ä½
        depth_column = None
        possible_depth_cols = ['ä¸Šé™æ·±åº¦(å…¬å°º)', 'ä¸Šé™æ·±åº¦(m)', 'from', 'ä¸Šé™æ·±åº¦']
        
        for col in possible_depth_cols:
            if col in final_df.columns:
                depth_column = col
                break
        if depth_column:
            print(f"  æ­£åœ¨è™•ç†æ·±åº¦éæ¿¾...")
            
            # æŒ‰é‘½å­”åˆ†çµ„è™•ç†
            filtered_dfs = []
            
            for hole_id in final_df['é‘½å­”ç·¨è™Ÿ'].unique():
                hole_data = final_df[final_df['é‘½å­”ç·¨è™Ÿ'] == hole_id].copy()
                
                # æŒ‰ä¸Šé™æ·±åº¦æ’åº
                hole_data = hole_data.sort_values(depth_column).reset_index(drop=True)
                
                # æª¢æŸ¥åœŸå±¤æ·±åº¦æ¬„ä½
                soil_depth_col = None
                for col in ['åœŸå±¤æ·±åº¦', 'åœŸå±¤æ·±åº¦(m)', 'åˆ†æé»æ·±åº¦']:
                    if col in hole_data.columns:
                        soil_depth_col = col
                        break
                
                if soil_depth_col is None:
                    print(f"    è­¦å‘Šï¼šé‘½å­” {hole_id} æ‰¾ä¸åˆ°åœŸå±¤æ·±åº¦æ¬„ä½ï¼Œä½¿ç”¨åŸå§‹é‚è¼¯")
                    # ä½¿ç”¨åŸä¾†çš„é‚è¼¯
                    depth_numeric = pd.to_numeric(hole_data[depth_column], errors='coerce')
                    over_20_indices = depth_numeric[depth_numeric > 20].index
                    
                    if len(over_20_indices) > 0:
                        first_over_20_idx = over_20_indices[0]
                        keep_data = hole_data.iloc[:first_over_20_idx + 1].copy()
                        if 'ä¸‹é™æ·±åº¦(å…¬å°º)' in keep_data.columns:
                            keep_data.loc[keep_data.index[first_over_20_idx], 'ä¸‹é™æ·±åº¦(å…¬å°º)'] = 20.0
                    else:
                        keep_data = hole_data
                else:
                    # ä½¿ç”¨åœŸå±¤æ·±åº¦é€²è¡Œåˆ¤æ–·
                    soil_depths = pd.to_numeric(hole_data[soil_depth_col], errors='coerce')
                    
                    # æ‰¾åˆ°ç¬¬ä¸€å€‹åœŸå±¤æ·±åº¦è¶…é20mçš„ç´¢å¼•
                    first_over_20_idx = None
                    for i, depth in enumerate(soil_depths):
                        if pd.notna(depth) and depth > 20:
                            first_over_20_idx = i
                            break
                    
                    if first_over_20_idx is not None:
                        # ä¿ç•™åˆ°ç¬¬ä¸€å€‹è¶…é20mçš„å±¤ï¼ˆåŒ…å«ï¼‰
                        keep_data = hole_data.iloc[:first_over_20_idx + 1].copy()
                        
                        # å°‡ç¬¬ä¸€å€‹è¶…é20mçš„åœŸå±¤æ·±åº¦è¨­ç‚º20
                        keep_data.iloc[first_over_20_idx, keep_data.columns.get_loc(soil_depth_col)] = 20.0
                        
                        print(f"    é‘½å­” {hole_id}: ä¿ç•™ {len(keep_data)} å±¤ï¼ˆåŸ {len(hole_data)} å±¤ï¼‰ï¼Œå°‡ç¬¬ä¸€å€‹>20må±¤({soil_depths.iloc[first_over_20_idx]:.3f}m)è¨­ç‚º20m")
                    else:
                        # æ²’æœ‰è¶…é20mçš„å±¤ï¼Œå…¨éƒ¨ä¿ç•™
                        keep_data = hole_data
                        print(f"    é‘½å­” {hole_id}: å…¨éƒ¨ä¿ç•™ {len(keep_data)} å±¤ï¼ˆç„¡è¶…é20mçš„åœŸå±¤ï¼‰")
                
                filtered_dfs.append(keep_data)
            
            filtered_df = pd.concat(filtered_dfs, ignore_index=True)
            
            removed_count = len(final_df) - len(filtered_df)
            print(f"  ç¸½å…±ç§»é™¤è³‡æ–™ï¼š{removed_count} ç­†")
            print(f"  éæ¿¾å¾Œè³‡æ–™ç­†æ•¸ï¼š{len(filtered_df)}")
            
            if len(filtered_df) == 0:
                print(f"  è­¦å‘Šï¼šéæ¿¾å¾Œæ²’æœ‰è³‡æ–™ï¼")
                return None
        else:
            print(f"  è­¦å‘Šï¼šæ‰¾ä¸åˆ°ä¸Šé™æ·±åº¦æ¬„ä½ï¼Œè·³éæ·±åº¦éæ¿¾")
            filtered_df = final_df.copy()
        
        # å»ºç«‹ç°¡åŒ–å ±è¡¨
        simplified_df = pd.DataFrame()
        
        for original_col, new_col in available_columns:
            if original_col in filtered_df.columns:
                simplified_df[new_col] = filtered_df[original_col]
        
        # è£œå……ç¼ºå¤±çš„æ¬„ä½ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        for original_col, new_col in column_mapping.items():
            if new_col not in simplified_df.columns:
                if original_col in filtered_df.columns:
                    simplified_df[new_col] = filtered_df[original_col]
                else:
                    simplified_df[new_col] = "-"
        
        # ç¢ºä¿æ¬„ä½é †åºæ­£ç¢º
        desired_order = ['HOLE ID', 'X', 'Y', 'Z', 'from', 'to', 'USCS', 'SPT-N', 'FS', 'LPI']
        simplified_df = simplified_df[desired_order]
        
        # é‡æ–°è¨ˆç®— from å’Œ toï¼ˆæ ¹æ“šåœŸå±¤æ·±åº¦ä½œç‚ºä¸­å¿ƒæ·±åº¦ï¼‰
        print("  æ­£åœ¨é‡æ–°è¨ˆç®— from å’Œ to æ·±åº¦...")
        for hole_id in simplified_df['HOLE ID'].unique():
            hole_mask = simplified_df['HOLE ID'] == hole_id
            hole_data = simplified_df[hole_mask].copy()
            
            # æŒ‰ç…§åŸå§‹é †åºæ’åº
            hole_data = hole_data.sort_values('from').reset_index(drop=True)
            hole_indices = simplified_df[hole_mask].index.tolist()
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åœŸå±¤æ·±åº¦æ¬„ä½
            depth_col = None
            possible_depth_cols = ['åœŸå±¤æ·±åº¦', 'åœŸå±¤æ·±åº¦(m)']
            
            # å¾ filtered_df ä¸­æ‰¾å°æ‡‰çš„åœŸå±¤æ·±åº¦è³‡æ–™
            hole_original_data = filtered_df[filtered_df['é‘½å­”ç·¨è™Ÿ'] == hole_id].copy()
            
            for col in possible_depth_cols:
                if col in hole_original_data.columns:
                    depth_col = col
                    break
            
            if depth_col is None:
                print(f"    è­¦å‘Šï¼šé‘½å­” {hole_id} æ‰¾ä¸åˆ°åœŸå±¤æ·±åº¦æ¬„ä½ï¼Œä½¿ç”¨åŸå§‹ from/to")
                continue
            
            # å–å¾—æ‰€æœ‰åœŸå±¤æ·±åº¦å€¼ä¸¦æ’åº
            layer_depths = []
            for i in range(len(hole_data)):
                try:
                    depth_value = hole_original_data.iloc[i][depth_col]
                    depth = float(depth_value) if pd.notnull(depth_value) and depth_value != "-" else 0.0
                    layer_depths.append(depth)
                except (ValueError, IndexError, TypeError):
                    layer_depths.append(0.0)
            
            # é‡æ–°è¨ˆç®— from å’Œ to
            for i in range(len(hole_data)):
                actual_idx = hole_indices[i]
                current_depth = layer_depths[i]
                
                if i == 0:
                    # ç¬¬ä¸€å±¤ï¼šfrom = 0, to = ç•¶å‰æ·±åº¦
                    from_depth = 0.0
                    if i + 1 < len(layer_depths):
                        to_depth = current_depth
                    else:
                        # åªæœ‰ä¸€å±¤çš„æƒ…æ³ï¼Œto = ç•¶å‰æ·±åº¦æˆ–20
                        to_depth = min(current_depth, 20.0)
                elif i == len(layer_depths) - 1:
                    # æœ€å¾Œä¸€å±¤ï¼šfrom = å‰ä¸€å±¤çš„ to, to = 20 æˆ–ç•¶å‰æ·±åº¦
                    prev_idx = hole_indices[i - 1]
                    from_depth = simplified_df.loc[prev_idx, 'to']
                    to_depth = 20.0
                else:
                    # ä¸­é–“å±¤ï¼šfrom = å‰ä¸€å±¤æ·±åº¦ + ç•¶å‰æ·±åº¦, to = ç•¶å‰æ·±åº¦
                    prev_idx = hole_indices[i - 1]
                    from_depth = simplified_df.loc[prev_idx, 'to']
                    to_depth = current_depth 
                
                # ç¢ºä¿ä¸è¶…é 20m
                to_depth = min(to_depth, 20.0)
                
                simplified_df.loc[actual_idx, 'from'] = from_depth
                simplified_df.loc[actual_idx, 'to'] = to_depth
            
            print(f"    é‘½å­” {hole_id}: é‡æ–°è¨ˆç®— from/toï¼ŒåŸºæ–¼åœŸå±¤æ·±åº¦åˆ†å‰²")
        
        # è™•ç†æ•¸å€¼æ ¼å¼
        numeric_cols = ['X', 'Y', 'Z', 'from', 'to', 'SPT-N', 'FS', 'LPI']
        for col in numeric_cols:
            if col in simplified_df.columns:
                simplified_df[col] = simplified_df[col].apply(
                    lambda x: format_result(x, 3) if pd.notnull(x) and x != "-" and x != "" else "-"
                )
        
        # ç”Ÿæˆè¼¸å‡ºæª”å
        if output_dir is None:
            output_dir = ""
        current_date = datetime.now().strftime("%m%d")
        simplified_filename = os.path.join(output_dir, f"NCEER_{scenario}_{current_date}.csv")
        
        try:
            simplified_df.to_csv(simplified_filename, index=False, encoding='utf-8-sig')
            print(f"âœ… ç°¡åŒ–å ±è¡¨å·²å„²å­˜è‡³ï¼š{simplified_filename}")
            
            # é¡¯ç¤ºå ±è¡¨çµ±è¨ˆ
            total_rows = len(simplified_df)
            unique_holes = simplified_df['HOLE ID'].nunique()
            print(f"   ç¸½è¨˜éŒ„æ•¸ï¼š{total_rows}")
            print(f"   é‘½å­”æ•¸é‡ï¼š{unique_holes}")
            
            return simplified_filename
            
        except Exception as e:
            print(f"å„²å­˜ç°¡åŒ–å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return None
    
    def generate_lpi_summary_report(self, final_df: pd.DataFrame, output_dir: str = None) -> str:
        """ç”ŸæˆLPIæ‘˜è¦å ±è¡¨"""
        print(f"\næ­£åœ¨ç”ŸæˆLPIæ‘˜è¦å ±è¡¨...")
        
        # å–å¾—æ¯å€‹é‘½å­”çš„åŸºæœ¬è³‡è¨Šå’ŒLPIç¸½å’Œ
        summary_data = []
        
        for hole_id in final_df['é‘½å­”ç·¨è™Ÿ'].unique():
            hole_data = final_df[final_df['é‘½å­”ç·¨è™Ÿ'] == hole_id]
            
            if len(hole_data) == 0:
                continue
            
            # ===== åŠ å…¥è·Ÿç°¡åŒ–å ±è¡¨ç›¸åŒçš„æ·±åº¦éæ¿¾é‚è¼¯ =====
            # æŒ‰åˆ†æé»æ·±åº¦æ’åº
            hole_data = hole_data.sort_values('åˆ†æé»æ·±åº¦').reset_index(drop=True)
            
            # æ‰¾åˆ°ç¬¬ä¸€å€‹æ·±åº¦è¶…é20mçš„ç´¢å¼•
            first_over_20_idx = None
            for i, row in hole_data.iterrows():
                depth = row.get('åˆ†æé»æ·±åº¦', 0)
                try:
                    depth = float(depth) if pd.notna(depth) and depth != "" else 0
                except (ValueError, TypeError):
                    depth = 0
                
                if depth > 20:
                    first_over_20_idx = i
                    break
            
            # å¦‚æœæœ‰è¶…é20mçš„å±¤ï¼Œåªä¿ç•™åˆ°ç¬¬ä¸€å€‹è¶…é20mçš„å±¤ï¼ˆåŒ…å«ï¼‰
            if first_over_20_idx is not None:
                hole_data = hole_data.iloc[:first_over_20_idx + 1].copy()
            # ===== æ·±åº¦éæ¿¾é‚è¼¯çµæŸ =====
            
            # å–å¾—åº§æ¨™å’Œé«˜ç¨‹ï¼ˆä½¿ç”¨ç¬¬ä¸€ç­†è³‡æ–™ï¼‰
            first_row = hole_data.iloc[0]
            x = first_row.get('TWD97_X', '')
            y = first_row.get('TWD97_Y', '')
            z = first_row.get('é‘½å­”åœ°è¡¨é«˜ç¨‹', '')
            
            # è¨ˆç®—å„æƒ…å¢ƒçš„LPIç¸½å’Œï¼ˆä½¿ç”¨éæ¿¾å¾Œçš„è³‡æ–™ï¼‰
            lpi_sums = {}
            scenarios = ['Design', 'MidEq', 'MaxEq']
            
            for scenario in scenarios:
                lpi_col = f'LPI_{scenario}'
                if lpi_col in hole_data.columns:
                    # å°‡LPIå€¼è½‰æ›ç‚ºæ•¸å€¼ï¼Œå¿½ç•¥"-"å’Œç©ºå€¼
                    lpi_values = []
                    for lpi_val in hole_data[lpi_col]:
                        if lpi_val != '-' and lpi_val != '' and pd.notna(lpi_val):
                            try:
                                lpi_values.append(float(lpi_val))
                            except (ValueError, TypeError):
                                continue
                    
                    total_lpi = sum(lpi_values) if lpi_values else 0.0
                    lpi_sums[scenario] = round(total_lpi, 3)
                else:
                    lpi_sums[scenario] = 0.0
            
            summary_data.append({
                'Hole_ID': hole_id,
                'X': x,
                'Y': y,
                'Z': z,
                'LPI_Design': lpi_sums['Design'],
                'LPI_MidEq': lpi_sums['MidEq'],
                'LPI_MaxEq': lpi_sums['MaxEq']
            })
        
        # å»ºç«‹DataFrame
        summary_df = pd.DataFrame(summary_data)
        
        # æ ¼å¼åŒ–æ•¸å€¼
        numeric_cols = ['X', 'Y', 'Z', 'LPI_Design', 'LPI_MidEq', 'LPI_MaxEq']
        for col in numeric_cols:
            if col in summary_df.columns:
                summary_df[col] = summary_df[col].apply(
                    lambda x: format_result(x, 3) if pd.notnull(x) and x != "" else ""
                )
        
        # ç”Ÿæˆè¼¸å‡ºæª”å
        current_date = datetime.now().strftime("%m%d")
        if output_dir is None:
            output_dir = ""
        
        filename = os.path.join(output_dir, f"LPI_Summary_NCEER_{current_date}.csv")
        
        try:
            summary_df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"âœ… LPIæ‘˜è¦å ±è¡¨å·²å„²å­˜è‡³ï¼š{filename}")
            
            # é¡¯ç¤ºå ±è¡¨çµ±è¨ˆ
            print(f"   é‘½å­”æ•¸é‡ï¼š{len(summary_df)}")
            print(f"   å ±è¡¨æ¬„ä½ï¼š{list(summary_df.columns)}")
            
            return filename
            
        except Exception as e:
            print(f"å„²å­˜LPIæ‘˜è¦å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return None

    
    def NCEER_main(self, show_gui: bool = True, input_file_path: Optional[str] = None, 
         output_file_path: Optional[str] = None, use_fault_data: bool = True,
         fault_shapefile_path: Optional[str] = None, custom_em: Optional[float] = None):
    
        print("="*80)
        print("é–‹å§‹ NCEER æ¶²åŒ–åˆ†æ...")
        print("="*80)

        # å–å¾— Em å€¼
        if custom_em is not None:
            self.default_em = custom_em
            print(f"ä½¿ç”¨æŒ‡å®šçš„ Em å€¼: {custom_em}")
        else:
            self.default_em = self.get_user_em_value()
            print(f"ä½¿ç”¨ Em å€¼: {self.default_em}")

        # 1. å–å¾—æª”æ¡ˆè·¯å¾‘
        if input_file_path is None and show_gui:
            file_path = get_input_file(None, show_gui=True)
        elif input_file_path is not None:
            file_path = input_file_path
        else:
            print("éŒ¯èª¤ï¼šæœªæä¾› input_file_pathï¼Œä¸”æœªå•Ÿç”¨ GUI")
            return None, None, None
        
        if not file_path:
            return None, None, None

        # 2. è©¢å•æ˜¯å¦ä½¿ç”¨æ–·å±¤è³‡æ–™
        fault_gdf = None
        if use_fault_data:
            if fault_shapefile_path:
                try:
                    fault_gdf = gpd.read_file(fault_shapefile_path)
                    print(f"âœ… æˆåŠŸè¼‰å…¥æ–·å±¤è³‡æ–™ï¼š{len(fault_gdf)} å€‹è¨˜éŒ„")
                except Exception as e:
                    print(f"âš ï¸ è¼‰å…¥æ–·å±¤è³‡æ–™å¤±æ•—ï¼š{e}")
                    fault_gdf = None
            else:
                # è©¢å•ä½¿ç”¨è€…æ˜¯å¦è¦ä½¿ç”¨æ–·å±¤è³‡æ–™
                use_fault = input("æ˜¯å¦è¦ä½¿ç”¨æ–·å±¤è·é›¢åƒæ•¸ï¼Ÿ(y/nï¼Œé è¨­ç‚º y): ").strip().lower()
                if use_fault in ['y', 'yes','']:
                    print("è«‹é¸æ“‡æ–·å±¤ shapefile (.shp) æª”æ¡ˆ...")
                    try:
                        root = tk.Tk()
                        root.withdraw()
                        shp_path = filedialog.askopenfilename(
                            title="é¸æ“‡æ–·å±¤ shapefile",
                            filetypes=[("Shapefile", "*.shp")]
                        )
                        root.destroy()
                        
                        if shp_path:
                            fault_gdf = gpd.read_file(shp_path)
                            print(f"âœ… æˆåŠŸè¼‰å…¥æ–·å±¤è³‡æ–™ï¼š{len(fault_gdf)} å€‹è¨˜éŒ„")
                        else:
                            print("âš ï¸ æœªé¸æ“‡æ–·å±¤æª”æ¡ˆï¼Œè·³éæ–·å±¤è·é›¢åƒæ•¸æŸ¥è©¢")
                            use_fault_data = False
                    except Exception as e:
                        print(f"âš ï¸ è¼‰å…¥æ–·å±¤è³‡æ–™å¤±æ•—ï¼š{e}")
                        use_fault_data = False
                else:
                    print("è·³éæ–·å±¤è·é›¢åƒæ•¸æŸ¥è©¢")
                    use_fault_data = False

        # 3. è®€å–è³‡æ–™
        print("æ­£åœ¨è®€å–è³‡æ–™...")
        try:
            df = pd.read_csv(file_path)
            df = self.validate_input_data(df)
            print(f"å…±è®€å– {len(df)} ç­†è³‡æ–™")
        except Exception as e:
            print(f"è®€å–æª”æ¡ˆéŒ¯èª¤ï¼š{e}")
            return None, None, None



        # 3.1 éæ¿¾Nå€¼ç‚ºç©ºçš„è³‡æ–™
        print("\næ­£åœ¨éæ¿¾Nå€¼...")
        original_count = len(df)

        # æª¢æŸ¥Nå€¼æ¬„ä½
        n_value_column = None
        possible_n_cols = ['N_value', 'Nå€¼', 'SPT_N', 'N', 'spt_n']

        for col in possible_n_cols:
            if col in df.columns:
                n_value_column = col
                break

        if n_value_column is None:
            print("è­¦å‘Šï¼šæ‰¾ä¸åˆ°Nå€¼æ¬„ä½ï¼Œè·³éNå€¼éæ¿¾")
            print(f"å¯ç”¨æ¬„ä½ï¼š{list(df.columns)}")
        else:
            print(f"ä½¿ç”¨Nå€¼æ¬„ä½ï¼š{n_value_column}")
            
            # éæ¿¾æ¢ä»¶ï¼šNå€¼ä¸ç‚ºç©ºã€ä¸ç‚ºNaNã€ä¸ç‚ºç©ºå­—ä¸²
            def is_valid_n_value(value):
                if pd.isna(value) or value == '' or value is None:
                    return False
                
                # è½‰æ›ç‚ºå­—ä¸²æª¢æŸ¥
                value_str = str(value).strip()
                
                if value_str == '' or value_str.upper() == 'NAN':
                    return False
                
                # å˜—è©¦è§£ææ•¸å€¼ï¼ˆåŒ…å«>ç¬¦è™Ÿçš„æƒ…æ³ï¼‰
                parsed_value = parse_numeric_value(value)
                return parsed_value is not None
            
            # æ‡‰ç”¨éæ¿¾æ¢ä»¶
            valid_mask = df[n_value_column].apply(is_valid_n_value)
            df = df[valid_mask].reset_index(drop=True)
            
            filtered_count = len(df)
            removed_count = original_count - filtered_count
            
            print(f"Nå€¼éæ¿¾çµæœï¼š")
            print(f"  åŸå§‹è³‡æ–™ç­†æ•¸ï¼š{original_count}")
            print(f"  ä¿ç•™è³‡æ–™ç­†æ•¸ï¼š{filtered_count}")
            print(f"  ç§»é™¤è³‡æ–™ç­†æ•¸ï¼š{removed_count}")
            
            if filtered_count == 0:
                print("âŒ éŒ¯èª¤ï¼šéæ¿¾å¾Œæ²’æœ‰ä»»ä½•è³‡æ–™ï¼è«‹æª¢æŸ¥Nå€¼è³‡æ–™")
                return None, None, None
            
            # é¡¯ç¤ºç§»é™¤çš„è³‡æ–™çµ±è¨ˆ
            if removed_count > 0:
                removed_wells = df[~valid_mask]['é‘½å­”ç·¨è™Ÿ'].nunique() if 'é‘½å­”ç·¨è™Ÿ' in df.columns else 0
                print(f"  å½±éŸ¿é‘½å­”æ•¸ï¼š{removed_wells} å€‹")
        #3.2 éæ¿¾éSPTé‘½äº•
        # éæ¿¾å–æ¨£ç·¨è™Ÿï¼šåªä¿ç•™é–‹é ­æ˜¯ "S" çš„è³‡æ–™
        print("\næ­£åœ¨éæ¿¾å–æ¨£ç·¨è™Ÿ...")
        original_count = len(df)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å–æ¨£ç·¨è™Ÿæ¬„ä½
        sampling_id_column = None
        possible_columns = ['å–æ¨£ç·¨è™Ÿ', 'æ¨£æœ¬ç·¨è™Ÿ', 'Sample_ID', 'sampling_id', 'ç·¨è™Ÿ']
        
        for col in possible_columns:
            if col in df.columns:
                sampling_id_column = col
                break
        
        if sampling_id_column is None:
            print("è­¦å‘Šï¼šæ‰¾ä¸åˆ°å–æ¨£ç·¨è™Ÿæ¬„ä½ï¼Œè·³ééæ¿¾æ­¥é©Ÿ")
            print(f"å¯ç”¨æ¬„ä½ï¼š{list(df.columns)}")
        else:
            print(f"ä½¿ç”¨æ¬„ä½ï¼š{sampling_id_column}")
            
            # éæ¿¾æ¢ä»¶ï¼šå–æ¨£ç·¨è™Ÿé–‹é ­æ˜¯ "S"
            mask = df[sampling_id_column].astype(str).str.startswith('S')
            df = df[mask].reset_index(drop=True)
            
            filtered_count = len(df)
            removed_count = original_count - filtered_count
            
            print(f"éæ¿¾çµæœï¼š")
            print(f"  åŸå§‹è³‡æ–™ç­†æ•¸ï¼š{original_count}")
            print(f"  ä¿ç•™è³‡æ–™ç­†æ•¸ï¼š{filtered_count}")
            print(f"  ç§»é™¤è³‡æ–™ç­†æ•¸ï¼š{removed_count}")
            
            if filtered_count == 0:
                print("âŒ éŒ¯èª¤ï¼šéæ¿¾å¾Œæ²’æœ‰ä»»ä½•è³‡æ–™ï¼è«‹æª¢æŸ¥å–æ¨£ç·¨è™Ÿæ ¼å¼")
                return None, None, None
            
            # é¡¯ç¤ºä¿ç•™çš„å–æ¨£ç·¨è™Ÿç¯„ä¾‹
            sample_ids = df[sampling_id_column].unique()[:5]
            print(f"  ä¿ç•™çš„å–æ¨£ç·¨è™Ÿç¯„ä¾‹ï¼š{list(sample_ids)}")
            if len(df[sampling_id_column].unique()) > 5:
                print(f"  ... ç­‰å…± {len(df[sampling_id_column].unique())} å€‹ä¸åŒçš„å–æ¨£ç·¨è™Ÿ")

        # 4. ç²å–å”¯ä¸€çš„é‘½å­”ç·¨è™Ÿ
        well_ids = df['é‘½å­”ç·¨è™Ÿ'].unique()
        print(f"ç™¼ç¾ {len(well_ids)} å€‹é‘½å­”ï¼š{list(well_ids)}")

        # 5. ä½¿ç”¨æª”æ¡ˆä¸­çš„åº§æ¨™é€²è¡Œæœå°‹ï¼Œç²å–åœ°éœ‡åƒæ•¸
        well_params = get_earthquake_parameters_from_wells(df, use_fault_data, fault_gdf)

        # 6. å°‡æŸ¥è©¢çµæœæ·»åŠ åˆ°åŸå§‹è³‡æ–™ä¸­
        print("\næ­£åœ¨å°‡åœ°éœ‡åƒæ•¸æ·»åŠ åˆ°è³‡æ–™ä¸­...")
        df['åŸå¸‚'] = df['é‘½å­”ç·¨è™Ÿ'].map(lambda x: well_params[x]['city'] if x in well_params else 'æœªçŸ¥')
        df['åŸºæº–Mw'] = df['é‘½å­”ç·¨è™Ÿ'].map(lambda x: well_params[x]['base_mw'] if x in well_params else 7.0)
        df['SDS'] = df['é‘½å­”ç·¨è™Ÿ'].map(lambda x: well_params[x]['SDS'] if x in well_params else 0.8)
        df['SMS'] = df['é‘½å­”ç·¨è™Ÿ'].map(lambda x: well_params[x]['SMS'] if x in well_params else 1.0)
        df['è³‡æ–™ä¾†æº'] = df['é‘½å­”ç·¨è™Ÿ'].map(lambda x: well_params[x]['search_result'].get('è³‡æ–™ä¾†æº', '') if x in well_params and well_params[x]['search_result'] else '')
        
        # 7. é¡¯ç¤ºæ¯å€‹é‘½å­”ä½¿ç”¨çš„åœ°éœ‡åƒæ•¸
        print("\n=== å„é‘½å­”åœ°éœ‡åƒæ•¸æ‘˜è¦ ===")
        for well_id in well_ids:
            params = well_params[well_id]
            print(f"é‘½å­” {well_id}:")
            print(f"  ä½ç½®: {params['city']}")
            print(f"  åŸºæº–Mw: {params['base_mw']}")
            print(f"  SDS: {params['SDS']}")
            print(f"  SMS: {params['SMS']}")

        # 8. é€äº•è¨ˆç®—æ¶²åŒ–åƒæ•¸
        print("\n=== æ­£åœ¨è¨ˆç®—æ¶²åŒ–åƒæ•¸ ===")
        results_list = []
        lpi_summary = {}

        for well_id in well_ids:
            print(f"\nè™•ç†é‘½å­”ï¼š{well_id}")
            well_df = df[df['é‘½å­”ç·¨è™Ÿ'] == well_id].copy()
            
            # å–å¾—è©²äº•çš„åœ°éœ‡åƒæ•¸
            params = well_params[well_id]
            SDS = params['SDS']
            SMS = params['SMS']
            base_mw = params['base_mw']
            city = params['city']
            
            # åœ°éœ‡æƒ…å¢ƒè¨­å®š
            earthquake_scenarios = {
                "Design": {"description": "è¨­è¨ˆåœ°éœ‡"},
                "MidEq": {"description": "ä¸­å°åœ°éœ‡"}, 
                "MaxEq": {"description": "æœ€å¤§åœ°éœ‡"}
            }
            
            print(f"  ä½¿ç”¨åœ°éœ‡åƒæ•¸ï¼šSDS={SDS}, SMS={SMS}")
            
            # ç¢ºä¿ GWT_CSR æ¬„ä½å­˜åœ¨
            if 'GWT_CSR' not in well_df.columns:
                well_df['GWT_CSR'] = 0  # é è¨­åœ°ä¸‹æ°´ä½æ·±åº¦ 0m
            
            try:
                # è¨ˆç®—åŸºæœ¬åƒæ•¸
                well_df = self.compute_coefficient(well_df)
                
                # è¨ˆç®— Vs ç›¸é—œåƒæ•¸
                well_df['Vs'] = well_df.apply(self.compute_Vs, axis=1)
                
                # è¨ˆç®— Vs30 (éœ€è¦æ•´å€‹group)
                vs30 = self.compute_Vs30(well_df)
                well_df['Vs30'] = vs30
                well_df['åœ°ç›¤åˆ†é¡'] = self.ground_class_from_vs30(vs30)
                
                # ç‚ºæ¯è¡Œæ·»åŠ  vs30 å±¬æ€§ä»¥ä¾› compute_Fa ä½¿ç”¨
                for idx in well_df.index:
                    well_df.loc[idx, '_vs30'] = vs30
                
                # è¨ˆç®— N60, N1_60, N1_60cs, CRR_7_5
                well_df['N_60'] = well_df.apply(self.compute_N60, axis=1)
                well_df['N1_60'] = well_df.apply(self.compute_N1_60, axis=1)  
                well_df['N1_60cs'] = well_df.apply(self.compute_N1_60cs, axis=1)
                well_df['CRR_7_5'] = well_df.apply(self.compute_CRR_7_5, axis=1)
                
                # è¨ˆç®—ä¸‰ç¨®åœ°éœ‡æƒ…å¢ƒçš„æ¶²åŒ–åƒæ•¸
                for scenario, scenario_data in earthquake_scenarios.items():
                    print(f"    æ­£åœ¨è¨ˆç®— {scenario} åœ°éœ‡æƒ…å¢ƒ...")
                    
                    # æ ¹æ“šæƒ…å¢ƒèª¿æ•´ Mw å€¼
                    adjusted_mw = get_scenario_mw(base_mw, scenario)
                    
                    # è¨ˆç®—æ¶²åŒ–åƒæ•¸
                    liq_results = well_df.apply(
                        lambda row: self.calculate_FS(row, scenario), 
                        axis=1
                    )
                    
                    # æå–çµæœåˆ°å°æ‡‰æ¬„ä½
                    well_df[f'Mw_{scenario}'] = [result['Mw_used'] for result in liq_results]
                    well_df[f'A_value_{scenario}'] = [result['A_value'] for result in liq_results]
                    well_df[f'SD_S_{scenario}'] = [result['SD_S'] for result in liq_results]
                    well_df[f'SM_S_{scenario}'] = [result['SM_S'] for result in liq_results]
                    well_df[f'MSF_{scenario}'] = [result['MSF'] for result in liq_results]
                    well_df[f'rd_{scenario}'] = [result['rd'] for result in liq_results]
                    well_df[f'CSR_{scenario}'] = [result['CSR'] for result in liq_results]
                    well_df[f'CRR_{scenario}'] = [result['CRR'] for result in liq_results]
                    well_df[f'FS_{scenario}'] = [result['FS'] for result in liq_results]
                    
                    print(f"      Mw: {base_mw} â†’ {adjusted_mw} (èª¿æ•´å€¼: {adjusted_mw - base_mw:+.1f})")
                
                # è¨ˆç®—æ¯å±¤ LPI
                for scenario in earthquake_scenarios.keys():
                    well_df[f'LPI_{scenario}'] = well_df.apply(
                        lambda row: self.calculate_LPI_single_layer(row, scenario), axis=1
                    )
                
                # æ·»åŠ äº•çš„åŸºæœ¬è³‡è¨Š
                well_df['åŸå¸‚'] = city
                well_df['åŸºæº–åœ°éœ‡è¦æ¨¡Mw'] = format_result(base_mw, 1)
                well_df['ä½¿ç”¨SDS'] = SDS
                well_df['ä½¿ç”¨SMS'] = SMS
                
                # è¨ˆç®—è©²äº•ç¸½ LPI
                lpi_results = {}
                for scenario in earthquake_scenarios.keys():
                    lpi_col = f'LPI_{scenario}'
                    total_lpi = well_df[lpi_col].apply(
                        lambda x: float(x) if x != "-" and pd.notnull(x) else 0.0
                    ).sum()
                    lpi_results[scenario] = format_result(total_lpi)
                
                lpi_summary[well_id] = lpi_results
                results_list.append(well_df)
                
            except Exception as e:
                print(f"  âŒ è™•ç†é‘½å­” {well_id} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                logger.error(f"è™•ç†é‘½å­” {well_id} éŒ¯èª¤ï¼š{e}")
                continue

        if not results_list:
            print("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•é‘½å­”è³‡æ–™")
            return None, None, file_path

        # 9. åˆä½µæ‰€æœ‰çµæœ
        final_df = pd.concat(results_list, ignore_index=True)

        # 10. æ ¼å¼åŒ–æ•¸å€¼æ¬„ä½
        numeric_columns = ['ç´¯è¨ˆsigmav', 'sigma_v_CSR', 'åˆ†æé»æ·±åº¦', 'åœŸå±¤åšåº¦', 'åœŸå±¤ä¸­é»æ·±åº¦']
        for col in numeric_columns:
            if col in final_df.columns:
                final_df[col] = final_df[col].apply(lambda x: format_result(x) if pd.notnull(x) else "-")

        # 11. é¸æ“‡è¼¸å‡ºè³‡æ–™å¤¾ - æ”¹å–„ç‰ˆæœ¬
        if show_gui:
            print("\nè«‹é¸æ“‡ç¸½è¼¸å‡ºè³‡æ–™å¤¾...")
            try:
                root = tk.Tk()
                root.withdraw()
                output_dir = filedialog.askdirectory(
                    title="é¸æ“‡æ‰€æœ‰åˆ†æçµæœçš„ç¸½è¼¸å‡ºè³‡æ–™å¤¾"
                )
                root.destroy()
                
                if not output_dir:
                    print("âš ï¸ æœªé¸æ“‡è¼¸å‡ºè³‡æ–™å¤¾ï¼Œä½¿ç”¨ç•¶å‰ç›®éŒ„")
                    output_dir = os.getcwd()
                else:
                    print(f"âœ… å·²é¸æ“‡ç¸½è¼¸å‡ºè³‡æ–™å¤¾ï¼š{output_dir}")
            except ImportError:
                # Django ç’°å¢ƒä¸­ä½¿ç”¨é è¨­è·¯å¾‘
                output_dir = os.getcwd()
                print(f"ç¶²é ç’°å¢ƒï¼šä½¿ç”¨é è¨­è¼¸å‡ºç›®éŒ„ï¼š{output_dir}")   
                                    
            except Exception as e:
                print(f"GUI éŒ¯èª¤ï¼š{e}")
                output_dir = os.getcwd()
                print(f"ä½¿ç”¨ç•¶å‰å·¥ä½œç›®éŒ„ï¼š{output_dir}")
        else:
            if output_file_path:
                output_dir = os.path.dirname(output_file_path)
                if not output_dir:
                    output_dir = os.getcwd()
            else:
                output_dir = os.getcwd()
            print(f"ä½¿ç”¨è¼¸å‡ºç›®éŒ„ï¼š{output_dir}")

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        if not os.path.exists(output_dir):
            try:
                os.makedirs(output_dir)
                print(f"âœ… å·²å‰µå»ºè¼¸å‡ºç›®éŒ„ï¼š{output_dir}")
            except Exception as e:
                print(f"âŒ ç„¡æ³•å‰µå»ºè¼¸å‡ºç›®éŒ„ï¼š{e}")
                output_dir = os.getcwd()
                print(f"æ”¹ç”¨ç•¶å‰å·¥ä½œç›®éŒ„ï¼š{output_dir}")

        # 11.1 è¨­å®šä¸»è¦CSVè¼¸å‡ºæª”å
        current_date = datetime.now().strftime("%m%d")
        if output_file_path is None:
            output_filename = os.path.join(output_dir, f"NCEERæ¶²åŒ–åˆ†æçµæœ_{current_date}.csv")
        else:
            output_filename = output_file_path

        try:
            final_df.to_csv(output_filename, index=False, encoding='utf-8-sig')
            print(f"\nâœ… åˆ†æå®Œæˆï¼")
            print(f"âœ… å·²å„²å­˜æ‰€æœ‰çµæœè‡³ï¼š{output_filename}")
        except Exception as e:
            print(f"å„²å­˜æª”æ¡ˆéŒ¯èª¤ï¼š{e}")
            return final_df, lpi_summary, file_path

        # 12. è¼¸å‡ºè©³ç´°æ‘˜è¦çµ±è¨ˆ
        print("\n" + "="*80)
        print("=== æœ€çµ‚åˆ†ææ‘˜è¦ ===")
        print("="*80)
        print("åˆ†ææ–¹æ³•ï¼šNCEER(2001)")
        for well_id in well_ids:
            if well_id not in well_params:
                continue
                
            params = well_params[well_id]
            well_result = final_df[final_df['é‘½å­”ç·¨è™Ÿ'] == well_id]
            
            if len(well_result) == 0:
                continue
            
            print(f"\né‘½å­” {well_id}:")
            print(f"  TWD97åº§æ¨™: ({params['x']}, {params['y']})")
            print(f"  åŸå¸‚: {params['city']}")
            print(f"  åŸºæº–åœ°éœ‡è¦æ¨¡ Mw: {params['base_mw']}")
            print(f"  ä½¿ç”¨åœ°éœ‡åƒæ•¸: SDS={params['SDS']}, SMS={params['SMS']}")
            print(f"  åˆ†æå±¤æ•¸: {len(well_result)}")
            
            # é¡¯ç¤ºå„æƒ…å¢ƒä½¿ç”¨çš„Mwå€¼å’Œåœ°è¡¨åŠ é€Ÿåº¦
            print("  å„æƒ…å¢ƒåƒæ•¸:")
            
            scenarios_info = {
                "Design": {"desc": "è¨­è¨ˆåœ°éœ‡"},
                "MidEq": {"desc": "ä¸­å°åœ°éœ‡"}, 
                "MaxEq": {"desc": "æœ€å¤§åœ°éœ‡"}
            }
            
            for scenario, info in scenarios_info.items():
                scenario_mw = get_scenario_mw(params['base_mw'], scenario)
                adjustment = earthquake_mw_adjustments[scenario]
                print(f"    {scenario} ({info['desc']}): Mw={scenario_mw:.1f} (åŸºæº–{adjustment:+.1f})")
            
            # çµ±è¨ˆæ¶²åŒ–æ½›èƒ½å’Œ LPI
            for scenario in scenarios_info.keys():
                fs_col = f'FS_{scenario}'
                if fs_col in well_result.columns:
                    valid_fs = pd.to_numeric(well_result[fs_col], errors='coerce').dropna()
                    if len(valid_fs) > 0:
                        liquefaction_count = sum(valid_fs < 1.0)
                        total_lpi = lpi_summary.get(well_id, {}).get(scenario, "N/A")
                        print(f"  {scenario} æƒ…å¢ƒçµæœ:")
                        print(f"    æ¶²åŒ–å±¤æ•¸: {liquefaction_count}/{len(valid_fs)}")
                        print(f"    ç¸½LPI: {total_lpi}")

        print("\nç¨‹å¼åŸ·è¡Œå®Œæˆï¼")


        # 13. ç”Ÿæˆç°¡åŒ–å ±è¡¨åˆ°ç¸½è¼¸å‡ºè³‡æ–™å¤¾
        print("\n" + "="*60)
        print("=== ç”Ÿæˆç°¡åŒ–å ±è¡¨ ===")
        print("="*60)

        simplified_reports = {}

        for scenario in ["Design", "MidEq", "MaxEq"]:
            try:
                report_file = self.generate_simplified_report(
                    final_df, 
                    output_dir=output_dir, 
                    scenario=scenario
                )
                if report_file:
                    simplified_reports[scenario] = report_file
            except Exception as e:
                print(f"ç”Ÿæˆ {scenario} æƒ…å¢ƒç°¡åŒ–å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

        if simplified_reports:
            print(f"\nâœ… å…±ç”Ÿæˆ {len(simplified_reports)} å€‹ç°¡åŒ–å ±è¡¨ï¼š")
            for scenario, filename in simplified_reports.items():
                print(f"   {scenario} æƒ…å¢ƒï¼š{filename}")

        # 14. ç‚ºæ¯å€‹é‘½å­”ç”Ÿæˆç¨ç«‹è³‡æ–™å¤¾ï¼ŒåŒ…å«Excelå ±è¡¨å’Œåœ–è¡¨
        print("\n" + "="*60)
        print("=== ç‚ºæ¯å€‹é‘½å­”ç”Ÿæˆè³‡æ–™å¤¾ï¼ˆåŒ…å«Excelå ±è¡¨å’Œåœ–è¡¨ï¼‰===")
        print("="*60)

        generate_individual = input("æ˜¯å¦è¦ç‚ºæ¯å€‹é‘½å­”ç”Ÿæˆç¨ç«‹è³‡æ–™å¤¾ï¼ˆåŒ…å«Excelå ±è¡¨å’ŒJPGåœ–è¡¨ï¼‰ï¼Ÿ(y/nï¼Œé è¨­ç‚º y): ").strip().lower()

        if generate_individual in ['', 'y', 'yes']:
            try:
                # ç²å–æ‰€æœ‰é‘½å­”ID
                well_ids = final_df['é‘½å­”ç·¨è™Ÿ'].unique()
                
                print(f"æ­£åœ¨ç‚º {len(well_ids)} å€‹é‘½å­”ç”Ÿæˆç¨ç«‹è³‡æ–™å¤¾...")
                
                for i, well_id in enumerate(well_ids, 1):
                    print(f"\né€²åº¦ [{i}/{len(well_ids)}] è™•ç†é‘½å­”ï¼š{well_id}")
                    
                    try:
                        # 1. å»ºç«‹é‘½å­”è³‡æ–™å¤¾
                        well_dir = os.path.join(output_dir, str(well_id))
                        if not os.path.exists(well_dir):
                            os.makedirs(well_dir)
                        print(f"  âœ… å·²å»ºç«‹è³‡æ–™å¤¾ï¼š{well_dir}")
                        
                        # 2. ç¯©é¸è©²é‘½å­”çš„è³‡æ–™
                        well_data = final_df[final_df['é‘½å­”ç·¨è™Ÿ'] == well_id].copy()
                        
                        if len(well_data) == 0:
                            print(f"  âš ï¸ é‘½å­” {well_id} æ²’æœ‰è³‡æ–™ï¼Œè·³é")
                            continue
                        
                        # 3. ç”ŸæˆExcelå ±è¡¨
                        print(f"  æ­£åœ¨ç”ŸæˆExcelå ±è¡¨...")
                        current_date = datetime.now().strftime("%m%d")
                        excel_filename = f"{well_id}_æ¶²åŒ–åˆ†æå ±è¡¨_{current_date}.xlsx"
                        excel_filepath = os.path.join(well_dir, excel_filename)
                        
                        # ç¢ºä¿å°å…¥æ¨¡çµ„
                        try:
                            from report import create_liquefaction_excel_from_dataframe
                            create_liquefaction_excel_from_dataframe(well_data, excel_filepath)
                            print(f"  âœ… Excelå ±è¡¨ï¼š{excel_filename}")
                        except Exception as e:
                            print(f"  âŒ Excelå ±è¡¨ç”Ÿæˆå¤±æ•—ï¼š{e}")
                        
                        # 4. ç”Ÿæˆåœ–è¡¨
                        print(f"  æ­£åœ¨ç”Ÿæˆåœ–è¡¨...")
                        n_size = (5, 10)    # Nå€¼åœ–è¡¨å¤§å°
                        fs_size = (5, 10)   # FSåœ–è¡¨å¤§å°
                        
                        # ç¢ºä¿å°å…¥ä¸¦ä½¿ç”¨æ­£ç¢ºçš„åœ–è¡¨ç”Ÿæˆå™¨
                        try:
                            from report import LiquefactionChartGenerator
                            chart_generator = LiquefactionChartGenerator(
                                n_chart_size=n_size,
                                fs_chart_size=fs_size
                            )
                            
                            # ç”Ÿæˆæ·±åº¦-Nå€¼åœ–è¡¨
                            chart1 = chart_generator.generate_depth_n_chart(well_data, well_id, well_dir)
                            if chart1:
                                print(f"  âœ… Nå€¼åœ–è¡¨ï¼š{os.path.basename(chart1)}")
                            
                            # ç”Ÿæˆæ·±åº¦-FSåœ–è¡¨
                            chart2 = chart_generator.generate_depth_fs_chart(well_data, well_id, well_dir)
                            if chart2:
                                print(f"  âœ… FSåœ–è¡¨ï¼š{os.path.basename(chart2)}")
                            # ç”ŸæˆåœŸå£¤æŸ±ç‹€åœ–
                            chart3 = chart_generator.generate_soil_column_chart(well_data, well_id, well_dir)
                            if chart3:
                                print(f"  âœ… åœŸå£¤æŸ±ç‹€åœ–ï¼š{os.path.basename(chart3)}")
                                
                        except Exception as e:
                            print(f"  âŒ åœ–è¡¨ç”Ÿæˆå¤±æ•—ï¼š{e}")
                            import traceback
                            print(f"     è©³ç´°éŒ¯èª¤ï¼š{traceback.format_exc()}")
                        
                        print(f"  âœ… é‘½å­” {well_id} è™•ç†å®Œæˆ")
                        
                    except Exception as e:
                        print(f"  âŒ è™•ç†é‘½å­” {well_id} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                        import traceback
                        print(f"     è©³ç´°éŒ¯èª¤ï¼š{traceback.format_exc()}")
                        continue
                
                print(f"\nğŸ‰ æ‰€æœ‰é‘½å­”è³‡æ–™å¤¾ç”Ÿæˆå®Œæˆï¼")
                print(f"ğŸ“ è¼¸å‡ºä½ç½®ï¼š{output_dir}")
                print(f"ğŸ“‚ æ¯å€‹é‘½å­”è³‡æ–™å¤¾åŒ…å«ï¼š")
                print(f"   - Excelæ¶²åŒ–åˆ†æå ±è¡¨")
                print(f"   - SPT-Nå€¼éš¨æ·±åº¦è®ŠåŒ–åœ–ï¼ˆé™åˆ¶0-20mï¼‰")
                print(f"   - å®‰å…¨ä¿‚æ•¸éš¨æ·±åº¦è®ŠåŒ–åœ–ï¼ˆé™åˆ¶0-20mï¼‰")
                print(f"   - åœŸå£¤æŸ±ç‹€åœ–ï¼ˆå«åœ°ä¸‹æ°´ä½æ¨™ç¤ºï¼‰")
            except Exception as e:
                print(f"âŒ ç”Ÿæˆé‘½å­”è³‡æ–™å¤¾æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                import traceback
                print(f"è©³ç´°éŒ¯èª¤ï¼š{traceback.format_exc()}")
        else:
            print("è·³éé‘½å­”è³‡æ–™å¤¾ç”Ÿæˆ")
        
        # 15. ç”ŸæˆLPIæ‘˜è¦å ±è¡¨
        print("\n" + "="*60)
        print("=== ç”ŸæˆLPIæ‘˜è¦å ±è¡¨ ===")
        print("="*60)

        try:
            lpi_summary_file = self.generate_lpi_summary_report(final_df, output_dir)
            if lpi_summary_file:
                print(f"âœ… LPIæ‘˜è¦å ±è¡¨ç”Ÿæˆå®Œæˆ")
        except Exception as e:
            print(f"ç”ŸæˆLPIæ‘˜è¦å ±è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

        return final_df, lpi_summary, file_path
"""
        # 15. ç”ŸæˆJPGåœ–è¡¨ - æ”¹å–„ç‰ˆæœ¬
        print("\n" + "="*60)
        print("=== ç”ŸæˆJPGåœ–è¡¨ ===")
        print("="*60)

        # è©¢å•æ˜¯å¦è¦ç”Ÿæˆåœ–è¡¨
        generate_charts = input("æ˜¯å¦è¦ç‚ºæ¯å€‹é‘½å­”ç”ŸæˆJPGæ ¼å¼çš„æŠ˜ç·šåœ–ï¼Ÿ(y/nï¼Œé è¨­ç‚º y): ").strip().lower()

        if generate_charts in ['', 'y', 'yes']:
            try:
                print(f"é–‹å§‹ç”Ÿæˆåœ–è¡¨ï¼Œè¼¸å‡ºç›®éŒ„ï¼š{output_dir}")
                
                n_size = (5, 10)    # Nå€¼åœ–è¡¨ï¼šå¯¬12è‹±å¯¸ï¼Œé«˜10è‹±å¯¸
                fs_size = (5, 10)   # FSåœ–è¡¨ï¼šå¯¬14è‹±å¯¸ï¼Œé«˜10è‹±å¯¸
                # å…ˆå°å…¥åœ–è¡¨ç”Ÿæˆæ¨¡çµ„
                from report import generate_all_wells_charts
                
                # ç”Ÿæˆæ‰€æœ‰é‘½å­”çš„åœ–è¡¨
                chart_files = generate_all_wells_charts(final_df, output_dir,
                                                        n_chart_size= n_size,
                                                        fs_chart_size=fs_size
                                                        )
                
                if chart_files:
                    print(f"\nğŸ‰ åœ–è¡¨ç”Ÿæˆå®Œæˆï¼")
                    print(f"ğŸ“ˆ æ¯å€‹é‘½å­”ç”Ÿæˆ2å¼µåœ–è¡¨ï¼š")
                    print(f"   - è¨ˆç®—æ·±åº¦ vs Nå€¼é—œä¿‚åœ–")
                    print(f"   - è¨ˆç®—æ·±åº¦ vs å®‰å…¨ä¿‚æ•¸é—œä¿‚åœ– (ä¸‰ç¨®åœ°éœ‡æƒ…å¢ƒ)")
                    print(f"ğŸ“ åœ–è¡¨å„²å­˜ä½ç½®ï¼š{os.path.join(output_dir, 'åœ–è¡¨')}")
                else:
                    print(f"âš ï¸ æœªç”Ÿæˆä»»ä½•åœ–è¡¨ï¼Œè«‹æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§")
                
            except Exception as e:
                print(f"âŒ ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                import traceback
                print(f"è©³ç´°éŒ¯èª¤ï¼š{traceback.format_exc()}")
        else:
            print("è·³éJPGåœ–è¡¨ç”Ÿæˆ")

        return final_df, lpi_summary, file_path
"""


if __name__ == "__main__":
    input_path = get_input_file(None)
    NCEER_analyzer = NCEER()
    NCEER_analyzer.NCEER_main(show_gui=True, input_file_path=input_path)